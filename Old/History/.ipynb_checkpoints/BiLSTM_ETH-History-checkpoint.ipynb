{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499ef9d1-2655-483e-9f50-0badccf17d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Skripsi import Preprocessing\n",
    "from Skripsi import Evaluation\n",
    "from Skripsi import LSTMUnit\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openpyxl.workbook import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ed0706-d5c2-4868-beee-6933c00b0a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unix</th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume BTC</th>\n",
       "      <th>Volume USDT</th>\n",
       "      <th>tradecount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1672527600000</td>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>16520.28</td>\n",
       "      <td>16551.24</td>\n",
       "      <td>16487.74</td>\n",
       "      <td>16542.40</td>\n",
       "      <td>4973.433070</td>\n",
       "      <td>8.217183e+07</td>\n",
       "      <td>152632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1672524000000</td>\n",
       "      <td>2022-12-31 22:00:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>16548.28</td>\n",
       "      <td>16567.49</td>\n",
       "      <td>16470.00</td>\n",
       "      <td>16520.81</td>\n",
       "      <td>6695.136250</td>\n",
       "      <td>1.106669e+08</td>\n",
       "      <td>153933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1672520400000</td>\n",
       "      <td>2022-12-31 21:00:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>16568.19</td>\n",
       "      <td>16571.64</td>\n",
       "      <td>16544.12</td>\n",
       "      <td>16548.28</td>\n",
       "      <td>3618.773890</td>\n",
       "      <td>5.992803e+07</td>\n",
       "      <td>105065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1672516800000</td>\n",
       "      <td>2022-12-31 20:00:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>16570.14</td>\n",
       "      <td>16574.97</td>\n",
       "      <td>16564.09</td>\n",
       "      <td>16568.60</td>\n",
       "      <td>2622.143550</td>\n",
       "      <td>4.344849e+07</td>\n",
       "      <td>90705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1672513200000</td>\n",
       "      <td>2022-12-31 19:00:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>16577.78</td>\n",
       "      <td>16590.06</td>\n",
       "      <td>16565.10</td>\n",
       "      <td>16570.14</td>\n",
       "      <td>4044.433590</td>\n",
       "      <td>6.704605e+07</td>\n",
       "      <td>116587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26269</th>\n",
       "      <td>1577851200000</td>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>7225.00</td>\n",
       "      <td>7230.00</td>\n",
       "      <td>7215.03</td>\n",
       "      <td>7217.27</td>\n",
       "      <td>467.812578</td>\n",
       "      <td>3.379094e+06</td>\n",
       "      <td>5896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>1577847600000</td>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>7242.66</td>\n",
       "      <td>7245.00</td>\n",
       "      <td>7220.00</td>\n",
       "      <td>7225.01</td>\n",
       "      <td>783.724867</td>\n",
       "      <td>5.667367e+06</td>\n",
       "      <td>8337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26271</th>\n",
       "      <td>1577844000000</td>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>7215.52</td>\n",
       "      <td>7244.87</td>\n",
       "      <td>7211.41</td>\n",
       "      <td>7242.85</td>\n",
       "      <td>655.156809</td>\n",
       "      <td>4.736719e+06</td>\n",
       "      <td>7466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>1577840400000</td>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>7176.47</td>\n",
       "      <td>7230.00</td>\n",
       "      <td>7175.71</td>\n",
       "      <td>7216.27</td>\n",
       "      <td>883.052603</td>\n",
       "      <td>6.365953e+06</td>\n",
       "      <td>9033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26273</th>\n",
       "      <td>1577836800000</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>7195.24</td>\n",
       "      <td>7196.25</td>\n",
       "      <td>7175.46</td>\n",
       "      <td>7177.02</td>\n",
       "      <td>511.814901</td>\n",
       "      <td>3.675857e+06</td>\n",
       "      <td>7640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26274 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Unix                 Date   Symbol      Open      High  \\\n",
       "0      1672527600000  2022-12-31 23:00:00  BTCUSDT  16520.28  16551.24   \n",
       "1      1672524000000  2022-12-31 22:00:00  BTCUSDT  16548.28  16567.49   \n",
       "2      1672520400000  2022-12-31 21:00:00  BTCUSDT  16568.19  16571.64   \n",
       "3      1672516800000  2022-12-31 20:00:00  BTCUSDT  16570.14  16574.97   \n",
       "4      1672513200000  2022-12-31 19:00:00  BTCUSDT  16577.78  16590.06   \n",
       "...              ...                  ...      ...       ...       ...   \n",
       "26269  1577851200000  2020-01-01 04:00:00  BTCUSDT   7225.00   7230.00   \n",
       "26270  1577847600000  2020-01-01 03:00:00  BTCUSDT   7242.66   7245.00   \n",
       "26271  1577844000000  2020-01-01 02:00:00  BTCUSDT   7215.52   7244.87   \n",
       "26272  1577840400000  2020-01-01 01:00:00  BTCUSDT   7176.47   7230.00   \n",
       "26273  1577836800000  2020-01-01 00:00:00  BTCUSDT   7195.24   7196.25   \n",
       "\n",
       "            Low     Close   Volume BTC   Volume USDT  tradecount  \n",
       "0      16487.74  16542.40  4973.433070  8.217183e+07      152632  \n",
       "1      16470.00  16520.81  6695.136250  1.106669e+08      153933  \n",
       "2      16544.12  16548.28  3618.773890  5.992803e+07      105065  \n",
       "3      16564.09  16568.60  2622.143550  4.344849e+07       90705  \n",
       "4      16565.10  16570.14  4044.433590  6.704605e+07      116587  \n",
       "...         ...       ...          ...           ...         ...  \n",
       "26269   7215.03   7217.27   467.812578  3.379094e+06        5896  \n",
       "26270   7220.00   7225.01   783.724867  5.667367e+06        8337  \n",
       "26271   7211.41   7242.85   655.156809  4.736719e+06        7466  \n",
       "26272   7175.71   7216.27   883.052603  6.365953e+06        9033  \n",
       "26273   7175.46   7177.02   511.814901  3.675857e+06        7640  \n",
       "\n",
       "[26274 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth_dfd = pd.read_csv('../Dataset/Binance_ETHUSDT_1h.csv')\n",
    "eth_dfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41062755-9cca-4348-91bc-e80d46b79c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume USDT</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7195.24</td>\n",
       "      <td>7196.25</td>\n",
       "      <td>7175.46</td>\n",
       "      <td>3.675857e+06</td>\n",
       "      <td>7177.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7176.47</td>\n",
       "      <td>7230.00</td>\n",
       "      <td>7175.71</td>\n",
       "      <td>6.365953e+06</td>\n",
       "      <td>7216.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7215.52</td>\n",
       "      <td>7244.87</td>\n",
       "      <td>7211.41</td>\n",
       "      <td>4.736719e+06</td>\n",
       "      <td>7242.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7242.66</td>\n",
       "      <td>7245.00</td>\n",
       "      <td>7220.00</td>\n",
       "      <td>5.667367e+06</td>\n",
       "      <td>7225.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7225.00</td>\n",
       "      <td>7230.00</td>\n",
       "      <td>7215.03</td>\n",
       "      <td>3.379094e+06</td>\n",
       "      <td>7217.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26269</th>\n",
       "      <td>16577.78</td>\n",
       "      <td>16590.06</td>\n",
       "      <td>16565.10</td>\n",
       "      <td>6.704605e+07</td>\n",
       "      <td>16570.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>16570.14</td>\n",
       "      <td>16574.97</td>\n",
       "      <td>16564.09</td>\n",
       "      <td>4.344849e+07</td>\n",
       "      <td>16568.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26271</th>\n",
       "      <td>16568.19</td>\n",
       "      <td>16571.64</td>\n",
       "      <td>16544.12</td>\n",
       "      <td>5.992803e+07</td>\n",
       "      <td>16548.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>16548.28</td>\n",
       "      <td>16567.49</td>\n",
       "      <td>16470.00</td>\n",
       "      <td>1.106669e+08</td>\n",
       "      <td>16520.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26273</th>\n",
       "      <td>16520.28</td>\n",
       "      <td>16551.24</td>\n",
       "      <td>16487.74</td>\n",
       "      <td>8.217183e+07</td>\n",
       "      <td>16542.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26274 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open      High       Low   Volume USDT     Close\n",
       "0       7195.24   7196.25   7175.46  3.675857e+06   7177.02\n",
       "1       7176.47   7230.00   7175.71  6.365953e+06   7216.27\n",
       "2       7215.52   7244.87   7211.41  4.736719e+06   7242.85\n",
       "3       7242.66   7245.00   7220.00  5.667367e+06   7225.01\n",
       "4       7225.00   7230.00   7215.03  3.379094e+06   7217.27\n",
       "...         ...       ...       ...           ...       ...\n",
       "26269  16577.78  16590.06  16565.10  6.704605e+07  16570.14\n",
       "26270  16570.14  16574.97  16564.09  4.344849e+07  16568.60\n",
       "26271  16568.19  16571.64  16544.12  5.992803e+07  16548.28\n",
       "26272  16548.28  16567.49  16470.00  1.106669e+08  16520.81\n",
       "26273  16520.28  16551.24  16487.74  8.217183e+07  16542.40\n",
       "\n",
       "[26274 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Preprocessing.feature_selection(eth_dfd)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc368c1b-a82f-4dbf-85c4-f19ebff7a21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume USDT</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7195.24</td>\n",
       "      <td>7196.25</td>\n",
       "      <td>7175.46</td>\n",
       "      <td>3.675857e+06</td>\n",
       "      <td>7177.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7176.47</td>\n",
       "      <td>7230.00</td>\n",
       "      <td>7175.71</td>\n",
       "      <td>6.365953e+06</td>\n",
       "      <td>7216.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7215.52</td>\n",
       "      <td>7244.87</td>\n",
       "      <td>7211.41</td>\n",
       "      <td>4.736719e+06</td>\n",
       "      <td>7242.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7242.66</td>\n",
       "      <td>7245.00</td>\n",
       "      <td>7220.00</td>\n",
       "      <td>5.667367e+06</td>\n",
       "      <td>7225.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7225.00</td>\n",
       "      <td>7230.00</td>\n",
       "      <td>7215.03</td>\n",
       "      <td>3.379094e+06</td>\n",
       "      <td>7217.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26269</th>\n",
       "      <td>16577.78</td>\n",
       "      <td>16590.06</td>\n",
       "      <td>16565.10</td>\n",
       "      <td>6.704605e+07</td>\n",
       "      <td>16570.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>16570.14</td>\n",
       "      <td>16574.97</td>\n",
       "      <td>16564.09</td>\n",
       "      <td>4.344849e+07</td>\n",
       "      <td>16568.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26271</th>\n",
       "      <td>16568.19</td>\n",
       "      <td>16571.64</td>\n",
       "      <td>16544.12</td>\n",
       "      <td>5.992803e+07</td>\n",
       "      <td>16548.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>16548.28</td>\n",
       "      <td>16567.49</td>\n",
       "      <td>16470.00</td>\n",
       "      <td>1.106669e+08</td>\n",
       "      <td>16520.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26273</th>\n",
       "      <td>16520.28</td>\n",
       "      <td>16551.24</td>\n",
       "      <td>16487.74</td>\n",
       "      <td>8.217183e+07</td>\n",
       "      <td>16542.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26274 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open      High       Low   Volume USDT     Close\n",
       "0       7195.24   7196.25   7175.46  3.675857e+06   7177.02\n",
       "1       7176.47   7230.00   7175.71  6.365953e+06   7216.27\n",
       "2       7215.52   7244.87   7211.41  4.736719e+06   7242.85\n",
       "3       7242.66   7245.00   7220.00  5.667367e+06   7225.01\n",
       "4       7225.00   7230.00   7215.03  3.379094e+06   7217.27\n",
       "...         ...       ...       ...           ...       ...\n",
       "26269  16577.78  16590.06  16565.10  6.704605e+07  16570.14\n",
       "26270  16570.14  16574.97  16564.09  4.344849e+07  16568.60\n",
       "26271  16568.19  16571.64  16544.12  5.992803e+07  16548.28\n",
       "26272  16548.28  16567.49  16470.00  1.106669e+08  16520.81\n",
       "26273  16520.28  16551.24  16487.74  8.217183e+07  16542.40\n",
       "\n",
       "[26274 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_dup = Preprocessing.handle_duplicate(df)\n",
    "df_no_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "483f3731-9efb-47c6-af9c-6eadc95287e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss = Preprocessing.handle_missing_value(df_no_dup)\n",
    "miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "140ecfee-f8cf-45f6-b3c6-49e8e7458101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04750117, 0.0401654 , 0.05247223, 0.00122299, 0.04722846],\n",
       "       [0.04721018, 0.04068955, 0.0524761 , 0.00211801, 0.04783696],\n",
       "       [0.04781557, 0.04092048, 0.05302814, 0.00157595, 0.04824904],\n",
       "       ...,\n",
       "       [0.19280946, 0.1857686 , 0.19734306, 0.01993857, 0.19251245],\n",
       "       [0.19250079, 0.18570415, 0.19619691, 0.03681983, 0.19208658],\n",
       "       [0.19206671, 0.18545178, 0.19647123, 0.02733927, 0.19242129]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, scaler = Preprocessing.minmax_scale(df_no_dup)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c42a7847-70b8-4487-a874-67e370666724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04750117, 0.0401654 , 0.05247223, 0.00122299, 0.04722846],\n",
       "       [0.04721018, 0.04068955, 0.0524761 , 0.00211801, 0.04783696],\n",
       "       [0.04781557, 0.04092048, 0.05302814, 0.00157595, 0.04824904],\n",
       "       ...,\n",
       "       [0.39451404, 0.38918512, 0.39751838, 0.01247029, 0.39344233],\n",
       "       [0.39342821, 0.38742771, 0.39264325, 0.02946575, 0.3886748 ],\n",
       "       [0.38866059, 0.38484765, 0.39034385, 0.03564371, 0.38670838]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = Preprocessing.splitting_data(x)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8e525a6-83d0-4c8b-9875-33e0e15480ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38669404, 0.3808301 , 0.38809703, 0.0406164 , 0.38493033],\n",
       "       [0.38491617, 0.38016586, 0.38748453, 0.03251634, 0.38538193],\n",
       "       [0.38536761, 0.38119677, 0.38950296, 0.01847402, 0.38586346],\n",
       "       ...,\n",
       "       [0.19280946, 0.1857686 , 0.19734306, 0.01993857, 0.19251245],\n",
       "       [0.19250079, 0.18570415, 0.19619691, 0.03681983, 0.19208658],\n",
       "       [0.19206671, 0.18545178, 0.19647123, 0.02733927, 0.19242129]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08213717-a303-4c9e-97bb-280204035109",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = Preprocessing.create_dataset(train,5)\n",
    "test_X, test_y = Preprocessing.create_dataset(test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aff76bd7-16f2-4bf2-8a64-f1f6a1194661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.04750117, 0.0401654 , 0.05247223, 0.00122299, 0.04722846],\n",
       "        [0.04721018, 0.04068955, 0.0524761 , 0.00211801, 0.04783696],\n",
       "        [0.04781557, 0.04092048, 0.05302814, 0.00157595, 0.04824904],\n",
       "        [0.04823632, 0.0409225 , 0.05316097, 0.00188558, 0.04797246],\n",
       "        [0.04796253, 0.04068955, 0.05308412, 0.00112425, 0.04785247]],\n",
       "\n",
       "       [[0.04721018, 0.04068955, 0.0524761 , 0.00211801, 0.04783696],\n",
       "        [0.04781557, 0.04092048, 0.05302814, 0.00157595, 0.04824904],\n",
       "        [0.04823632, 0.0409225 , 0.05316097, 0.00188558, 0.04797246],\n",
       "        [0.04796253, 0.04068955, 0.05308412, 0.00112425, 0.04785247],\n",
       "        [0.04784254, 0.04068582, 0.05310917, 0.00082828, 0.04796006]],\n",
       "\n",
       "       [[0.04781557, 0.04092048, 0.05302814, 0.00157595, 0.04824904],\n",
       "        [0.04823632, 0.0409225 , 0.05316097, 0.00188558, 0.04797246],\n",
       "        [0.04796253, 0.04068955, 0.05308412, 0.00112425, 0.04785247],\n",
       "        [0.04784254, 0.04068582, 0.05310917, 0.00082828, 0.04796006],\n",
       "        [0.04795075, 0.04078692, 0.05318432, 0.00149488, 0.04798192]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.3946286 , 0.38931449, 0.39714015, 0.02031909, 0.39545386],\n",
       "        [0.39543941, 0.38881488, 0.39737488, 0.02178632, 0.3949359 ],\n",
       "        [0.39492161, 0.38841109, 0.39572587, 0.02434051, 0.39144071],\n",
       "        [0.39142647, 0.3880059 , 0.39436169, 0.01783611, 0.39268484],\n",
       "        [0.39267058, 0.38939028, 0.39706577, 0.01464281, 0.39452832]],\n",
       "\n",
       "       [[0.39543941, 0.38881488, 0.39737488, 0.02178632, 0.3949359 ],\n",
       "        [0.39492161, 0.38841109, 0.39572587, 0.02434051, 0.39144071],\n",
       "        [0.39142647, 0.3880059 , 0.39436169, 0.01783611, 0.39268484],\n",
       "        [0.39267058, 0.38939028, 0.39706577, 0.01464281, 0.39452832],\n",
       "        [0.39451404, 0.38918512, 0.39751838, 0.01247029, 0.39344233]],\n",
       "\n",
       "       [[0.39492161, 0.38841109, 0.39572587, 0.02434051, 0.39144071],\n",
       "        [0.39142647, 0.3880059 , 0.39436169, 0.01783611, 0.39268484],\n",
       "        [0.39267058, 0.38939028, 0.39706577, 0.01464281, 0.39452832],\n",
       "        [0.39451404, 0.38918512, 0.39751838, 0.01247029, 0.39344233],\n",
       "        [0.39342821, 0.38742771, 0.39264325, 0.02946575, 0.3886748 ]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4efa14c4-f85e-47c3-bc04-7f0d029d3a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04796006, 0.04798192, 0.04773712, ..., 0.39344233, 0.3886748 ,\n",
       "       0.38670838])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51dc56af-5903-45ab-a70b-556fb3f3d97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.38669404, 0.3808301 , 0.38809703, 0.0406164 , 0.38493033],\n",
       "        [0.38491617, 0.38016586, 0.38748453, 0.03251634, 0.38538193],\n",
       "        [0.38536761, 0.38119677, 0.38950296, 0.01847402, 0.38586346],\n",
       "        [0.38584929, 0.38055428, 0.38798971, 0.02809654, 0.38442601],\n",
       "        [0.38441201, 0.37958689, 0.38444598, 0.06968765, 0.38245246]],\n",
       "\n",
       "       [[0.38491617, 0.38016586, 0.38748453, 0.03251634, 0.38538193],\n",
       "        [0.38536761, 0.38119677, 0.38950296, 0.01847402, 0.38586346],\n",
       "        [0.38584929, 0.38055428, 0.38798971, 0.02809654, 0.38442601],\n",
       "        [0.38441201, 0.37958689, 0.38444598, 0.06968765, 0.38245246],\n",
       "        [0.38243833, 0.37939121, 0.38454046, 0.07592605, 0.38515838]],\n",
       "\n",
       "       [[0.38536761, 0.38119677, 0.38950296, 0.01847402, 0.38586346],\n",
       "        [0.38584929, 0.38055428, 0.38798971, 0.02809654, 0.38442601],\n",
       "        [0.38441201, 0.37958689, 0.38444598, 0.06968765, 0.38245246],\n",
       "        [0.38243833, 0.37939121, 0.38454046, 0.07592605, 0.38515838],\n",
       "        [0.38514421, 0.38210902, 0.38840892, 0.03432136, 0.38544456]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.19314913, 0.18641559, 0.19791706, 0.02357757, 0.19332032],\n",
       "        [0.19331702, 0.18627691, 0.19775887, 0.02673015, 0.19303645],\n",
       "        [0.19301503, 0.1860438 , 0.19777108, 0.01842876, 0.19296994],\n",
       "        [0.19295813, 0.18605467, 0.19766748, 0.02230679, 0.19285135],\n",
       "        [0.19283969, 0.18582031, 0.19765186, 0.01445568, 0.19282747]],\n",
       "\n",
       "       [[0.19331702, 0.18627691, 0.19775887, 0.02673015, 0.19303645],\n",
       "        [0.19301503, 0.1860438 , 0.19777108, 0.01842876, 0.19296994],\n",
       "        [0.19295813, 0.18605467, 0.19766748, 0.02230679, 0.19285135],\n",
       "        [0.19283969, 0.18582031, 0.19765186, 0.01445568, 0.19282747],\n",
       "        [0.19280946, 0.1857686 , 0.19734306, 0.01993857, 0.19251245]],\n",
       "\n",
       "       [[0.19301503, 0.1860438 , 0.19777108, 0.01842876, 0.19296994],\n",
       "        [0.19295813, 0.18605467, 0.19766748, 0.02230679, 0.19285135],\n",
       "        [0.19283969, 0.18582031, 0.19765186, 0.01445568, 0.19282747],\n",
       "        [0.19280946, 0.1857686 , 0.19734306, 0.01993857, 0.19251245],\n",
       "        [0.19250079, 0.18570415, 0.19619691, 0.03681983, 0.19208658]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d98152d5-e8c5-4645-90ea-876a042b25e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38515838, 0.38544456, 0.38463778, ..., 0.19251245, 0.19208658,\n",
       "       0.19242129])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d80df0f9-fe70-44f0-bef3-b779d95da0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21014, 5, 5) (21014,) (5250, 5, 5) (5250,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf43011a-1b18-4fef-b638-d84109a5347b",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c6e3c5f-f40b-427b-bbf6-715de9fbfed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 100, 50),\n",
       " (32, 100, 60),\n",
       " (32, 100, 100),\n",
       " (64, 100, 50),\n",
       " (64, 100, 60),\n",
       " (64, 100, 100),\n",
       " (128, 100, 50),\n",
       " (128, 100, 60),\n",
       " (128, 100, 100)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams = []\n",
    "batch = [32, 64, 128]\n",
    "epoch = [100]\n",
    "neuron = [50, 60, 100]\n",
    "for j in batch:\n",
    "    for k in epoch:\n",
    "        for l in neuron:\n",
    "            hyperparams.append((j,k,l))\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ffd8dc1-5eb8-4d7e-aba2-cab78df020ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 22:20:34.826559: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-20 22:20:34.826913: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 22:20:35.063706: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-03-20 22:20:36.024194: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:20:36.165980: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:20:36.178033: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:20:36.333700: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:20:36.349911: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:20:44.708673: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:20:44.758885: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:20:44.767844: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 - 11s - loss: 2.6271e-04 - val_loss: 4.9956e-04 - 11s/epoch - 16ms/step\n",
      "Epoch 2/100\n",
      "657/657 - 9s - loss: 2.6440e-04 - val_loss: 3.2082e-04 - 9s/epoch - 13ms/step\n",
      "Epoch 3/100\n",
      "657/657 - 9s - loss: 3.6322e-04 - val_loss: 1.4968e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 4/100\n",
      "657/657 - 9s - loss: 5.1037e-04 - val_loss: 3.1450e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 5/100\n",
      "657/657 - 10s - loss: 9.0931e-04 - val_loss: 8.5830e-04 - 10s/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "657/657 - 9s - loss: 8.3779e-04 - val_loss: 6.3831e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 7/100\n",
      "657/657 - 9s - loss: 6.7702e-04 - val_loss: 3.6544e-04 - 9s/epoch - 13ms/step\n",
      "Epoch 8/100\n",
      "657/657 - 9s - loss: 5.5464e-04 - val_loss: 1.8793e-04 - 9s/epoch - 13ms/step\n",
      "Epoch 9/100\n",
      "657/657 - 9s - loss: 4.6853e-04 - val_loss: 9.3994e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 10/100\n",
      "657/657 - 9s - loss: 4.0807e-04 - val_loss: 5.2184e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 11/100\n",
      "657/657 - 9s - loss: 3.6415e-04 - val_loss: 3.6931e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "657/657 - 9s - loss: 3.3261e-04 - val_loss: 3.3130e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "657/657 - 9s - loss: 3.0872e-04 - val_loss: 3.2958e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "657/657 - 9s - loss: 2.9167e-04 - val_loss: 3.3237e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "657/657 - 9s - loss: 2.7940e-04 - val_loss: 3.3082e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "657/657 - 9s - loss: 2.6858e-04 - val_loss: 3.2701e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 17/100\n",
      "657/657 - 9s - loss: 2.5875e-04 - val_loss: 3.1886e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 18/100\n",
      "657/657 - 9s - loss: 2.4968e-04 - val_loss: 3.0816e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 19/100\n",
      "657/657 - 9s - loss: 2.4149e-04 - val_loss: 2.9555e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 20/100\n",
      "657/657 - 9s - loss: 2.3290e-04 - val_loss: 2.8322e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 21/100\n",
      "657/657 - 9s - loss: 2.2457e-04 - val_loss: 2.7105e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 22/100\n",
      "657/657 - 9s - loss: 2.1704e-04 - val_loss: 2.5840e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "657/657 - 9s - loss: 2.1013e-04 - val_loss: 2.4677e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "657/657 - 9s - loss: 2.0372e-04 - val_loss: 2.3575e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 25/100\n",
      "657/657 - 9s - loss: 1.9745e-04 - val_loss: 2.2568e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 26/100\n",
      "657/657 - 9s - loss: 1.9175e-04 - val_loss: 2.1650e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "657/657 - 9s - loss: 1.8640e-04 - val_loss: 2.0808e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 28/100\n",
      "657/657 - 9s - loss: 1.8138e-04 - val_loss: 2.0071e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 29/100\n",
      "657/657 - 9s - loss: 1.7664e-04 - val_loss: 1.9377e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 30/100\n",
      "657/657 - 9s - loss: 1.7219e-04 - val_loss: 1.8726e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 31/100\n",
      "657/657 - 9s - loss: 1.6784e-04 - val_loss: 1.8142e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 32/100\n",
      "657/657 - 9s - loss: 1.6366e-04 - val_loss: 1.7663e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 33/100\n",
      "657/657 - 9s - loss: 1.5975e-04 - val_loss: 1.7433e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 34/100\n",
      "657/657 - 9s - loss: 1.5597e-04 - val_loss: 1.7537e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 35/100\n",
      "657/657 - 9s - loss: 1.5236e-04 - val_loss: 1.8052e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 36/100\n",
      "657/657 - 9s - loss: 1.4892e-04 - val_loss: 1.9153e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 37/100\n",
      "657/657 - 9s - loss: 1.4589e-04 - val_loss: 2.0811e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 38/100\n",
      "657/657 - 9s - loss: 1.4318e-04 - val_loss: 2.2857e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 39/100\n",
      "657/657 - 9s - loss: 1.4073e-04 - val_loss: 2.5002e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 40/100\n",
      "657/657 - 10s - loss: 1.3845e-04 - val_loss: 2.7058e-05 - 10s/epoch - 14ms/step\n",
      "Epoch 41/100\n",
      "657/657 - 9s - loss: 1.3639e-04 - val_loss: 2.8605e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 42/100\n",
      "657/657 - 9s - loss: 1.3447e-04 - val_loss: 2.9502e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 43/100\n",
      "657/657 - 9s - loss: 1.3262e-04 - val_loss: 2.9880e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 44/100\n",
      "657/657 - 9s - loss: 1.3077e-04 - val_loss: 2.9851e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 45/100\n",
      "657/657 - 9s - loss: 1.2891e-04 - val_loss: 2.9500e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 46/100\n",
      "657/657 - 9s - loss: 1.2707e-04 - val_loss: 2.8867e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 47/100\n",
      "657/657 - 9s - loss: 1.2529e-04 - val_loss: 2.7919e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 48/100\n",
      "657/657 - 9s - loss: 1.2363e-04 - val_loss: 2.6651e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 49/100\n",
      "657/657 - 9s - loss: 1.2209e-04 - val_loss: 2.5113e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 50/100\n",
      "657/657 - 9s - loss: 1.2067e-04 - val_loss: 2.3403e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 51/100\n",
      "657/657 - 9s - loss: 1.1935e-04 - val_loss: 2.1614e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 52/100\n",
      "657/657 - 9s - loss: 1.1810e-04 - val_loss: 1.9891e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 53/100\n",
      "657/657 - 9s - loss: 1.1690e-04 - val_loss: 1.8455e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 54/100\n",
      "657/657 - 9s - loss: 1.1576e-04 - val_loss: 1.7432e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 55/100\n",
      "657/657 - 9s - loss: 1.1472e-04 - val_loss: 1.6693e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 56/100\n",
      "657/657 - 9s - loss: 1.1378e-04 - val_loss: 1.6120e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 57/100\n",
      "657/657 - 9s - loss: 1.1293e-04 - val_loss: 1.5674e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 58/100\n",
      "657/657 - 9s - loss: 1.1215e-04 - val_loss: 1.5360e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 59/100\n",
      "657/657 - 9s - loss: 1.1146e-04 - val_loss: 1.5199e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 60/100\n",
      "657/657 - 9s - loss: 1.1083e-04 - val_loss: 1.5237e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 61/100\n",
      "657/657 - 9s - loss: 1.1021e-04 - val_loss: 1.5499e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 62/100\n",
      "657/657 - 9s - loss: 1.0958e-04 - val_loss: 1.5974e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 63/100\n",
      "657/657 - 10s - loss: 1.0889e-04 - val_loss: 1.6607e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 64/100\n",
      "657/657 - 10s - loss: 1.0817e-04 - val_loss: 1.7334e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 65/100\n",
      "657/657 - 10s - loss: 1.0748e-04 - val_loss: 1.8106e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 66/100\n",
      "657/657 - 10s - loss: 1.0685e-04 - val_loss: 1.8904e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 67/100\n",
      "657/657 - 10s - loss: 1.0626e-04 - val_loss: 1.9711e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 68/100\n",
      "657/657 - 10s - loss: 1.0568e-04 - val_loss: 2.0530e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 69/100\n",
      "657/657 - 10s - loss: 1.0509e-04 - val_loss: 2.1340e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 70/100\n",
      "657/657 - 10s - loss: 1.0445e-04 - val_loss: 2.2175e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 71/100\n",
      "657/657 - 10s - loss: 1.0380e-04 - val_loss: 2.3000e-05 - 10s/epoch - 14ms/step\n",
      "Epoch 72/100\n",
      "657/657 - 10s - loss: 1.0314e-04 - val_loss: 2.3877e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 73/100\n",
      "657/657 - 10s - loss: 1.0250e-04 - val_loss: 2.4763e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 74/100\n",
      "657/657 - 10s - loss: 1.0186e-04 - val_loss: 2.5718e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 75/100\n",
      "657/657 - 10s - loss: 1.0123e-04 - val_loss: 2.6695e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 76/100\n",
      "657/657 - 10s - loss: 1.0059e-04 - val_loss: 2.7727e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 77/100\n",
      "657/657 - 10s - loss: 9.9925e-05 - val_loss: 2.8794e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 78/100\n",
      "657/657 - 10s - loss: 9.9249e-05 - val_loss: 2.9912e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 79/100\n",
      "657/657 - 10s - loss: 9.8577e-05 - val_loss: 3.1071e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 80/100\n",
      "657/657 - 10s - loss: 9.7921e-05 - val_loss: 3.2282e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 81/100\n",
      "657/657 - 9s - loss: 9.7291e-05 - val_loss: 3.3556e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 82/100\n",
      "657/657 - 10s - loss: 9.6648e-05 - val_loss: 3.4827e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 83/100\n",
      "657/657 - 10s - loss: 9.6006e-05 - val_loss: 3.6147e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 84/100\n",
      "657/657 - 10s - loss: 9.5366e-05 - val_loss: 3.7490e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 85/100\n",
      "657/657 - 10s - loss: 9.4731e-05 - val_loss: 3.8877e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 86/100\n",
      "657/657 - 10s - loss: 9.4117e-05 - val_loss: 4.0276e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 87/100\n",
      "657/657 - 10s - loss: 9.3510e-05 - val_loss: 4.1658e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 88/100\n",
      "657/657 - 10s - loss: 9.2912e-05 - val_loss: 4.3058e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 89/100\n",
      "657/657 - 10s - loss: 9.2310e-05 - val_loss: 4.4398e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 90/100\n",
      "657/657 - 10s - loss: 9.1698e-05 - val_loss: 4.5703e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 91/100\n",
      "657/657 - 10s - loss: 9.1090e-05 - val_loss: 4.6977e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 92/100\n",
      "657/657 - 10s - loss: 9.0495e-05 - val_loss: 4.8225e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 93/100\n",
      "657/657 - 10s - loss: 8.9922e-05 - val_loss: 4.9451e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 94/100\n",
      "657/657 - 10s - loss: 8.9361e-05 - val_loss: 5.0650e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 95/100\n",
      "657/657 - 10s - loss: 8.8798e-05 - val_loss: 5.1809e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 96/100\n",
      "657/657 - 10s - loss: 8.8229e-05 - val_loss: 5.2923e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 97/100\n",
      "657/657 - 10s - loss: 8.7656e-05 - val_loss: 5.3999e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 98/100\n",
      "657/657 - 10s - loss: 8.7083e-05 - val_loss: 5.5032e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 99/100\n",
      "657/657 - 10s - loss: 8.6521e-05 - val_loss: 5.6047e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 100/100\n",
      "657/657 - 10s - loss: 8.5959e-05 - val_loss: 5.7015e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 22:36:20.190907: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:36:20.371827: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:36:20.391044: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:36:20.524419: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:36:20.546172: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:36:29.763900: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:36:29.817995: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:36:29.828261: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 - 12s - loss: 1.4845e-04 - val_loss: 9.2481e-04 - 12s/epoch - 18ms/step\n",
      "Epoch 2/100\n",
      "657/657 - 10s - loss: 1.9316e-04 - val_loss: 5.3831e-04 - 10s/epoch - 15ms/step\n",
      "Epoch 3/100\n",
      "657/657 - 10s - loss: 2.0414e-04 - val_loss: 3.2500e-04 - 10s/epoch - 15ms/step\n",
      "Epoch 4/100\n",
      "657/657 - 10s - loss: 2.5329e-04 - val_loss: 3.6687e-04 - 10s/epoch - 15ms/step\n",
      "Epoch 5/100\n",
      "657/657 - 10s - loss: 3.5959e-04 - val_loss: 1.7771e-04 - 10s/epoch - 15ms/step\n",
      "Epoch 6/100\n",
      "657/657 - 10s - loss: 4.7990e-04 - val_loss: 3.2601e-04 - 10s/epoch - 15ms/step\n",
      "Epoch 7/100\n",
      "657/657 - 10s - loss: 8.4799e-04 - val_loss: 9.1135e-04 - 10s/epoch - 15ms/step\n",
      "Epoch 8/100\n",
      "657/657 - 10s - loss: 8.0568e-04 - val_loss: 7.4209e-04 - 10s/epoch - 15ms/step\n",
      "Epoch 9/100\n",
      "657/657 - 10s - loss: 6.4414e-04 - val_loss: 4.4257e-04 - 10s/epoch - 14ms/step\n",
      "Epoch 10/100\n",
      "657/657 - 9s - loss: 5.2179e-04 - val_loss: 2.3228e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 11/100\n",
      "657/657 - 9s - loss: 4.3456e-04 - val_loss: 1.1655e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 12/100\n",
      "657/657 - 9s - loss: 3.7499e-04 - val_loss: 6.2907e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "657/657 - 9s - loss: 3.3354e-04 - val_loss: 4.2142e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "657/657 - 10s - loss: 3.0503e-04 - val_loss: 3.5590e-05 - 10s/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "657/657 - 9s - loss: 2.8473e-04 - val_loss: 3.4133e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "657/657 - 10s - loss: 2.7035e-04 - val_loss: 3.3955e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 17/100\n",
      "657/657 - 9s - loss: 2.5970e-04 - val_loss: 3.4142e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 18/100\n",
      "657/657 - 10s - loss: 2.5119e-04 - val_loss: 3.4292e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 19/100\n",
      "657/657 - 9s - loss: 2.4265e-04 - val_loss: 3.4156e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 20/100\n",
      "657/657 - 9s - loss: 2.3500e-04 - val_loss: 3.4001e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 21/100\n",
      "657/657 - 9s - loss: 2.2720e-04 - val_loss: 3.3411e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 22/100\n",
      "657/657 - 9s - loss: 2.1905e-04 - val_loss: 3.2677e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "657/657 - 9s - loss: 2.1192e-04 - val_loss: 3.2011e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "657/657 - 9s - loss: 2.0529e-04 - val_loss: 3.1240e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 25/100\n",
      "657/657 - 9s - loss: 1.9951e-04 - val_loss: 3.0615e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 26/100\n",
      "657/657 - 9s - loss: 1.9433e-04 - val_loss: 3.0013e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "657/657 - 9s - loss: 1.8984e-04 - val_loss: 2.9332e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 28/100\n",
      "657/657 - 9s - loss: 1.8573e-04 - val_loss: 2.8918e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 29/100\n",
      "657/657 - 10s - loss: 1.8188e-04 - val_loss: 2.8301e-05 - 10s/epoch - 14ms/step\n",
      "Epoch 30/100\n",
      "657/657 - 9s - loss: 1.7802e-04 - val_loss: 2.7760e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 31/100\n",
      "657/657 - 9s - loss: 1.7440e-04 - val_loss: 2.6904e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 32/100\n",
      "657/657 - 9s - loss: 1.7022e-04 - val_loss: 2.6205e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 33/100\n",
      "657/657 - 10s - loss: 1.6629e-04 - val_loss: 2.5371e-05 - 10s/epoch - 14ms/step\n",
      "Epoch 34/100\n",
      "657/657 - 9s - loss: 1.6283e-04 - val_loss: 2.4806e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 35/100\n",
      "657/657 - 9s - loss: 1.5998e-04 - val_loss: 2.4304e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 36/100\n",
      "657/657 - 9s - loss: 1.5740e-04 - val_loss: 2.3903e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 37/100\n",
      "657/657 - 9s - loss: 1.5506e-04 - val_loss: 2.3619e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 38/100\n",
      "657/657 - 9s - loss: 1.5281e-04 - val_loss: 2.3273e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 39/100\n",
      "657/657 - 9s - loss: 1.5050e-04 - val_loss: 2.2982e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 40/100\n",
      "657/657 - 10s - loss: 1.4820e-04 - val_loss: 2.2743e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 41/100\n",
      "657/657 - 9s - loss: 1.4590e-04 - val_loss: 2.2591e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 42/100\n",
      "657/657 - 10s - loss: 1.4366e-04 - val_loss: 2.2622e-05 - 10s/epoch - 14ms/step\n",
      "Epoch 43/100\n",
      "657/657 - 9s - loss: 1.4155e-04 - val_loss: 2.2768e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 44/100\n",
      "657/657 - 9s - loss: 1.3960e-04 - val_loss: 2.3011e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 45/100\n",
      "657/657 - 10s - loss: 1.3761e-04 - val_loss: 2.3290e-05 - 10s/epoch - 14ms/step\n",
      "Epoch 46/100\n",
      "657/657 - 9s - loss: 1.3571e-04 - val_loss: 2.3652e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 47/100\n",
      "657/657 - 9s - loss: 1.3391e-04 - val_loss: 2.4070e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 48/100\n",
      "657/657 - 10s - loss: 1.3211e-04 - val_loss: 2.4567e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 49/100\n",
      "657/657 - 10s - loss: 1.3039e-04 - val_loss: 2.5174e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 50/100\n",
      "657/657 - 10s - loss: 1.2870e-04 - val_loss: 2.5838e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 51/100\n",
      "657/657 - 10s - loss: 1.2705e-04 - val_loss: 2.6534e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 52/100\n",
      "657/657 - 10s - loss: 1.2538e-04 - val_loss: 2.7244e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 53/100\n",
      "657/657 - 10s - loss: 1.2368e-04 - val_loss: 2.8010e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 54/100\n",
      "657/657 - 10s - loss: 1.2202e-04 - val_loss: 2.8826e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 55/100\n",
      "657/657 - 10s - loss: 1.2040e-04 - val_loss: 2.9741e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 56/100\n",
      "657/657 - 10s - loss: 1.1886e-04 - val_loss: 3.0700e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 57/100\n",
      "657/657 - 10s - loss: 1.1732e-04 - val_loss: 3.1662e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 58/100\n",
      "657/657 - 10s - loss: 1.1575e-04 - val_loss: 3.2641e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 59/100\n",
      "657/657 - 10s - loss: 1.1415e-04 - val_loss: 3.3628e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 60/100\n",
      "657/657 - 10s - loss: 1.1260e-04 - val_loss: 3.4583e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 61/100\n",
      "657/657 - 10s - loss: 1.1107e-04 - val_loss: 3.5561e-05 - 10s/epoch - 14ms/step\n",
      "Epoch 62/100\n",
      "657/657 - 9s - loss: 1.0956e-04 - val_loss: 3.6552e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 63/100\n",
      "657/657 - 8s - loss: 1.0808e-04 - val_loss: 3.7567e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 64/100\n",
      "657/657 - 8s - loss: 1.0660e-04 - val_loss: 3.8510e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 65/100\n",
      "657/657 - 8s - loss: 1.0513e-04 - val_loss: 3.9462e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 66/100\n",
      "657/657 - 8s - loss: 1.0371e-04 - val_loss: 4.0403e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 67/100\n",
      "657/657 - 8s - loss: 1.0233e-04 - val_loss: 4.1377e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 68/100\n",
      "657/657 - 8s - loss: 1.0095e-04 - val_loss: 4.2293e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 69/100\n",
      "657/657 - 8s - loss: 9.9609e-05 - val_loss: 4.3170e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 70/100\n",
      "657/657 - 8s - loss: 9.8340e-05 - val_loss: 4.4054e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 71/100\n",
      "657/657 - 8s - loss: 9.7117e-05 - val_loss: 4.4736e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 72/100\n",
      "657/657 - 8s - loss: 9.5883e-05 - val_loss: 4.5396e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 73/100\n",
      "657/657 - 8s - loss: 9.4707e-05 - val_loss: 4.5933e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 74/100\n",
      "657/657 - 8s - loss: 9.3557e-05 - val_loss: 4.6391e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 75/100\n",
      "657/657 - 8s - loss: 9.2414e-05 - val_loss: 4.6661e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 76/100\n",
      "657/657 - 8s - loss: 9.1299e-05 - val_loss: 4.6932e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 77/100\n",
      "657/657 - 8s - loss: 9.0197e-05 - val_loss: 4.7116e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 78/100\n",
      "657/657 - 8s - loss: 8.9105e-05 - val_loss: 4.7285e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 79/100\n",
      "657/657 - 8s - loss: 8.8066e-05 - val_loss: 4.7456e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 80/100\n",
      "657/657 - 8s - loss: 8.7073e-05 - val_loss: 4.7641e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 81/100\n",
      "657/657 - 8s - loss: 8.6116e-05 - val_loss: 4.7792e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 82/100\n",
      "657/657 - 8s - loss: 8.5210e-05 - val_loss: 4.7966e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 83/100\n",
      "657/657 - 8s - loss: 8.4350e-05 - val_loss: 4.8136e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 84/100\n",
      "657/657 - 8s - loss: 8.3533e-05 - val_loss: 4.8278e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 85/100\n",
      "657/657 - 8s - loss: 8.2765e-05 - val_loss: 4.8423e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 86/100\n",
      "657/657 - 8s - loss: 8.2046e-05 - val_loss: 4.8567e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 87/100\n",
      "657/657 - 8s - loss: 8.1362e-05 - val_loss: 4.8721e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 88/100\n",
      "657/657 - 8s - loss: 8.0694e-05 - val_loss: 4.8916e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 89/100\n",
      "657/657 - 8s - loss: 8.0061e-05 - val_loss: 4.9181e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 90/100\n",
      "657/657 - 8s - loss: 7.9488e-05 - val_loss: 4.9591e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 91/100\n",
      "657/657 - 8s - loss: 7.8960e-05 - val_loss: 5.0098e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 92/100\n",
      "657/657 - 8s - loss: 7.8467e-05 - val_loss: 5.0699e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 93/100\n",
      "657/657 - 8s - loss: 7.7984e-05 - val_loss: 5.1367e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 94/100\n",
      "657/657 - 8s - loss: 7.7496e-05 - val_loss: 5.2097e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 95/100\n",
      "657/657 - 8s - loss: 7.7010e-05 - val_loss: 5.2873e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 96/100\n",
      "657/657 - 8s - loss: 7.6531e-05 - val_loss: 5.3745e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 97/100\n",
      "657/657 - 8s - loss: 7.6068e-05 - val_loss: 5.4675e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 98/100\n",
      "657/657 - 8s - loss: 7.5625e-05 - val_loss: 5.5698e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 99/100\n",
      "657/657 - 8s - loss: 7.5203e-05 - val_loss: 5.6825e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 100/100\n",
      "657/657 - 8s - loss: 7.4792e-05 - val_loss: 5.7996e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 22:51:14.114495: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:51:14.252927: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:51:14.264334: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:51:14.370930: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:51:14.386000: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:51:22.007678: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:51:22.052975: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 22:51:22.061508: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 - 10s - loss: 1.2895e-04 - val_loss: 7.2252e-04 - 10s/epoch - 15ms/step\n",
      "Epoch 2/100\n",
      "657/657 - 8s - loss: 1.9095e-04 - val_loss: 7.3455e-04 - 8s/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "657/657 - 8s - loss: 2.1235e-04 - val_loss: 7.9905e-04 - 8s/epoch - 12ms/step\n",
      "Epoch 4/100\n",
      "657/657 - 8s - loss: 2.2747e-04 - val_loss: 6.0840e-04 - 8s/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "657/657 - 8s - loss: 2.5298e-04 - val_loss: 5.3582e-04 - 8s/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "657/657 - 8s - loss: 3.7719e-04 - val_loss: 3.0327e-04 - 8s/epoch - 12ms/step\n",
      "Epoch 7/100\n",
      "657/657 - 8s - loss: 4.6663e-04 - val_loss: 3.0094e-04 - 8s/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "657/657 - 8s - loss: 8.0986e-04 - val_loss: 9.4788e-04 - 8s/epoch - 13ms/step\n",
      "Epoch 9/100\n",
      "657/657 - 8s - loss: 0.0010 - val_loss: 0.0011 - 8s/epoch - 13ms/step\n",
      "Epoch 10/100\n",
      "657/657 - 8s - loss: 8.5653e-04 - val_loss: 7.2076e-04 - 8s/epoch - 13ms/step\n",
      "Epoch 11/100\n",
      "657/657 - 8s - loss: 6.9008e-04 - val_loss: 4.1104e-04 - 8s/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "657/657 - 8s - loss: 5.6147e-04 - val_loss: 2.1381e-04 - 8s/epoch - 13ms/step\n",
      "Epoch 13/100\n",
      "657/657 - 8s - loss: 4.6654e-04 - val_loss: 1.0600e-04 - 8s/epoch - 12ms/step\n",
      "Epoch 14/100\n",
      "657/657 - 8s - loss: 3.9974e-04 - val_loss: 5.5332e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "657/657 - 9s - loss: 3.5247e-04 - val_loss: 3.5667e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 16/100\n",
      "657/657 - 8s - loss: 3.1874e-04 - val_loss: 2.9790e-05 - 8s/epoch - 13ms/step\n",
      "Epoch 17/100\n",
      "657/657 - 8s - loss: 2.9452e-04 - val_loss: 2.8609e-05 - 8s/epoch - 13ms/step\n",
      "Epoch 18/100\n",
      "657/657 - 8s - loss: 2.7697e-04 - val_loss: 2.8634e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 19/100\n",
      "657/657 - 8s - loss: 2.6496e-04 - val_loss: 2.8951e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "657/657 - 8s - loss: 2.5701e-04 - val_loss: 2.9403e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 21/100\n",
      "657/657 - 8s - loss: 2.4862e-04 - val_loss: 2.9391e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 22/100\n",
      "657/657 - 8s - loss: 2.4010e-04 - val_loss: 2.9016e-05 - 8s/epoch - 13ms/step\n",
      "Epoch 23/100\n",
      "657/657 - 8s - loss: 2.3105e-04 - val_loss: 2.8376e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 24/100\n",
      "657/657 - 8s - loss: 2.2201e-04 - val_loss: 2.7491e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "657/657 - 8s - loss: 2.1355e-04 - val_loss: 2.6567e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 26/100\n",
      "657/657 - 8s - loss: 2.0591e-04 - val_loss: 2.5686e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 27/100\n",
      "657/657 - 8s - loss: 1.9909e-04 - val_loss: 2.4892e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 28/100\n",
      "657/657 - 8s - loss: 1.9303e-04 - val_loss: 2.4013e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 29/100\n",
      "657/657 - 8s - loss: 1.8719e-04 - val_loss: 2.3004e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "657/657 - 8s - loss: 1.8180e-04 - val_loss: 2.2038e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 31/100\n",
      "657/657 - 8s - loss: 1.7669e-04 - val_loss: 2.1215e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 32/100\n",
      "657/657 - 8s - loss: 1.7215e-04 - val_loss: 2.0600e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "657/657 - 8s - loss: 1.6793e-04 - val_loss: 2.0073e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 34/100\n",
      "657/657 - 8s - loss: 1.6411e-04 - val_loss: 1.9696e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 35/100\n",
      "657/657 - 8s - loss: 1.6036e-04 - val_loss: 1.9290e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 36/100\n",
      "657/657 - 8s - loss: 1.5668e-04 - val_loss: 1.8813e-05 - 8s/epoch - 13ms/step\n",
      "Epoch 37/100\n",
      "657/657 - 8s - loss: 1.5301e-04 - val_loss: 1.8365e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 38/100\n",
      "657/657 - 8s - loss: 1.4954e-04 - val_loss: 1.8003e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 39/100\n",
      "657/657 - 8s - loss: 1.4636e-04 - val_loss: 1.7630e-05 - 8s/epoch - 13ms/step\n",
      "Epoch 40/100\n",
      "657/657 - 8s - loss: 1.4347e-04 - val_loss: 1.7321e-05 - 8s/epoch - 13ms/step\n",
      "Epoch 41/100\n",
      "657/657 - 8s - loss: 1.4087e-04 - val_loss: 1.7040e-05 - 8s/epoch - 13ms/step\n",
      "Epoch 42/100\n",
      "657/657 - 8s - loss: 1.3832e-04 - val_loss: 1.6737e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 43/100\n",
      "657/657 - 8s - loss: 1.3586e-04 - val_loss: 1.6477e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 44/100\n",
      "657/657 - 8s - loss: 1.3349e-04 - val_loss: 1.6264e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 45/100\n",
      "657/657 - 8s - loss: 1.3120e-04 - val_loss: 1.6057e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 46/100\n",
      "657/657 - 8s - loss: 1.2908e-04 - val_loss: 1.5900e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 47/100\n",
      "657/657 - 8s - loss: 1.2711e-04 - val_loss: 1.5771e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 48/100\n",
      "657/657 - 8s - loss: 1.2531e-04 - val_loss: 1.5696e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 49/100\n",
      "657/657 - 8s - loss: 1.2367e-04 - val_loss: 1.5667e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 50/100\n",
      "657/657 - 8s - loss: 1.2217e-04 - val_loss: 1.5714e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 51/100\n",
      "657/657 - 8s - loss: 1.2077e-04 - val_loss: 1.5840e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 52/100\n",
      "657/657 - 8s - loss: 1.1946e-04 - val_loss: 1.6065e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 53/100\n",
      "657/657 - 8s - loss: 1.1822e-04 - val_loss: 1.6404e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 54/100\n",
      "657/657 - 8s - loss: 1.1706e-04 - val_loss: 1.6859e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 55/100\n",
      "657/657 - 8s - loss: 1.1595e-04 - val_loss: 1.7472e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 56/100\n",
      "657/657 - 8s - loss: 1.1487e-04 - val_loss: 1.8237e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 57/100\n",
      "657/657 - 8s - loss: 1.1383e-04 - val_loss: 1.9169e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 58/100\n",
      "657/657 - 8s - loss: 1.1284e-04 - val_loss: 2.0291e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 59/100\n",
      "657/657 - 8s - loss: 1.1192e-04 - val_loss: 2.1609e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 60/100\n",
      "657/657 - 8s - loss: 1.1101e-04 - val_loss: 2.3116e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 61/100\n",
      "657/657 - 8s - loss: 1.1016e-04 - val_loss: 2.4883e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 62/100\n",
      "657/657 - 8s - loss: 1.0937e-04 - val_loss: 2.6796e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 63/100\n",
      "657/657 - 8s - loss: 1.0864e-04 - val_loss: 2.8859e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 64/100\n",
      "657/657 - 8s - loss: 1.0791e-04 - val_loss: 3.0960e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 65/100\n",
      "657/657 - 8s - loss: 1.0721e-04 - val_loss: 3.2963e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 66/100\n",
      "657/657 - 8s - loss: 1.0655e-04 - val_loss: 3.4902e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 67/100\n",
      "657/657 - 8s - loss: 1.0589e-04 - val_loss: 3.6477e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 68/100\n",
      "657/657 - 8s - loss: 1.0524e-04 - val_loss: 3.7985e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 69/100\n",
      "657/657 - 8s - loss: 1.0455e-04 - val_loss: 3.9133e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 70/100\n",
      "657/657 - 8s - loss: 1.0379e-04 - val_loss: 4.0402e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 71/100\n",
      "657/657 - 8s - loss: 1.0298e-04 - val_loss: 4.1584e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 72/100\n",
      "657/657 - 8s - loss: 1.0223e-04 - val_loss: 4.3075e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 73/100\n",
      "657/657 - 8s - loss: 1.0152e-04 - val_loss: 4.4562e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 74/100\n",
      "657/657 - 8s - loss: 1.0081e-04 - val_loss: 4.6249e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 75/100\n",
      "657/657 - 8s - loss: 1.0006e-04 - val_loss: 4.7813e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 76/100\n",
      "657/657 - 8s - loss: 9.9310e-05 - val_loss: 4.9533e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 77/100\n",
      "657/657 - 8s - loss: 9.8576e-05 - val_loss: 5.1268e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 78/100\n",
      "657/657 - 8s - loss: 9.7871e-05 - val_loss: 5.3053e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 79/100\n",
      "657/657 - 8s - loss: 9.7170e-05 - val_loss: 5.4871e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 80/100\n",
      "657/657 - 8s - loss: 9.6474e-05 - val_loss: 5.6671e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 81/100\n",
      "657/657 - 8s - loss: 9.5798e-05 - val_loss: 5.8436e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 82/100\n",
      "657/657 - 8s - loss: 9.5126e-05 - val_loss: 6.0116e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 83/100\n",
      "657/657 - 8s - loss: 9.4398e-05 - val_loss: 6.1652e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 84/100\n",
      "657/657 - 8s - loss: 9.3661e-05 - val_loss: 6.3204e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 85/100\n",
      "657/657 - 8s - loss: 9.2955e-05 - val_loss: 6.4656e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 86/100\n",
      "657/657 - 8s - loss: 9.2276e-05 - val_loss: 6.6097e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 87/100\n",
      "657/657 - 8s - loss: 9.1612e-05 - val_loss: 6.7428e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 88/100\n",
      "657/657 - 8s - loss: 9.0951e-05 - val_loss: 6.8621e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 89/100\n",
      "657/657 - 8s - loss: 9.0317e-05 - val_loss: 6.9810e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 90/100\n",
      "657/657 - 8s - loss: 8.9664e-05 - val_loss: 7.0769e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 91/100\n",
      "657/657 - 8s - loss: 8.8996e-05 - val_loss: 7.1583e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 92/100\n",
      "657/657 - 8s - loss: 8.8363e-05 - val_loss: 7.2277e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 93/100\n",
      "657/657 - 8s - loss: 8.7661e-05 - val_loss: 7.2692e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 94/100\n",
      "657/657 - 8s - loss: 8.6949e-05 - val_loss: 7.3080e-05 - 8s/epoch - 13ms/step\n",
      "Epoch 95/100\n",
      "657/657 - 8s - loss: 8.6274e-05 - val_loss: 7.3394e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 96/100\n",
      "657/657 - 8s - loss: 8.5650e-05 - val_loss: 7.3757e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 97/100\n",
      "657/657 - 8s - loss: 8.5057e-05 - val_loss: 7.3979e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 98/100\n",
      "657/657 - 8s - loss: 8.4419e-05 - val_loss: 7.4025e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 99/100\n",
      "657/657 - 8s - loss: 8.3748e-05 - val_loss: 7.4074e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 100/100\n",
      "657/657 - 8s - loss: 8.3132e-05 - val_loss: 7.4095e-05 - 8s/epoch - 12ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 23:04:50.776485: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:04:50.914750: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:04:50.926232: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:04:51.027839: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:04:51.043126: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:04:55.087258: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:04:55.132293: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:04:55.140678: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 - 6s - loss: 3.4136e-04 - val_loss: 3.3607e-04 - 6s/epoch - 18ms/step\n",
      "Epoch 2/100\n",
      "329/329 - 4s - loss: 4.6318e-04 - val_loss: 2.7088e-04 - 4s/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "329/329 - 4s - loss: 2.4481e-04 - val_loss: 1.1753e-04 - 4s/epoch - 12ms/step\n",
      "Epoch 4/100\n",
      "329/329 - 4s - loss: 1.8153e-04 - val_loss: 5.2771e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "329/329 - 4s - loss: 1.5825e-04 - val_loss: 2.6938e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "329/329 - 4s - loss: 1.5023e-04 - val_loss: 1.9027e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 7/100\n",
      "329/329 - 4s - loss: 1.4648e-04 - val_loss: 1.7111e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "329/329 - 4s - loss: 1.4373e-04 - val_loss: 1.6996e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "329/329 - 4s - loss: 1.4124e-04 - val_loss: 1.7427e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 10/100\n",
      "329/329 - 4s - loss: 1.3871e-04 - val_loss: 1.8079e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 11/100\n",
      "329/329 - 4s - loss: 1.3625e-04 - val_loss: 1.8883e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 12/100\n",
      "329/329 - 4s - loss: 1.3347e-04 - val_loss: 1.9771e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 13/100\n",
      "329/329 - 4s - loss: 1.3086e-04 - val_loss: 2.0776e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 14/100\n",
      "329/329 - 4s - loss: 1.2830e-04 - val_loss: 2.1875e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "329/329 - 4s - loss: 1.2583e-04 - val_loss: 2.2905e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 16/100\n",
      "329/329 - 4s - loss: 1.2314e-04 - val_loss: 2.3764e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 17/100\n",
      "329/329 - 4s - loss: 1.2046e-04 - val_loss: 2.4577e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "329/329 - 4s - loss: 1.1806e-04 - val_loss: 2.5359e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 19/100\n",
      "329/329 - 4s - loss: 1.1574e-04 - val_loss: 2.5872e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "329/329 - 4s - loss: 1.1326e-04 - val_loss: 2.6769e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 21/100\n",
      "329/329 - 4s - loss: 1.1115e-04 - val_loss: 2.6976e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 22/100\n",
      "329/329 - 4s - loss: 1.0841e-04 - val_loss: 2.7129e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 23/100\n",
      "329/329 - 4s - loss: 1.0614e-04 - val_loss: 2.7996e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 24/100\n",
      "329/329 - 4s - loss: 1.0411e-04 - val_loss: 2.8355e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "329/329 - 4s - loss: 1.0176e-04 - val_loss: 2.8595e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 26/100\n",
      "329/329 - 4s - loss: 9.9441e-05 - val_loss: 2.8710e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 27/100\n",
      "329/329 - 4s - loss: 9.7747e-05 - val_loss: 2.9172e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 28/100\n",
      "329/329 - 4s - loss: 9.5301e-05 - val_loss: 2.9144e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 29/100\n",
      "329/329 - 4s - loss: 9.3046e-05 - val_loss: 2.9222e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "329/329 - 4s - loss: 9.1285e-05 - val_loss: 2.9488e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 31/100\n",
      "329/329 - 4s - loss: 8.9084e-05 - val_loss: 2.9310e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 32/100\n",
      "329/329 - 4s - loss: 8.6606e-05 - val_loss: 2.8861e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "329/329 - 4s - loss: 8.4233e-05 - val_loss: 2.8150e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 34/100\n",
      "329/329 - 4s - loss: 8.1919e-05 - val_loss: 2.7682e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 35/100\n",
      "329/329 - 4s - loss: 8.0413e-05 - val_loss: 2.7649e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 36/100\n",
      "329/329 - 4s - loss: 7.9271e-05 - val_loss: 2.7645e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 37/100\n",
      "329/329 - 4s - loss: 7.7415e-05 - val_loss: 2.7088e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 38/100\n",
      "329/329 - 4s - loss: 7.5392e-05 - val_loss: 2.6190e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 39/100\n",
      "329/329 - 4s - loss: 7.3711e-05 - val_loss: 2.5591e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 40/100\n",
      "329/329 - 4s - loss: 7.2411e-05 - val_loss: 2.5125e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 41/100\n",
      "329/329 - 4s - loss: 7.1197e-05 - val_loss: 2.4859e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 42/100\n",
      "329/329 - 4s - loss: 7.0238e-05 - val_loss: 2.4782e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 43/100\n",
      "329/329 - 4s - loss: 6.8619e-05 - val_loss: 2.3938e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 44/100\n",
      "329/329 - 4s - loss: 6.7019e-05 - val_loss: 2.3086e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 45/100\n",
      "329/329 - 4s - loss: 6.5907e-05 - val_loss: 2.2831e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 46/100\n",
      "329/329 - 4s - loss: 6.5138e-05 - val_loss: 2.2699e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 47/100\n",
      "329/329 - 4s - loss: 6.4623e-05 - val_loss: 2.3013e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 48/100\n",
      "329/329 - 4s - loss: 6.3756e-05 - val_loss: 2.2802e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 49/100\n",
      "329/329 - 4s - loss: 6.2741e-05 - val_loss: 2.2630e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 50/100\n",
      "329/329 - 4s - loss: 6.1770e-05 - val_loss: 2.2455e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 51/100\n",
      "329/329 - 4s - loss: 6.0767e-05 - val_loss: 2.2465e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 52/100\n",
      "329/329 - 4s - loss: 6.0386e-05 - val_loss: 2.2884e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 53/100\n",
      "329/329 - 4s - loss: 5.9908e-05 - val_loss: 2.3193e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 54/100\n",
      "329/329 - 4s - loss: 5.9273e-05 - val_loss: 2.3360e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 55/100\n",
      "329/329 - 4s - loss: 5.8227e-05 - val_loss: 2.3181e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 56/100\n",
      "329/329 - 4s - loss: 5.7442e-05 - val_loss: 2.3385e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 57/100\n",
      "329/329 - 4s - loss: 5.7020e-05 - val_loss: 2.3862e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 58/100\n",
      "329/329 - 4s - loss: 5.6475e-05 - val_loss: 2.4020e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 59/100\n",
      "329/329 - 4s - loss: 5.5882e-05 - val_loss: 2.4403e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 60/100\n",
      "329/329 - 4s - loss: 5.5699e-05 - val_loss: 2.5170e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 61/100\n",
      "329/329 - 4s - loss: 5.5342e-05 - val_loss: 2.5575e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 62/100\n",
      "329/329 - 4s - loss: 5.4449e-05 - val_loss: 2.5515e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 63/100\n",
      "329/329 - 4s - loss: 5.3815e-05 - val_loss: 2.5894e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 64/100\n",
      "329/329 - 4s - loss: 5.3410e-05 - val_loss: 2.5974e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 65/100\n",
      "329/329 - 4s - loss: 5.2941e-05 - val_loss: 2.6518e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 66/100\n",
      "329/329 - 4s - loss: 5.2686e-05 - val_loss: 2.7095e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 67/100\n",
      "329/329 - 4s - loss: 5.2467e-05 - val_loss: 2.7819e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 68/100\n",
      "329/329 - 4s - loss: 5.1857e-05 - val_loss: 2.7748e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 69/100\n",
      "329/329 - 4s - loss: 5.1326e-05 - val_loss: 2.8029e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 70/100\n",
      "329/329 - 4s - loss: 5.1185e-05 - val_loss: 2.8610e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 71/100\n",
      "329/329 - 4s - loss: 5.0902e-05 - val_loss: 2.8948e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 72/100\n",
      "329/329 - 4s - loss: 5.0384e-05 - val_loss: 2.9194e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 73/100\n",
      "329/329 - 4s - loss: 4.9803e-05 - val_loss: 2.9109e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 74/100\n",
      "329/329 - 4s - loss: 4.9332e-05 - val_loss: 2.9244e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 75/100\n",
      "329/329 - 4s - loss: 4.9373e-05 - val_loss: 2.9889e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 76/100\n",
      "329/329 - 4s - loss: 4.9534e-05 - val_loss: 3.0648e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 77/100\n",
      "329/329 - 4s - loss: 4.9101e-05 - val_loss: 3.0472e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 78/100\n",
      "329/329 - 4s - loss: 4.8272e-05 - val_loss: 3.0200e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 79/100\n",
      "329/329 - 4s - loss: 4.7858e-05 - val_loss: 3.0507e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 80/100\n",
      "329/329 - 4s - loss: 4.7514e-05 - val_loss: 3.0339e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 81/100\n",
      "329/329 - 4s - loss: 4.7250e-05 - val_loss: 3.0413e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 82/100\n",
      "329/329 - 4s - loss: 4.7387e-05 - val_loss: 3.1061e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 83/100\n",
      "329/329 - 4s - loss: 4.7218e-05 - val_loss: 3.1072e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 84/100\n",
      "329/329 - 4s - loss: 4.6577e-05 - val_loss: 3.0832e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 85/100\n",
      "329/329 - 4s - loss: 4.6071e-05 - val_loss: 3.0667e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 86/100\n",
      "329/329 - 4s - loss: 4.6071e-05 - val_loss: 3.1053e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 87/100\n",
      "329/329 - 4s - loss: 4.6115e-05 - val_loss: 3.1245e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 88/100\n",
      "329/329 - 4s - loss: 4.5707e-05 - val_loss: 3.1062e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 89/100\n",
      "329/329 - 4s - loss: 4.5127e-05 - val_loss: 3.0715e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 90/100\n",
      "329/329 - 4s - loss: 4.4846e-05 - val_loss: 3.0858e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 91/100\n",
      "329/329 - 4s - loss: 4.4918e-05 - val_loss: 3.1303e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 92/100\n",
      "329/329 - 4s - loss: 4.4872e-05 - val_loss: 3.1689e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 93/100\n",
      "329/329 - 4s - loss: 4.4348e-05 - val_loss: 3.1471e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 94/100\n",
      "329/329 - 4s - loss: 4.3934e-05 - val_loss: 3.1524e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 95/100\n",
      "329/329 - 4s - loss: 4.3749e-05 - val_loss: 3.1589e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 96/100\n",
      "329/329 - 4s - loss: 4.3635e-05 - val_loss: 3.1995e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 97/100\n",
      "329/329 - 4s - loss: 4.3418e-05 - val_loss: 3.2099e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 98/100\n",
      "329/329 - 4s - loss: 4.3195e-05 - val_loss: 3.2547e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 99/100\n",
      "329/329 - 4s - loss: 4.2955e-05 - val_loss: 3.2627e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 100/100\n",
      "329/329 - 4s - loss: 4.2692e-05 - val_loss: 3.3076e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 23:11:34.288240: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:11:34.426566: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:11:34.438082: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:11:34.557205: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:11:34.572197: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:11:38.709641: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:11:38.754696: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:11:38.763020: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 - 6s - loss: 2.2187e-04 - val_loss: 1.5124e-04 - 6s/epoch - 18ms/step\n",
      "Epoch 2/100\n",
      "329/329 - 4s - loss: 3.4795e-04 - val_loss: 4.6656e-04 - 4s/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "329/329 - 4s - loss: 4.9805e-04 - val_loss: 3.2858e-04 - 4s/epoch - 12ms/step\n",
      "Epoch 4/100\n",
      "329/329 - 4s - loss: 2.6886e-04 - val_loss: 1.3223e-04 - 4s/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "329/329 - 4s - loss: 1.8621e-04 - val_loss: 6.2092e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "329/329 - 4s - loss: 1.5266e-04 - val_loss: 3.1245e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 7/100\n",
      "329/329 - 4s - loss: 1.4061e-04 - val_loss: 1.9771e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "329/329 - 4s - loss: 1.3590e-04 - val_loss: 1.6106e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "329/329 - 4s - loss: 1.3275e-04 - val_loss: 1.5126e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 10/100\n",
      "329/329 - 4s - loss: 1.2984e-04 - val_loss: 1.5101e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 11/100\n",
      "329/329 - 4s - loss: 1.2712e-04 - val_loss: 1.5474e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 12/100\n",
      "329/329 - 4s - loss: 1.2476e-04 - val_loss: 1.6136e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 13/100\n",
      "329/329 - 4s - loss: 1.2278e-04 - val_loss: 1.7193e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 14/100\n",
      "329/329 - 4s - loss: 1.2133e-04 - val_loss: 1.8430e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "329/329 - 4s - loss: 1.2000e-04 - val_loss: 2.0129e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 16/100\n",
      "329/329 - 4s - loss: 1.1848e-04 - val_loss: 2.1803e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 17/100\n",
      "329/329 - 4s - loss: 1.1636e-04 - val_loss: 2.3139e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "329/329 - 4s - loss: 1.1422e-04 - val_loss: 2.4437e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 19/100\n",
      "329/329 - 4s - loss: 1.1234e-04 - val_loss: 2.5406e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "329/329 - 4s - loss: 1.1034e-04 - val_loss: 2.6265e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 21/100\n",
      "329/329 - 4s - loss: 1.0839e-04 - val_loss: 2.6911e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 22/100\n",
      "329/329 - 4s - loss: 1.0612e-04 - val_loss: 2.7717e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 23/100\n",
      "329/329 - 4s - loss: 1.0433e-04 - val_loss: 2.8177e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 24/100\n",
      "329/329 - 4s - loss: 1.0221e-04 - val_loss: 2.8115e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "329/329 - 4s - loss: 9.9706e-05 - val_loss: 2.7821e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 26/100\n",
      "329/329 - 4s - loss: 9.7337e-05 - val_loss: 2.7795e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 27/100\n",
      "329/329 - 4s - loss: 9.6293e-05 - val_loss: 2.8590e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 28/100\n",
      "329/329 - 4s - loss: 9.4218e-05 - val_loss: 2.8737e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 29/100\n",
      "329/329 - 4s - loss: 9.2427e-05 - val_loss: 2.8930e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "329/329 - 4s - loss: 9.0972e-05 - val_loss: 2.9202e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 31/100\n",
      "329/329 - 4s - loss: 8.8903e-05 - val_loss: 2.9243e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 32/100\n",
      "329/329 - 4s - loss: 8.7290e-05 - val_loss: 2.9385e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "329/329 - 4s - loss: 8.4871e-05 - val_loss: 2.8827e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 34/100\n",
      "329/329 - 4s - loss: 8.3381e-05 - val_loss: 2.9001e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 35/100\n",
      "329/329 - 4s - loss: 8.1568e-05 - val_loss: 2.8881e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 36/100\n",
      "329/329 - 4s - loss: 8.1204e-05 - val_loss: 2.9828e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 37/100\n",
      "329/329 - 4s - loss: 7.9442e-05 - val_loss: 2.9537e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 38/100\n",
      "329/329 - 4s - loss: 7.7592e-05 - val_loss: 2.8745e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 39/100\n",
      "329/329 - 4s - loss: 7.5704e-05 - val_loss: 2.8326e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 40/100\n",
      "329/329 - 4s - loss: 7.5109e-05 - val_loss: 2.8777e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 41/100\n",
      "329/329 - 4s - loss: 7.4192e-05 - val_loss: 2.8689e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 42/100\n",
      "329/329 - 4s - loss: 7.2465e-05 - val_loss: 2.7538e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 43/100\n",
      "329/329 - 4s - loss: 7.0944e-05 - val_loss: 2.7236e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 44/100\n",
      "329/329 - 4s - loss: 6.9615e-05 - val_loss: 2.6473e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 45/100\n",
      "329/329 - 4s - loss: 6.9127e-05 - val_loss: 2.6577e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 46/100\n",
      "329/329 - 4s - loss: 6.8586e-05 - val_loss: 2.6714e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 47/100\n",
      "329/329 - 4s - loss: 6.7396e-05 - val_loss: 2.6028e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 48/100\n",
      "329/329 - 4s - loss: 6.6250e-05 - val_loss: 2.5555e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 49/100\n",
      "329/329 - 4s - loss: 6.5441e-05 - val_loss: 2.5281e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 50/100\n",
      "329/329 - 4s - loss: 6.4594e-05 - val_loss: 2.4876e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 51/100\n",
      "329/329 - 4s - loss: 6.3395e-05 - val_loss: 2.4305e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 52/100\n",
      "329/329 - 4s - loss: 6.2768e-05 - val_loss: 2.4469e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 53/100\n",
      "329/329 - 4s - loss: 6.2969e-05 - val_loss: 2.5395e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 54/100\n",
      "329/329 - 4s - loss: 6.1789e-05 - val_loss: 2.4296e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 55/100\n",
      "329/329 - 4s - loss: 5.9981e-05 - val_loss: 2.3485e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 56/100\n",
      "329/329 - 4s - loss: 5.9157e-05 - val_loss: 2.3701e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 57/100\n",
      "329/329 - 4s - loss: 5.9290e-05 - val_loss: 2.4303e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 58/100\n",
      "329/329 - 4s - loss: 5.9514e-05 - val_loss: 2.5409e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 59/100\n",
      "329/329 - 4s - loss: 5.8914e-05 - val_loss: 2.5264e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 60/100\n",
      "329/329 - 4s - loss: 5.7717e-05 - val_loss: 2.5004e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 61/100\n",
      "329/329 - 4s - loss: 5.6704e-05 - val_loss: 2.4834e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 62/100\n",
      "329/329 - 4s - loss: 5.5984e-05 - val_loss: 2.5046e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 63/100\n",
      "329/329 - 4s - loss: 5.5667e-05 - val_loss: 2.5450e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 64/100\n",
      "329/329 - 4s - loss: 5.5484e-05 - val_loss: 2.6186e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 65/100\n",
      "329/329 - 4s - loss: 5.5474e-05 - val_loss: 2.6883e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 66/100\n",
      "329/329 - 4s - loss: 5.4846e-05 - val_loss: 2.7041e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 67/100\n",
      "329/329 - 4s - loss: 5.3964e-05 - val_loss: 2.7114e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 68/100\n",
      "329/329 - 4s - loss: 5.3676e-05 - val_loss: 2.7966e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 69/100\n",
      "329/329 - 4s - loss: 5.3291e-05 - val_loss: 2.8192e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 70/100\n",
      "329/329 - 4s - loss: 5.2823e-05 - val_loss: 2.8742e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 71/100\n",
      "329/329 - 4s - loss: 5.2466e-05 - val_loss: 2.9237e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 72/100\n",
      "329/329 - 4s - loss: 5.2028e-05 - val_loss: 2.9699e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 73/100\n",
      "329/329 - 4s - loss: 5.1719e-05 - val_loss: 3.0645e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 74/100\n",
      "329/329 - 4s - loss: 5.1565e-05 - val_loss: 3.1527e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 75/100\n",
      "329/329 - 4s - loss: 5.1058e-05 - val_loss: 3.2118e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 76/100\n",
      "329/329 - 4s - loss: 5.0357e-05 - val_loss: 3.2422e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 77/100\n",
      "329/329 - 4s - loss: 5.0174e-05 - val_loss: 3.3776e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 78/100\n",
      "329/329 - 4s - loss: 4.9795e-05 - val_loss: 3.4061e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 79/100\n",
      "329/329 - 4s - loss: 4.9347e-05 - val_loss: 3.5170e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 80/100\n",
      "329/329 - 4s - loss: 4.9369e-05 - val_loss: 3.6568e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 81/100\n",
      "329/329 - 4s - loss: 4.9220e-05 - val_loss: 3.7888e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 82/100\n",
      "329/329 - 4s - loss: 4.8806e-05 - val_loss: 3.8822e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 83/100\n",
      "329/329 - 4s - loss: 4.8094e-05 - val_loss: 3.9458e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 84/100\n",
      "329/329 - 4s - loss: 4.7695e-05 - val_loss: 4.0698e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 85/100\n",
      "329/329 - 4s - loss: 4.7836e-05 - val_loss: 4.2529e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 86/100\n",
      "329/329 - 4s - loss: 4.7740e-05 - val_loss: 4.3962e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 87/100\n",
      "329/329 - 4s - loss: 4.7340e-05 - val_loss: 4.5128e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 88/100\n",
      "329/329 - 4s - loss: 4.7026e-05 - val_loss: 4.6415e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 89/100\n",
      "329/329 - 4s - loss: 4.6754e-05 - val_loss: 4.7653e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 90/100\n",
      "329/329 - 4s - loss: 4.6494e-05 - val_loss: 4.8968e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 91/100\n",
      "329/329 - 4s - loss: 4.6341e-05 - val_loss: 5.0362e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 92/100\n",
      "329/329 - 4s - loss: 4.6169e-05 - val_loss: 5.1727e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 93/100\n",
      "329/329 - 4s - loss: 4.5996e-05 - val_loss: 5.3036e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 94/100\n",
      "329/329 - 4s - loss: 4.5757e-05 - val_loss: 5.4179e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 95/100\n",
      "329/329 - 4s - loss: 4.5543e-05 - val_loss: 5.5325e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 96/100\n",
      "329/329 - 4s - loss: 4.5346e-05 - val_loss: 5.6438e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 97/100\n",
      "329/329 - 4s - loss: 4.5244e-05 - val_loss: 5.7635e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 98/100\n",
      "329/329 - 4s - loss: 4.5041e-05 - val_loss: 5.8586e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 99/100\n",
      "329/329 - 4s - loss: 4.4824e-05 - val_loss: 5.9520e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 100/100\n",
      "329/329 - 4s - loss: 4.4766e-05 - val_loss: 6.0644e-05 - 4s/epoch - 12ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 23:18:24.897940: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:18:25.031758: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:18:25.043378: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:18:25.174199: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:18:25.189287: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:18:29.486920: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:18:29.532324: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:18:29.540802: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 - 6s - loss: 2.3324e-04 - val_loss: 2.0852e-04 - 6s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "329/329 - 4s - loss: 2.0736e-04 - val_loss: 1.6092e-04 - 4s/epoch - 13ms/step\n",
      "Epoch 3/100\n",
      "329/329 - 4s - loss: 3.6716e-04 - val_loss: 6.1832e-04 - 4s/epoch - 13ms/step\n",
      "Epoch 4/100\n",
      "329/329 - 4s - loss: 6.7888e-04 - val_loss: 5.6364e-04 - 4s/epoch - 13ms/step\n",
      "Epoch 5/100\n",
      "329/329 - 4s - loss: 3.8648e-04 - val_loss: 2.9353e-04 - 4s/epoch - 13ms/step\n",
      "Epoch 6/100\n",
      "329/329 - 4s - loss: 2.6354e-04 - val_loss: 1.8175e-04 - 4s/epoch - 13ms/step\n",
      "Epoch 7/100\n",
      "329/329 - 4s - loss: 1.9874e-04 - val_loss: 1.0973e-04 - 4s/epoch - 13ms/step\n",
      "Epoch 8/100\n",
      "329/329 - 4s - loss: 1.6441e-04 - val_loss: 6.1322e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 9/100\n",
      "329/329 - 4s - loss: 1.5067e-04 - val_loss: 3.6884e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 10/100\n",
      "329/329 - 4s - loss: 1.4617e-04 - val_loss: 2.6990e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 11/100\n",
      "329/329 - 4s - loss: 1.4405e-04 - val_loss: 2.3578e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "329/329 - 4s - loss: 1.4219e-04 - val_loss: 2.3087e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 13/100\n",
      "329/329 - 4s - loss: 1.4013e-04 - val_loss: 2.4015e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 14/100\n",
      "329/329 - 4s - loss: 1.3782e-04 - val_loss: 2.5825e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 15/100\n",
      "329/329 - 4s - loss: 1.3602e-04 - val_loss: 2.8271e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 16/100\n",
      "329/329 - 4s - loss: 1.3445e-04 - val_loss: 3.1298e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 17/100\n",
      "329/329 - 4s - loss: 1.3209e-04 - val_loss: 3.3946e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 18/100\n",
      "329/329 - 4s - loss: 1.3033e-04 - val_loss: 3.6513e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 19/100\n",
      "329/329 - 4s - loss: 1.2674e-04 - val_loss: 3.7119e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 20/100\n",
      "329/329 - 4s - loss: 1.2252e-04 - val_loss: 3.7538e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 21/100\n",
      "329/329 - 4s - loss: 1.1899e-04 - val_loss: 3.7967e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 22/100\n",
      "329/329 - 4s - loss: 1.1601e-04 - val_loss: 3.8346e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 23/100\n",
      "329/329 - 4s - loss: 1.1388e-04 - val_loss: 3.9783e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 24/100\n",
      "329/329 - 4s - loss: 1.1096e-04 - val_loss: 3.9608e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 25/100\n",
      "329/329 - 4s - loss: 1.0732e-04 - val_loss: 3.9062e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 26/100\n",
      "329/329 - 4s - loss: 1.0430e-04 - val_loss: 3.9063e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 27/100\n",
      "329/329 - 4s - loss: 1.0242e-04 - val_loss: 3.9531e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 28/100\n",
      "329/329 - 4s - loss: 1.0070e-04 - val_loss: 4.0457e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 29/100\n",
      "329/329 - 4s - loss: 9.8627e-05 - val_loss: 4.0785e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 30/100\n",
      "329/329 - 4s - loss: 9.6077e-05 - val_loss: 4.0387e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 31/100\n",
      "329/329 - 4s - loss: 9.3913e-05 - val_loss: 4.0293e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 32/100\n",
      "329/329 - 4s - loss: 9.2085e-05 - val_loss: 4.0355e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 33/100\n",
      "329/329 - 4s - loss: 9.0747e-05 - val_loss: 4.1244e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 34/100\n",
      "329/329 - 4s - loss: 8.8859e-05 - val_loss: 4.0553e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 35/100\n",
      "329/329 - 4s - loss: 8.6195e-05 - val_loss: 3.9309e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 36/100\n",
      "329/329 - 4s - loss: 8.4679e-05 - val_loss: 3.9429e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 37/100\n",
      "329/329 - 4s - loss: 8.3504e-05 - val_loss: 3.9551e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 38/100\n",
      "329/329 - 4s - loss: 8.2383e-05 - val_loss: 3.9608e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 39/100\n",
      "329/329 - 4s - loss: 8.1701e-05 - val_loss: 4.0472e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 40/100\n",
      "329/329 - 4s - loss: 7.8893e-05 - val_loss: 3.7459e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 41/100\n",
      "329/329 - 4s - loss: 7.6840e-05 - val_loss: 3.7106e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 42/100\n",
      "329/329 - 4s - loss: 7.5417e-05 - val_loss: 3.6275e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 43/100\n",
      "329/329 - 4s - loss: 7.5954e-05 - val_loss: 3.8681e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 44/100\n",
      "329/329 - 4s - loss: 7.4082e-05 - val_loss: 3.5765e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 45/100\n",
      "329/329 - 4s - loss: 7.2051e-05 - val_loss: 3.5107e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 46/100\n",
      "329/329 - 4s - loss: 7.1021e-05 - val_loss: 3.4666e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 47/100\n",
      "329/329 - 4s - loss: 7.0357e-05 - val_loss: 3.4732e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 48/100\n",
      "329/329 - 4s - loss: 7.0211e-05 - val_loss: 3.5599e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 49/100\n",
      "329/329 - 4s - loss: 6.7938e-05 - val_loss: 3.2669e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 50/100\n",
      "329/329 - 4s - loss: 6.6770e-05 - val_loss: 3.3055e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 51/100\n",
      "329/329 - 4s - loss: 6.6108e-05 - val_loss: 3.2553e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 52/100\n",
      "329/329 - 4s - loss: 6.5558e-05 - val_loss: 3.2677e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 53/100\n",
      "329/329 - 4s - loss: 6.4747e-05 - val_loss: 3.2041e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 54/100\n",
      "329/329 - 4s - loss: 6.5010e-05 - val_loss: 3.3982e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 55/100\n",
      "329/329 - 4s - loss: 6.3004e-05 - val_loss: 3.1031e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 56/100\n",
      "329/329 - 4s - loss: 6.1262e-05 - val_loss: 3.0405e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 57/100\n",
      "329/329 - 4s - loss: 6.1934e-05 - val_loss: 3.2405e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 58/100\n",
      "329/329 - 4s - loss: 6.1356e-05 - val_loss: 3.1332e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 59/100\n",
      "329/329 - 4s - loss: 5.9837e-05 - val_loss: 3.0342e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 60/100\n",
      "329/329 - 4s - loss: 5.9485e-05 - val_loss: 3.0871e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 61/100\n",
      "329/329 - 4s - loss: 5.8840e-05 - val_loss: 3.0290e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 62/100\n",
      "329/329 - 4s - loss: 5.8238e-05 - val_loss: 3.0366e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 63/100\n",
      "329/329 - 4s - loss: 5.7492e-05 - val_loss: 2.9785e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 64/100\n",
      "329/329 - 4s - loss: 5.6823e-05 - val_loss: 2.9445e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 65/100\n",
      "329/329 - 4s - loss: 5.7200e-05 - val_loss: 3.0839e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 66/100\n",
      "329/329 - 4s - loss: 5.6345e-05 - val_loss: 2.9590e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 67/100\n",
      "329/329 - 4s - loss: 5.6370e-05 - val_loss: 3.0868e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 68/100\n",
      "329/329 - 4s - loss: 5.4424e-05 - val_loss: 2.8056e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 69/100\n",
      "329/329 - 4s - loss: 5.4025e-05 - val_loss: 2.9134e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 70/100\n",
      "329/329 - 4s - loss: 5.3822e-05 - val_loss: 2.8931e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 71/100\n",
      "329/329 - 4s - loss: 5.3976e-05 - val_loss: 2.9924e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 72/100\n",
      "329/329 - 4s - loss: 5.3060e-05 - val_loss: 2.8891e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 73/100\n",
      "329/329 - 4s - loss: 5.2468e-05 - val_loss: 2.9328e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 74/100\n",
      "329/329 - 4s - loss: 5.2217e-05 - val_loss: 2.9564e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 75/100\n",
      "329/329 - 4s - loss: 5.1653e-05 - val_loss: 2.9535e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 76/100\n",
      "329/329 - 4s - loss: 5.1444e-05 - val_loss: 3.0186e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 77/100\n",
      "329/329 - 4s - loss: 5.1160e-05 - val_loss: 3.0527e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 78/100\n",
      "329/329 - 4s - loss: 5.0635e-05 - val_loss: 3.0651e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 79/100\n",
      "329/329 - 4s - loss: 5.0473e-05 - val_loss: 3.1619e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 80/100\n",
      "329/329 - 4s - loss: 4.9797e-05 - val_loss: 3.1313e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 81/100\n",
      "329/329 - 4s - loss: 5.0036e-05 - val_loss: 3.3054e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 82/100\n",
      "329/329 - 4s - loss: 4.9282e-05 - val_loss: 3.2580e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 83/100\n",
      "329/329 - 4s - loss: 4.8882e-05 - val_loss: 3.3063e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 84/100\n",
      "329/329 - 4s - loss: 4.9326e-05 - val_loss: 3.5401e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 85/100\n",
      "329/329 - 4s - loss: 4.8990e-05 - val_loss: 3.4876e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 86/100\n",
      "329/329 - 4s - loss: 4.7437e-05 - val_loss: 3.4530e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 87/100\n",
      "329/329 - 4s - loss: 4.7527e-05 - val_loss: 3.5324e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 88/100\n",
      "329/329 - 4s - loss: 4.7852e-05 - val_loss: 3.6945e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 89/100\n",
      "329/329 - 4s - loss: 4.8518e-05 - val_loss: 3.8246e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 90/100\n",
      "329/329 - 4s - loss: 4.7824e-05 - val_loss: 3.7878e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 91/100\n",
      "329/329 - 4s - loss: 4.6662e-05 - val_loss: 3.7196e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 92/100\n",
      "329/329 - 4s - loss: 4.6426e-05 - val_loss: 3.7480e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 93/100\n",
      "329/329 - 4s - loss: 4.6137e-05 - val_loss: 3.7755e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 94/100\n",
      "329/329 - 4s - loss: 4.6781e-05 - val_loss: 3.9374e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 95/100\n",
      "329/329 - 4s - loss: 4.6408e-05 - val_loss: 3.8867e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 96/100\n",
      "329/329 - 4s - loss: 4.5918e-05 - val_loss: 3.9243e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 97/100\n",
      "329/329 - 4s - loss: 4.5031e-05 - val_loss: 3.8554e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 98/100\n",
      "329/329 - 4s - loss: 4.4694e-05 - val_loss: 3.9067e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 99/100\n",
      "329/329 - 4s - loss: 4.4992e-05 - val_loss: 3.9819e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 100/100\n",
      "329/329 - 4s - loss: 4.5598e-05 - val_loss: 4.1635e-05 - 4s/epoch - 13ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 23:25:22.539694: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:25:22.678339: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:25:22.689892: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:25:22.825750: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:25:22.840881: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:25:25.266162: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:25:25.311218: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:25:25.320010: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 - 4s - loss: 6.4248e-04 - val_loss: 2.4261e-04 - 4s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "165/165 - 2s - loss: 5.4089e-04 - val_loss: 7.2588e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 3/100\n",
      "165/165 - 2s - loss: 9.8683e-04 - val_loss: 0.0025 - 2s/epoch - 13ms/step\n",
      "Epoch 4/100\n",
      "165/165 - 2s - loss: 0.0013 - val_loss: 0.0031 - 2s/epoch - 13ms/step\n",
      "Epoch 5/100\n",
      "165/165 - 2s - loss: 0.0015 - val_loss: 0.0049 - 2s/epoch - 13ms/step\n",
      "Epoch 6/100\n",
      "165/165 - 2s - loss: 0.0016 - val_loss: 0.0054 - 2s/epoch - 13ms/step\n",
      "Epoch 7/100\n",
      "165/165 - 2s - loss: 0.0016 - val_loss: 0.0063 - 2s/epoch - 13ms/step\n",
      "Epoch 8/100\n",
      "165/165 - 2s - loss: 0.0019 - val_loss: 0.0067 - 2s/epoch - 13ms/step\n",
      "Epoch 9/100\n",
      "165/165 - 2s - loss: 0.0021 - val_loss: 0.0063 - 2s/epoch - 13ms/step\n",
      "Epoch 10/100\n",
      "165/165 - 2s - loss: 0.0024 - val_loss: 0.0053 - 2s/epoch - 13ms/step\n",
      "Epoch 11/100\n",
      "165/165 - 2s - loss: 0.0025 - val_loss: 0.0036 - 2s/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "165/165 - 2s - loss: 0.0022 - val_loss: 0.0016 - 2s/epoch - 13ms/step\n",
      "Epoch 13/100\n",
      "165/165 - 2s - loss: 0.0017 - val_loss: 4.5050e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 14/100\n",
      "165/165 - 2s - loss: 0.0013 - val_loss: 9.4564e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 15/100\n",
      "165/165 - 2s - loss: 9.9718e-04 - val_loss: 1.0123e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 16/100\n",
      "165/165 - 2s - loss: 7.9694e-04 - val_loss: 1.4551e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 17/100\n",
      "165/165 - 2s - loss: 6.4283e-04 - val_loss: 1.5309e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 18/100\n",
      "165/165 - 2s - loss: 5.2521e-04 - val_loss: 1.3434e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 19/100\n",
      "165/165 - 2s - loss: 4.3905e-04 - val_loss: 1.0578e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 20/100\n",
      "165/165 - 2s - loss: 3.8054e-04 - val_loss: 7.7421e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 21/100\n",
      "165/165 - 2s - loss: 3.4510e-04 - val_loss: 5.7250e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 22/100\n",
      "165/165 - 2s - loss: 3.2996e-04 - val_loss: 5.2336e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 23/100\n",
      "165/165 - 2s - loss: 3.3366e-04 - val_loss: 7.0715e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 24/100\n",
      "165/165 - 2s - loss: 3.5612e-04 - val_loss: 1.2245e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 25/100\n",
      "165/165 - 2s - loss: 3.9850e-04 - val_loss: 2.1973e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 26/100\n",
      "165/165 - 2s - loss: 4.6272e-04 - val_loss: 3.7043e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 27/100\n",
      "165/165 - 2s - loss: 5.5049e-04 - val_loss: 5.5894e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 28/100\n",
      "165/165 - 2s - loss: 6.4914e-04 - val_loss: 6.9348e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 29/100\n",
      "165/165 - 2s - loss: 7.6672e-04 - val_loss: 9.6584e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 30/100\n",
      "165/165 - 2s - loss: 9.2251e-04 - val_loss: 0.0013 - 2s/epoch - 13ms/step\n",
      "Epoch 31/100\n",
      "165/165 - 2s - loss: 0.0011 - val_loss: 0.0015 - 2s/epoch - 13ms/step\n",
      "Epoch 32/100\n",
      "165/165 - 2s - loss: 0.0012 - val_loss: 9.5055e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 33/100\n",
      "165/165 - 2s - loss: 0.0011 - val_loss: 3.8843e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 34/100\n",
      "165/165 - 2s - loss: 9.1759e-04 - val_loss: 9.4594e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 35/100\n",
      "165/165 - 2s - loss: 6.8929e-04 - val_loss: 1.3775e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 36/100\n",
      "165/165 - 2s - loss: 5.2926e-04 - val_loss: 2.5849e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 37/100\n",
      "165/165 - 2s - loss: 4.1872e-04 - val_loss: 3.1346e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 38/100\n",
      "165/165 - 2s - loss: 3.3704e-04 - val_loss: 3.0093e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 39/100\n",
      "165/165 - 2s - loss: 2.7868e-04 - val_loss: 2.5144e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 40/100\n",
      "165/165 - 2s - loss: 2.4085e-04 - val_loss: 1.7978e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 41/100\n",
      "165/165 - 2s - loss: 2.2059e-04 - val_loss: 1.1368e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 42/100\n",
      "165/165 - 2s - loss: 2.1791e-04 - val_loss: 6.1280e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 43/100\n",
      "165/165 - 2s - loss: 2.3307e-04 - val_loss: 4.3060e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 44/100\n",
      "165/165 - 2s - loss: 2.6739e-04 - val_loss: 7.8728e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 45/100\n",
      "165/165 - 2s - loss: 3.2185e-04 - val_loss: 1.6087e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 46/100\n",
      "165/165 - 2s - loss: 3.9387e-04 - val_loss: 2.8258e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 47/100\n",
      "165/165 - 2s - loss: 4.7869e-04 - val_loss: 4.8696e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 48/100\n",
      "165/165 - 2s - loss: 5.8200e-04 - val_loss: 6.5256e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 49/100\n",
      "165/165 - 2s - loss: 7.4069e-04 - val_loss: 9.0336e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 50/100\n",
      "165/165 - 2s - loss: 8.8396e-04 - val_loss: 7.7169e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 51/100\n",
      "165/165 - 2s - loss: 8.7285e-04 - val_loss: 3.3956e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 52/100\n",
      "165/165 - 2s - loss: 7.3369e-04 - val_loss: 8.7126e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 53/100\n",
      "165/165 - 2s - loss: 5.5237e-04 - val_loss: 1.0174e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 54/100\n",
      "165/165 - 2s - loss: 4.0963e-04 - val_loss: 2.1838e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 55/100\n",
      "165/165 - 2s - loss: 3.1633e-04 - val_loss: 2.8317e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 56/100\n",
      "165/165 - 2s - loss: 2.5386e-04 - val_loss: 2.8237e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 57/100\n",
      "165/165 - 2s - loss: 2.1332e-04 - val_loss: 2.3263e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 58/100\n",
      "165/165 - 2s - loss: 1.8982e-04 - val_loss: 1.5767e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 59/100\n",
      "165/165 - 2s - loss: 1.8073e-04 - val_loss: 8.1973e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 60/100\n",
      "165/165 - 2s - loss: 1.8605e-04 - val_loss: 3.7634e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 61/100\n",
      "165/165 - 2s - loss: 2.0745e-04 - val_loss: 3.8581e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 62/100\n",
      "165/165 - 2s - loss: 2.4453e-04 - val_loss: 8.4016e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 63/100\n",
      "165/165 - 2s - loss: 3.1268e-04 - val_loss: 2.2651e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 64/100\n",
      "165/165 - 2s - loss: 3.9057e-04 - val_loss: 4.0183e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 65/100\n",
      "165/165 - 2s - loss: 4.6699e-04 - val_loss: 5.8222e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 66/100\n",
      "165/165 - 2s - loss: 5.6102e-04 - val_loss: 6.0559e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 67/100\n",
      "165/165 - 2s - loss: 6.0913e-04 - val_loss: 4.5342e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 68/100\n",
      "165/165 - 2s - loss: 6.1235e-04 - val_loss: 2.2643e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 69/100\n",
      "165/165 - 2s - loss: 5.3484e-04 - val_loss: 7.4123e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 70/100\n",
      "165/165 - 2s - loss: 4.2884e-04 - val_loss: 6.8400e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 71/100\n",
      "165/165 - 2s - loss: 3.3809e-04 - val_loss: 1.2872e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 72/100\n",
      "165/165 - 2s - loss: 2.7214e-04 - val_loss: 1.7176e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 73/100\n",
      "165/165 - 2s - loss: 2.2802e-04 - val_loss: 1.7074e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 74/100\n",
      "165/165 - 2s - loss: 2.0031e-04 - val_loss: 1.3630e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 75/100\n",
      "165/165 - 2s - loss: 1.8601e-04 - val_loss: 8.8326e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 76/100\n",
      "165/165 - 2s - loss: 1.8406e-04 - val_loss: 4.8160e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 77/100\n",
      "165/165 - 2s - loss: 1.9471e-04 - val_loss: 3.4539e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 78/100\n",
      "165/165 - 2s - loss: 2.1748e-04 - val_loss: 4.9592e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 79/100\n",
      "165/165 - 2s - loss: 2.5775e-04 - val_loss: 1.0466e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 80/100\n",
      "165/165 - 2s - loss: 3.1669e-04 - val_loss: 2.5376e-04 - 2s/epoch - 12ms/step\n",
      "Epoch 81/100\n",
      "165/165 - 2s - loss: 3.9732e-04 - val_loss: 4.5530e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 82/100\n",
      "165/165 - 2s - loss: 4.5870e-04 - val_loss: 5.2327e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 83/100\n",
      "165/165 - 2s - loss: 5.1805e-04 - val_loss: 4.0394e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 84/100\n",
      "165/165 - 2s - loss: 5.1105e-04 - val_loss: 1.8444e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 85/100\n",
      "165/165 - 2s - loss: 4.4325e-04 - val_loss: 6.2736e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 86/100\n",
      "165/165 - 2s - loss: 3.5884e-04 - val_loss: 6.0309e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 87/100\n",
      "165/165 - 2s - loss: 2.8708e-04 - val_loss: 1.0817e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 88/100\n",
      "165/165 - 2s - loss: 2.3566e-04 - val_loss: 1.4113e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 89/100\n",
      "165/165 - 2s - loss: 2.0188e-04 - val_loss: 1.3736e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 90/100\n",
      "165/165 - 2s - loss: 1.8187e-04 - val_loss: 1.0591e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 91/100\n",
      "165/165 - 2s - loss: 1.7353e-04 - val_loss: 6.6184e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 92/100\n",
      "165/165 - 2s - loss: 1.7636e-04 - val_loss: 3.8503e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 93/100\n",
      "165/165 - 2s - loss: 1.9061e-04 - val_loss: 3.6037e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 94/100\n",
      "165/165 - 2s - loss: 2.1670e-04 - val_loss: 6.4408e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 95/100\n",
      "165/165 - 2s - loss: 2.5895e-04 - val_loss: 1.3219e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 96/100\n",
      "165/165 - 2s - loss: 3.0952e-04 - val_loss: 2.9340e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 97/100\n",
      "165/165 - 2s - loss: 3.8987e-04 - val_loss: 5.2124e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 98/100\n",
      "165/165 - 2s - loss: 4.4186e-04 - val_loss: 4.5736e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 99/100\n",
      "165/165 - 2s - loss: 4.4964e-04 - val_loss: 2.2176e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 100/100\n",
      "165/165 - 2s - loss: 4.0986e-04 - val_loss: 9.6275e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 23:28:54.346141: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:28:54.476885: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:28:54.488343: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:28:54.619005: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:28:54.633923: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:28:57.058933: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:28:57.104565: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:28:57.113206: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 - 4s - loss: 3.8252e-04 - val_loss: 9.4331e-05 - 4s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "165/165 - 2s - loss: 1.5431e-04 - val_loss: 6.2327e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 3/100\n",
      "165/165 - 2s - loss: 1.3695e-04 - val_loss: 4.1537e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 4/100\n",
      "165/165 - 2s - loss: 1.1976e-04 - val_loss: 3.0788e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 5/100\n",
      "165/165 - 2s - loss: 1.0472e-04 - val_loss: 2.3965e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 6/100\n",
      "165/165 - 2s - loss: 9.1135e-05 - val_loss: 1.9390e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 7/100\n",
      "165/165 - 2s - loss: 7.8986e-05 - val_loss: 1.7381e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 8/100\n",
      "165/165 - 2s - loss: 6.9600e-05 - val_loss: 1.9213e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 9/100\n",
      "165/165 - 2s - loss: 6.4689e-05 - val_loss: 2.0993e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 10/100\n",
      "165/165 - 2s - loss: 6.4130e-05 - val_loss: 2.1616e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 11/100\n",
      "165/165 - 2s - loss: 6.6235e-05 - val_loss: 2.2787e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "165/165 - 2s - loss: 6.8894e-05 - val_loss: 2.4673e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 13/100\n",
      "165/165 - 2s - loss: 7.0814e-05 - val_loss: 2.6535e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 14/100\n",
      "165/165 - 2s - loss: 7.1762e-05 - val_loss: 2.7664e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 15/100\n",
      "165/165 - 2s - loss: 7.2031e-05 - val_loss: 2.7844e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 16/100\n",
      "165/165 - 2s - loss: 7.2001e-05 - val_loss: 2.7217e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 17/100\n",
      "165/165 - 2s - loss: 7.1948e-05 - val_loss: 2.5950e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 18/100\n",
      "165/165 - 2s - loss: 7.2039e-05 - val_loss: 2.4083e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 19/100\n",
      "165/165 - 2s - loss: 7.2375e-05 - val_loss: 2.1553e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 20/100\n",
      "165/165 - 2s - loss: 7.3033e-05 - val_loss: 1.8472e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 21/100\n",
      "165/165 - 2s - loss: 7.4057e-05 - val_loss: 1.4947e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 22/100\n",
      "165/165 - 2s - loss: 7.5319e-05 - val_loss: 1.2008e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 23/100\n",
      "165/165 - 2s - loss: 7.6367e-05 - val_loss: 1.1028e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 24/100\n",
      "165/165 - 2s - loss: 7.6667e-05 - val_loss: 1.2796e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 25/100\n",
      "165/165 - 2s - loss: 7.5887e-05 - val_loss: 1.6275e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 26/100\n",
      "165/165 - 2s - loss: 7.4110e-05 - val_loss: 1.9252e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 27/100\n",
      "165/165 - 2s - loss: 7.1809e-05 - val_loss: 2.0495e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 28/100\n",
      "165/165 - 2s - loss: 6.9409e-05 - val_loss: 2.0167e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 29/100\n",
      "165/165 - 2s - loss: 6.7201e-05 - val_loss: 1.8893e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 30/100\n",
      "165/165 - 2s - loss: 6.5282e-05 - val_loss: 1.7147e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 31/100\n",
      "165/165 - 2s - loss: 6.3646e-05 - val_loss: 1.5341e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 32/100\n",
      "165/165 - 2s - loss: 6.2281e-05 - val_loss: 1.3823e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 33/100\n",
      "165/165 - 2s - loss: 6.1196e-05 - val_loss: 1.2596e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 34/100\n",
      "165/165 - 2s - loss: 6.0336e-05 - val_loss: 1.1681e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 35/100\n",
      "165/165 - 2s - loss: 5.9619e-05 - val_loss: 1.1032e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 36/100\n",
      "165/165 - 2s - loss: 5.9001e-05 - val_loss: 1.0581e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 37/100\n",
      "165/165 - 2s - loss: 5.8434e-05 - val_loss: 1.0272e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 38/100\n",
      "165/165 - 2s - loss: 5.7891e-05 - val_loss: 1.0087e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 39/100\n",
      "165/165 - 2s - loss: 5.7330e-05 - val_loss: 9.9407e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 40/100\n",
      "165/165 - 2s - loss: 5.6707e-05 - val_loss: 9.8351e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 41/100\n",
      "165/165 - 2s - loss: 5.6010e-05 - val_loss: 9.7075e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 42/100\n",
      "165/165 - 2s - loss: 5.5187e-05 - val_loss: 9.6226e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 43/100\n",
      "165/165 - 2s - loss: 5.4375e-05 - val_loss: 9.5141e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 44/100\n",
      "165/165 - 2s - loss: 5.3419e-05 - val_loss: 9.3248e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 45/100\n",
      "165/165 - 2s - loss: 5.2396e-05 - val_loss: 9.1261e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 46/100\n",
      "165/165 - 2s - loss: 5.1372e-05 - val_loss: 8.8951e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 47/100\n",
      "165/165 - 2s - loss: 5.0339e-05 - val_loss: 8.6514e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 48/100\n",
      "165/165 - 2s - loss: 4.9296e-05 - val_loss: 8.3915e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 49/100\n",
      "165/165 - 2s - loss: 4.8228e-05 - val_loss: 8.1136e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 50/100\n",
      "165/165 - 2s - loss: 4.7205e-05 - val_loss: 7.8793e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 51/100\n",
      "165/165 - 2s - loss: 4.6174e-05 - val_loss: 7.6941e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 52/100\n",
      "165/165 - 2s - loss: 4.5326e-05 - val_loss: 7.5171e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 53/100\n",
      "165/165 - 2s - loss: 4.4411e-05 - val_loss: 7.3955e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 54/100\n",
      "165/165 - 2s - loss: 4.3530e-05 - val_loss: 7.3192e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 55/100\n",
      "165/165 - 2s - loss: 4.2739e-05 - val_loss: 7.2803e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 56/100\n",
      "165/165 - 2s - loss: 4.2006e-05 - val_loss: 7.2826e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 57/100\n",
      "165/165 - 2s - loss: 4.1299e-05 - val_loss: 7.3167e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 58/100\n",
      "165/165 - 2s - loss: 4.0632e-05 - val_loss: 7.3767e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 59/100\n",
      "165/165 - 2s - loss: 4.0003e-05 - val_loss: 7.4601e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 60/100\n",
      "165/165 - 2s - loss: 3.9406e-05 - val_loss: 7.5675e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 61/100\n",
      "165/165 - 2s - loss: 3.8846e-05 - val_loss: 7.6882e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 62/100\n",
      "165/165 - 2s - loss: 3.8319e-05 - val_loss: 7.8191e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 63/100\n",
      "165/165 - 2s - loss: 3.7821e-05 - val_loss: 7.9518e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 64/100\n",
      "165/165 - 2s - loss: 3.7342e-05 - val_loss: 8.0969e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 65/100\n",
      "165/165 - 2s - loss: 3.6898e-05 - val_loss: 8.2246e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 66/100\n",
      "165/165 - 2s - loss: 3.6488e-05 - val_loss: 8.5024e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 67/100\n",
      "165/165 - 2s - loss: 3.6025e-05 - val_loss: 8.5812e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 68/100\n",
      "165/165 - 2s - loss: 3.5657e-05 - val_loss: 8.7101e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 69/100\n",
      "165/165 - 2s - loss: 3.5276e-05 - val_loss: 8.8147e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 70/100\n",
      "165/165 - 2s - loss: 3.4923e-05 - val_loss: 8.9707e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 71/100\n",
      "165/165 - 2s - loss: 3.4543e-05 - val_loss: 9.1359e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 72/100\n",
      "165/165 - 2s - loss: 3.4162e-05 - val_loss: 9.2462e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 73/100\n",
      "165/165 - 2s - loss: 3.3802e-05 - val_loss: 9.3542e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 74/100\n",
      "165/165 - 2s - loss: 3.3450e-05 - val_loss: 9.4437e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 75/100\n",
      "165/165 - 2s - loss: 3.3100e-05 - val_loss: 9.5689e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 76/100\n",
      "165/165 - 2s - loss: 3.2728e-05 - val_loss: 9.6543e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 77/100\n",
      "165/165 - 2s - loss: 3.2371e-05 - val_loss: 9.7413e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 78/100\n",
      "165/165 - 2s - loss: 3.2024e-05 - val_loss: 9.8316e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 79/100\n",
      "165/165 - 2s - loss: 3.1704e-05 - val_loss: 9.9513e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 80/100\n",
      "165/165 - 2s - loss: 3.1419e-05 - val_loss: 1.0186e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 81/100\n",
      "165/165 - 2s - loss: 3.1428e-05 - val_loss: 1.0816e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 82/100\n",
      "165/165 - 2s - loss: 3.1002e-05 - val_loss: 1.0946e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 83/100\n",
      "165/165 - 2s - loss: 3.0947e-05 - val_loss: 1.1540e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 84/100\n",
      "165/165 - 2s - loss: 3.1009e-05 - val_loss: 1.2397e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 85/100\n",
      "165/165 - 2s - loss: 3.1228e-05 - val_loss: 1.3562e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 86/100\n",
      "165/165 - 2s - loss: 3.1038e-05 - val_loss: 1.4322e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 87/100\n",
      "165/165 - 2s - loss: 3.1032e-05 - val_loss: 1.4947e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 88/100\n",
      "165/165 - 2s - loss: 3.0966e-05 - val_loss: 1.5454e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 89/100\n",
      "165/165 - 2s - loss: 3.0859e-05 - val_loss: 1.5712e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 90/100\n",
      "165/165 - 2s - loss: 3.0794e-05 - val_loss: 1.5989e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 91/100\n",
      "165/165 - 2s - loss: 3.0765e-05 - val_loss: 1.6282e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 92/100\n",
      "165/165 - 2s - loss: 3.0760e-05 - val_loss: 1.6479e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 93/100\n",
      "165/165 - 2s - loss: 3.0808e-05 - val_loss: 1.6903e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 94/100\n",
      "165/165 - 2s - loss: 3.0697e-05 - val_loss: 1.6862e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 95/100\n",
      "165/165 - 2s - loss: 3.0699e-05 - val_loss: 1.7103e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 96/100\n",
      "165/165 - 2s - loss: 3.1121e-05 - val_loss: 1.8088e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 97/100\n",
      "165/165 - 2s - loss: 3.0639e-05 - val_loss: 1.7350e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 98/100\n",
      "165/165 - 2s - loss: 3.0269e-05 - val_loss: 1.6606e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 99/100\n",
      "165/165 - 2s - loss: 3.0197e-05 - val_loss: 1.6525e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 100/100\n",
      "165/165 - 2s - loss: 3.0523e-05 - val_loss: 1.7334e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 23:32:29.043826: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:32:29.174919: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:32:29.186494: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:32:29.344330: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:32:29.359228: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:32:31.976410: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:32:32.028656: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-20 23:32:32.037536: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 - 4s - loss: 4.5936e-04 - val_loss: 1.9733e-04 - 4s/epoch - 27ms/step\n",
      "Epoch 2/100\n",
      "165/165 - 2s - loss: 2.2477e-04 - val_loss: 2.0551e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 3/100\n",
      "165/165 - 2s - loss: 2.3703e-04 - val_loss: 2.2564e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 4/100\n",
      "165/165 - 2s - loss: 2.8588e-04 - val_loss: 3.0219e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 5/100\n",
      "165/165 - 2s - loss: 3.8620e-04 - val_loss: 6.1511e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 6/100\n",
      "165/165 - 2s - loss: 5.6090e-04 - val_loss: 6.7031e-04 - 2s/epoch - 14ms/step\n",
      "Epoch 7/100\n",
      "165/165 - 2s - loss: 9.3577e-04 - val_loss: 0.0023 - 2s/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "165/165 - 2s - loss: 0.0015 - val_loss: 0.0036 - 2s/epoch - 13ms/step\n",
      "Epoch 9/100\n",
      "165/165 - 2s - loss: 0.0017 - val_loss: 0.0036 - 2s/epoch - 13ms/step\n",
      "Epoch 10/100\n",
      "165/165 - 2s - loss: 0.0017 - val_loss: 0.0053 - 2s/epoch - 14ms/step\n",
      "Epoch 11/100\n",
      "165/165 - 2s - loss: 0.0018 - val_loss: 0.0058 - 2s/epoch - 14ms/step\n",
      "Epoch 12/100\n",
      "165/165 - 2s - loss: 0.0018 - val_loss: 0.0068 - 2s/epoch - 13ms/step\n",
      "Epoch 13/100\n",
      "165/165 - 2s - loss: 0.0018 - val_loss: 0.0066 - 2s/epoch - 13ms/step\n",
      "Epoch 14/100\n",
      "165/165 - 2s - loss: 0.0017 - val_loss: 0.0060 - 2s/epoch - 13ms/step\n",
      "Epoch 15/100\n",
      "165/165 - 2s - loss: 0.0016 - val_loss: 0.0058 - 2s/epoch - 13ms/step\n",
      "Epoch 16/100\n",
      "165/165 - 2s - loss: 0.0017 - val_loss: 0.0052 - 2s/epoch - 13ms/step\n",
      "Epoch 17/100\n",
      "165/165 - 2s - loss: 0.0018 - val_loss: 0.0048 - 2s/epoch - 13ms/step\n",
      "Epoch 18/100\n",
      "165/165 - 2s - loss: 0.0020 - val_loss: 0.0040 - 2s/epoch - 13ms/step\n",
      "Epoch 19/100\n",
      "165/165 - 2s - loss: 0.0021 - val_loss: 0.0027 - 2s/epoch - 13ms/step\n",
      "Epoch 20/100\n",
      "165/165 - 2s - loss: 0.0019 - val_loss: 0.0015 - 2s/epoch - 13ms/step\n",
      "Epoch 21/100\n",
      "165/165 - 2s - loss: 0.0017 - val_loss: 6.0379e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 22/100\n",
      "165/165 - 2s - loss: 0.0013 - val_loss: 1.6099e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 23/100\n",
      "165/165 - 2s - loss: 0.0011 - val_loss: 7.8509e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 24/100\n",
      "165/165 - 2s - loss: 8.5094e-04 - val_loss: 9.1862e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 25/100\n",
      "165/165 - 2s - loss: 6.8525e-04 - val_loss: 9.7518e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 26/100\n",
      "165/165 - 2s - loss: 5.5503e-04 - val_loss: 8.8610e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 27/100\n",
      "165/165 - 2s - loss: 4.5916e-04 - val_loss: 7.2853e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 28/100\n",
      "165/165 - 2s - loss: 3.9363e-04 - val_loss: 5.7361e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 29/100\n",
      "165/165 - 2s - loss: 3.5377e-04 - val_loss: 4.8186e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 30/100\n",
      "165/165 - 2s - loss: 3.3597e-04 - val_loss: 5.1558e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 31/100\n",
      "165/165 - 2s - loss: 3.3810e-04 - val_loss: 7.5022e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 32/100\n",
      "165/165 - 2s - loss: 3.5969e-04 - val_loss: 1.2859e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 33/100\n",
      "165/165 - 2s - loss: 4.0200e-04 - val_loss: 2.2440e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 34/100\n",
      "165/165 - 2s - loss: 4.6766e-04 - val_loss: 3.6689e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 35/100\n",
      "165/165 - 2s - loss: 5.5423e-04 - val_loss: 4.8752e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 36/100\n",
      "165/165 - 2s - loss: 6.5302e-04 - val_loss: 6.0878e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 37/100\n",
      "165/165 - 2s - loss: 7.9665e-04 - val_loss: 0.0011 - 2s/epoch - 14ms/step\n",
      "Epoch 38/100\n",
      "165/165 - 2s - loss: 9.8649e-04 - val_loss: 0.0015 - 2s/epoch - 13ms/step\n",
      "Epoch 39/100\n",
      "165/165 - 2s - loss: 0.0012 - val_loss: 0.0016 - 2s/epoch - 13ms/step\n",
      "Epoch 40/100\n",
      "165/165 - 2s - loss: 0.0014 - val_loss: 9.0796e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 41/100\n",
      "165/165 - 2s - loss: 0.0012 - val_loss: 2.0601e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 42/100\n",
      "165/165 - 2s - loss: 8.4358e-04 - val_loss: 9.5093e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 43/100\n",
      "165/165 - 2s - loss: 5.9394e-04 - val_loss: 2.5867e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 44/100\n",
      "165/165 - 2s - loss: 4.4041e-04 - val_loss: 3.4452e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 45/100\n",
      "165/165 - 2s - loss: 3.3090e-04 - val_loss: 3.4968e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 46/100\n",
      "165/165 - 2s - loss: 2.5681e-04 - val_loss: 2.8806e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 47/100\n",
      "165/165 - 2s - loss: 2.1178e-04 - val_loss: 1.9084e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 48/100\n",
      "165/165 - 2s - loss: 1.8743e-04 - val_loss: 1.1106e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 49/100\n",
      "165/165 - 2s - loss: 1.8210e-04 - val_loss: 5.0663e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 50/100\n",
      "165/165 - 2s - loss: 1.9488e-04 - val_loss: 3.3694e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 51/100\n",
      "165/165 - 2s - loss: 2.2708e-04 - val_loss: 5.8205e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 52/100\n",
      "165/165 - 2s - loss: 2.7371e-04 - val_loss: 1.3741e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 53/100\n",
      "165/165 - 2s - loss: 3.5515e-04 - val_loss: 2.7432e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 54/100\n",
      "165/165 - 2s - loss: 4.5090e-04 - val_loss: 4.4501e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 55/100\n",
      "165/165 - 2s - loss: 5.5014e-04 - val_loss: 7.1258e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 56/100\n",
      "165/165 - 2s - loss: 6.7795e-04 - val_loss: 7.7983e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 57/100\n",
      "165/165 - 2s - loss: 8.2171e-04 - val_loss: 8.6553e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 58/100\n",
      "165/165 - 2s - loss: 9.4677e-04 - val_loss: 6.2853e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 59/100\n",
      "165/165 - 2s - loss: 8.6793e-04 - val_loss: 1.6077e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 60/100\n",
      "165/165 - 2s - loss: 6.3624e-04 - val_loss: 7.5837e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 61/100\n",
      "165/165 - 2s - loss: 4.3218e-04 - val_loss: 2.2920e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 62/100\n",
      "165/165 - 2s - loss: 3.0622e-04 - val_loss: 3.2802e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 63/100\n",
      "165/165 - 2s - loss: 2.3586e-04 - val_loss: 3.0865e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 64/100\n",
      "165/165 - 2s - loss: 1.9082e-04 - val_loss: 2.2859e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 65/100\n",
      "165/165 - 2s - loss: 1.6556e-04 - val_loss: 1.3329e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 66/100\n",
      "165/165 - 2s - loss: 1.5626e-04 - val_loss: 5.5259e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 67/100\n",
      "165/165 - 2s - loss: 1.6293e-04 - val_loss: 2.8282e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 68/100\n",
      "165/165 - 2s - loss: 1.8461e-04 - val_loss: 3.9584e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 69/100\n",
      "165/165 - 2s - loss: 2.2964e-04 - val_loss: 1.1987e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 70/100\n",
      "165/165 - 2s - loss: 3.1071e-04 - val_loss: 2.9151e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 71/100\n",
      "165/165 - 2s - loss: 3.9614e-04 - val_loss: 4.7452e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 72/100\n",
      "165/165 - 2s - loss: 4.5601e-04 - val_loss: 6.1292e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 73/100\n",
      "165/165 - 2s - loss: 5.5305e-04 - val_loss: 7.1307e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 74/100\n",
      "165/165 - 2s - loss: 6.2867e-04 - val_loss: 5.0803e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 75/100\n",
      "165/165 - 2s - loss: 6.4219e-04 - val_loss: 2.3675e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 76/100\n",
      "165/165 - 2s - loss: 5.5122e-04 - val_loss: 6.1363e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 77/100\n",
      "165/165 - 2s - loss: 4.1625e-04 - val_loss: 8.6889e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 78/100\n",
      "165/165 - 2s - loss: 3.0291e-04 - val_loss: 1.7639e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 79/100\n",
      "165/165 - 2s - loss: 2.2968e-04 - val_loss: 2.1286e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 80/100\n",
      "165/165 - 2s - loss: 1.8665e-04 - val_loss: 1.8224e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 81/100\n",
      "165/165 - 2s - loss: 1.6258e-04 - val_loss: 1.2130e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 82/100\n",
      "165/165 - 2s - loss: 1.5310e-04 - val_loss: 6.2413e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 83/100\n",
      "165/165 - 2s - loss: 1.5712e-04 - val_loss: 3.1763e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 84/100\n",
      "165/165 - 2s - loss: 1.7539e-04 - val_loss: 3.6101e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 85/100\n",
      "165/165 - 2s - loss: 2.0922e-04 - val_loss: 8.7533e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 86/100\n",
      "165/165 - 2s - loss: 2.7758e-04 - val_loss: 2.4373e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 87/100\n",
      "165/165 - 2s - loss: 3.6244e-04 - val_loss: 4.9889e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 88/100\n",
      "165/165 - 2s - loss: 4.2569e-04 - val_loss: 5.8815e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 89/100\n",
      "165/165 - 2s - loss: 5.0823e-04 - val_loss: 5.5927e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 90/100\n",
      "165/165 - 2s - loss: 5.3511e-04 - val_loss: 2.8567e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 91/100\n",
      "165/165 - 2s - loss: 4.9394e-04 - val_loss: 9.3343e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 92/100\n",
      "165/165 - 2s - loss: 3.9286e-04 - val_loss: 5.1487e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 93/100\n",
      "165/165 - 2s - loss: 2.8809e-04 - val_loss: 1.2021e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 94/100\n",
      "165/165 - 2s - loss: 2.1630e-04 - val_loss: 1.7372e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 95/100\n",
      "165/165 - 2s - loss: 1.7300e-04 - val_loss: 1.6896e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 96/100\n",
      "165/165 - 2s - loss: 1.4871e-04 - val_loss: 1.2214e-04 - 2s/epoch - 13ms/step\n",
      "Epoch 97/100\n",
      "165/165 - 2s - loss: 1.3851e-04 - val_loss: 6.6343e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 98/100\n",
      "165/165 - 2s - loss: 1.4167e-04 - val_loss: 3.2225e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 99/100\n",
      "165/165 - 2s - loss: 1.5972e-04 - val_loss: 3.6501e-05 - 2s/epoch - 13ms/step\n",
      "Epoch 100/100\n",
      "165/165 - 2s - loss: 1.9357e-04 - val_loss: 9.0497e-05 - 2s/epoch - 13ms/step\n"
     ]
    }
   ],
   "source": [
    "bilstms = []\n",
    "models = []\n",
    "for batch, epoch, neuron in hyperparams:\n",
    "    model, bilstm = LSTMUnit.train_bilstm(train_X, train_y, test_X, test_y, neuron, epoch, batch)\n",
    "    bilstms.append(bilstm)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebe15d8d-6bc9-4220-a7db-48e4d4c7cd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 1s 4ms/step\n",
      "(32, 100, 50)\n",
      "Epoch: 100\n",
      "Neurons: 50\n",
      "2.2704594777712495\n",
      "165/165 [==============================] - 1s 4ms/step\n",
      "(32, 100, 60)\n",
      "Epoch: 100\n",
      "Neurons: 60\n",
      "2.3227820262548904\n",
      "165/165 [==============================] - 1s 5ms/step\n",
      "(32, 100, 100)\n",
      "Epoch: 100\n",
      "Neurons: 100\n",
      "2.6454808486450347\n",
      "165/165 [==============================] - 1s 4ms/step\n",
      "(64, 100, 50)\n",
      "Epoch: 100\n",
      "Neurons: 50\n",
      "1.7405568067028458\n",
      "165/165 [==============================] - 1s 5ms/step\n",
      "(64, 100, 60)\n",
      "Epoch: 100\n",
      "Neurons: 60\n",
      "2.407471091404854\n",
      "165/165 [==============================] - 1s 5ms/step\n",
      "(64, 100, 100)\n",
      "Epoch: 100\n",
      "Neurons: 100\n",
      "1.9559151514036965\n",
      "165/165 [==============================] - 1s 5ms/step\n",
      "(128, 100, 50)\n",
      "Epoch: 100\n",
      "Neurons: 50\n",
      "2.681517325480302\n",
      "165/165 [==============================] - 1s 4ms/step\n",
      "(128, 100, 60)\n",
      "Epoch: 100\n",
      "Neurons: 60\n",
      "1.2012058630029427\n",
      "165/165 [==============================] - 1s 5ms/step\n",
      "(128, 100, 100)\n",
      "Epoch: 100\n",
      "Neurons: 100\n",
      "2.810189132733211\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "i=0\n",
    "for m in models:\n",
    "    test_x2 = test_X\n",
    "    yhat = m.predict(test_x2)\n",
    "    inv_yhat = Preprocessing.inverse_scaler(yhat, scaler)\n",
    "    inv_y = Preprocessing.inverse_scaler(test_y.reshape(-1,1), scaler)\n",
    "    print(hyperparams[i])\n",
    "    print(\"Epoch: \"+ str(bilstms[i].params['epochs']))\n",
    "    print(\"Neurons: \"+str(m.layers[0].layer.units))\n",
    "    print(Evaluation.mape(inv_y,inv_yhat)[0])\n",
    "    with open('BiLSTM_ETH'+str(hyperparams[i])+'.pkl', 'wb') as f:\n",
    "        pickle.dump(bilstms[i].history, f)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3723ed97-4baa-4c5e-9dac-aa107e173d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BiLSTM_ETH(32, 100, 50).pkl', \"rb\") as file_pi:\n",
    "    history = pickle.load(file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb32a172-5a13-4cfc-b543-96f48fe9f368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
