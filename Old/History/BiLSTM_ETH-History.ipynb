{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499ef9d1-2655-483e-9f50-0badccf17d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Skripsi import Preprocessing\n",
    "from Skripsi import Evaluation\n",
    "from Skripsi import LSTMUnit\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openpyxl.workbook import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ed0706-d5c2-4868-beee-6933c00b0a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unix</th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume ETH</th>\n",
       "      <th>Volume USDT</th>\n",
       "      <th>tradecount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1672527600000</td>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>1196.18</td>\n",
       "      <td>1197.43</td>\n",
       "      <td>1193.60</td>\n",
       "      <td>1196.13</td>\n",
       "      <td>5927.43200</td>\n",
       "      <td>7.086714e+06</td>\n",
       "      <td>11029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1672524000000</td>\n",
       "      <td>2022-12-31 22:00:00</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>1200.09</td>\n",
       "      <td>1201.11</td>\n",
       "      <td>1193.08</td>\n",
       "      <td>1196.19</td>\n",
       "      <td>9549.47930</td>\n",
       "      <td>1.143952e+07</td>\n",
       "      <td>13241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1672520400000</td>\n",
       "      <td>2022-12-31 21:00:00</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>1202.33</td>\n",
       "      <td>1203.00</td>\n",
       "      <td>1199.83</td>\n",
       "      <td>1200.10</td>\n",
       "      <td>3865.48620</td>\n",
       "      <td>4.643401e+06</td>\n",
       "      <td>7913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1672516800000</td>\n",
       "      <td>2022-12-31 20:00:00</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>1202.66</td>\n",
       "      <td>1203.71</td>\n",
       "      <td>1202.30</td>\n",
       "      <td>1202.34</td>\n",
       "      <td>3557.34730</td>\n",
       "      <td>4.278879e+06</td>\n",
       "      <td>7917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1672513200000</td>\n",
       "      <td>2022-12-31 19:00:00</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>1199.59</td>\n",
       "      <td>1205.61</td>\n",
       "      <td>1199.42</td>\n",
       "      <td>1202.65</td>\n",
       "      <td>6435.02040</td>\n",
       "      <td>7.738029e+06</td>\n",
       "      <td>9906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26269</th>\n",
       "      <td>1577851200000</td>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>130.21</td>\n",
       "      <td>130.74</td>\n",
       "      <td>130.15</td>\n",
       "      <td>130.20</td>\n",
       "      <td>3397.90747</td>\n",
       "      <td>4.430067e+05</td>\n",
       "      <td>2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>1577847600000</td>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>130.85</td>\n",
       "      <td>130.89</td>\n",
       "      <td>129.94</td>\n",
       "      <td>130.20</td>\n",
       "      <td>4968.55433</td>\n",
       "      <td>6.473610e+05</td>\n",
       "      <td>2818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26271</th>\n",
       "      <td>1577844000000</td>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>130.63</td>\n",
       "      <td>130.98</td>\n",
       "      <td>130.35</td>\n",
       "      <td>130.85</td>\n",
       "      <td>7603.35623</td>\n",
       "      <td>9.940256e+05</td>\n",
       "      <td>3046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>1577840400000</td>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>128.87</td>\n",
       "      <td>130.65</td>\n",
       "      <td>128.78</td>\n",
       "      <td>130.64</td>\n",
       "      <td>11344.65516</td>\n",
       "      <td>1.474278e+06</td>\n",
       "      <td>4885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26273</th>\n",
       "      <td>1577836800000</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>129.16</td>\n",
       "      <td>129.19</td>\n",
       "      <td>128.68</td>\n",
       "      <td>128.87</td>\n",
       "      <td>7769.17336</td>\n",
       "      <td>1.000930e+06</td>\n",
       "      <td>2504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26274 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Unix                 Date   Symbol     Open     High      Low  \\\n",
       "0      1672527600000  2022-12-31 23:00:00  ETHUSDT  1196.18  1197.43  1193.60   \n",
       "1      1672524000000  2022-12-31 22:00:00  ETHUSDT  1200.09  1201.11  1193.08   \n",
       "2      1672520400000  2022-12-31 21:00:00  ETHUSDT  1202.33  1203.00  1199.83   \n",
       "3      1672516800000  2022-12-31 20:00:00  ETHUSDT  1202.66  1203.71  1202.30   \n",
       "4      1672513200000  2022-12-31 19:00:00  ETHUSDT  1199.59  1205.61  1199.42   \n",
       "...              ...                  ...      ...      ...      ...      ...   \n",
       "26269  1577851200000  2020-01-01 04:00:00  ETHUSDT   130.21   130.74   130.15   \n",
       "26270  1577847600000  2020-01-01 03:00:00  ETHUSDT   130.85   130.89   129.94   \n",
       "26271  1577844000000  2020-01-01 02:00:00  ETHUSDT   130.63   130.98   130.35   \n",
       "26272  1577840400000  2020-01-01 01:00:00  ETHUSDT   128.87   130.65   128.78   \n",
       "26273  1577836800000  2020-01-01 00:00:00  ETHUSDT   129.16   129.19   128.68   \n",
       "\n",
       "         Close   Volume ETH   Volume USDT  tradecount  \n",
       "0      1196.13   5927.43200  7.086714e+06       11029  \n",
       "1      1196.19   9549.47930  1.143952e+07       13241  \n",
       "2      1200.10   3865.48620  4.643401e+06        7913  \n",
       "3      1202.34   3557.34730  4.278879e+06        7917  \n",
       "4      1202.65   6435.02040  7.738029e+06        9906  \n",
       "...        ...          ...           ...         ...  \n",
       "26269   130.20   3397.90747  4.430067e+05        2264  \n",
       "26270   130.20   4968.55433  6.473610e+05        2818  \n",
       "26271   130.85   7603.35623  9.940256e+05        3046  \n",
       "26272   130.64  11344.65516  1.474278e+06        4885  \n",
       "26273   128.87   7769.17336  1.000930e+06        2504  \n",
       "\n",
       "[26274 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth_dfd = pd.read_csv('../Dataset/Binance_ETHUSDT_1h.csv')\n",
    "eth_dfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41062755-9cca-4348-91bc-e80d46b79c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume USDT</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129.16</td>\n",
       "      <td>129.19</td>\n",
       "      <td>128.68</td>\n",
       "      <td>1.000930e+06</td>\n",
       "      <td>128.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128.87</td>\n",
       "      <td>130.65</td>\n",
       "      <td>128.78</td>\n",
       "      <td>1.474278e+06</td>\n",
       "      <td>130.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130.63</td>\n",
       "      <td>130.98</td>\n",
       "      <td>130.35</td>\n",
       "      <td>9.940256e+05</td>\n",
       "      <td>130.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130.85</td>\n",
       "      <td>130.89</td>\n",
       "      <td>129.94</td>\n",
       "      <td>6.473610e+05</td>\n",
       "      <td>130.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130.21</td>\n",
       "      <td>130.74</td>\n",
       "      <td>130.15</td>\n",
       "      <td>4.430067e+05</td>\n",
       "      <td>130.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26269</th>\n",
       "      <td>1199.59</td>\n",
       "      <td>1205.61</td>\n",
       "      <td>1199.42</td>\n",
       "      <td>7.738029e+06</td>\n",
       "      <td>1202.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>1202.66</td>\n",
       "      <td>1203.71</td>\n",
       "      <td>1202.30</td>\n",
       "      <td>4.278879e+06</td>\n",
       "      <td>1202.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26271</th>\n",
       "      <td>1202.33</td>\n",
       "      <td>1203.00</td>\n",
       "      <td>1199.83</td>\n",
       "      <td>4.643401e+06</td>\n",
       "      <td>1200.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>1200.09</td>\n",
       "      <td>1201.11</td>\n",
       "      <td>1193.08</td>\n",
       "      <td>1.143952e+07</td>\n",
       "      <td>1196.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26273</th>\n",
       "      <td>1196.18</td>\n",
       "      <td>1197.43</td>\n",
       "      <td>1193.60</td>\n",
       "      <td>7.086714e+06</td>\n",
       "      <td>1196.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26274 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Open     High      Low   Volume USDT    Close\n",
       "0       129.16   129.19   128.68  1.000930e+06   128.87\n",
       "1       128.87   130.65   128.78  1.474278e+06   130.64\n",
       "2       130.63   130.98   130.35  9.940256e+05   130.85\n",
       "3       130.85   130.89   129.94  6.473610e+05   130.20\n",
       "4       130.21   130.74   130.15  4.430067e+05   130.20\n",
       "...        ...      ...      ...           ...      ...\n",
       "26269  1199.59  1205.61  1199.42  7.738029e+06  1202.65\n",
       "26270  1202.66  1203.71  1202.30  4.278879e+06  1202.34\n",
       "26271  1202.33  1203.00  1199.83  4.643401e+06  1200.10\n",
       "26272  1200.09  1201.11  1193.08  1.143952e+07  1196.19\n",
       "26273  1196.18  1197.43  1193.60  7.086714e+06  1196.13\n",
       "\n",
       "[26274 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Preprocessing.feature_selection(eth_dfd)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc368c1b-a82f-4dbf-85c4-f19ebff7a21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume USDT</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129.16</td>\n",
       "      <td>129.19</td>\n",
       "      <td>128.68</td>\n",
       "      <td>1.000930e+06</td>\n",
       "      <td>128.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128.87</td>\n",
       "      <td>130.65</td>\n",
       "      <td>128.78</td>\n",
       "      <td>1.474278e+06</td>\n",
       "      <td>130.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130.63</td>\n",
       "      <td>130.98</td>\n",
       "      <td>130.35</td>\n",
       "      <td>9.940256e+05</td>\n",
       "      <td>130.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130.85</td>\n",
       "      <td>130.89</td>\n",
       "      <td>129.94</td>\n",
       "      <td>6.473610e+05</td>\n",
       "      <td>130.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130.21</td>\n",
       "      <td>130.74</td>\n",
       "      <td>130.15</td>\n",
       "      <td>4.430067e+05</td>\n",
       "      <td>130.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26269</th>\n",
       "      <td>1199.59</td>\n",
       "      <td>1205.61</td>\n",
       "      <td>1199.42</td>\n",
       "      <td>7.738029e+06</td>\n",
       "      <td>1202.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>1202.66</td>\n",
       "      <td>1203.71</td>\n",
       "      <td>1202.30</td>\n",
       "      <td>4.278879e+06</td>\n",
       "      <td>1202.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26271</th>\n",
       "      <td>1202.33</td>\n",
       "      <td>1203.00</td>\n",
       "      <td>1199.83</td>\n",
       "      <td>4.643401e+06</td>\n",
       "      <td>1200.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>1200.09</td>\n",
       "      <td>1201.11</td>\n",
       "      <td>1193.08</td>\n",
       "      <td>1.143952e+07</td>\n",
       "      <td>1196.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26273</th>\n",
       "      <td>1196.18</td>\n",
       "      <td>1197.43</td>\n",
       "      <td>1193.60</td>\n",
       "      <td>7.086714e+06</td>\n",
       "      <td>1196.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26274 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Open     High      Low   Volume USDT    Close\n",
       "0       129.16   129.19   128.68  1.000930e+06   128.87\n",
       "1       128.87   130.65   128.78  1.474278e+06   130.64\n",
       "2       130.63   130.98   130.35  9.940256e+05   130.85\n",
       "3       130.85   130.89   129.94  6.473610e+05   130.20\n",
       "4       130.21   130.74   130.15  4.430067e+05   130.20\n",
       "...        ...      ...      ...           ...      ...\n",
       "26269  1199.59  1205.61  1199.42  7.738029e+06  1202.65\n",
       "26270  1202.66  1203.71  1202.30  4.278879e+06  1202.34\n",
       "26271  1202.33  1203.00  1199.83  4.643401e+06  1200.10\n",
       "26272  1200.09  1201.11  1193.08  1.143952e+07  1196.19\n",
       "26273  1196.18  1197.43  1193.60  7.086714e+06  1196.13\n",
       "\n",
       "[26274 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_dup = Preprocessing.handle_duplicate(df)\n",
    "df_no_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "483f3731-9efb-47c6-af9c-6eadc95287e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss = Preprocessing.handle_missing_value(df_no_dup)\n",
    "miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "140ecfee-f8cf-45f6-b3c6-49e8e7458101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00687306, 0.00493458, 0.00899058, 0.00085515, 0.00678935],\n",
       "       [0.00681201, 0.00524115, 0.00901165, 0.00125955, 0.00716197],\n",
       "       [0.00718251, 0.00531045, 0.00934237, 0.00084925, 0.00720618],\n",
       "       ...,\n",
       "       [0.23278314, 0.23041549, 0.23462933, 0.00396711, 0.23230718],\n",
       "       [0.2323116 , 0.23001863, 0.23320743, 0.00977339, 0.23148404],\n",
       "       [0.23148852, 0.22924589, 0.23331697, 0.00605456, 0.2314714 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, scaler = Preprocessing.minmax_scale(df_no_dup)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c42a7847-70b8-4487-a874-67e370666724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00687306, 0.00493458, 0.00899058, 0.00085515, 0.00678935],\n",
       "       [0.00681201, 0.00524115, 0.00901165, 0.00125955, 0.00716197],\n",
       "       [0.00718251, 0.00531045, 0.00934237, 0.00084925, 0.00720618],\n",
       "       ...,\n",
       "       [0.36569953, 0.36527651, 0.3650033 , 0.03678181, 0.36294049],\n",
       "       [0.36293557, 0.3619231 , 0.35881859, 0.0818867 , 0.35696376],\n",
       "       [0.35696347, 0.35758067, 0.3546814 , 0.09563107, 0.35310278]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = Preprocessing.splitting_data(x)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8e525a6-83d0-4c8b-9875-33e0e15480ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35310067, 0.35162768, 0.34770043, 0.15036013, 0.34664396],\n",
       "       [0.3466423 , 0.3490365 , 0.34609738, 0.1292612 , 0.34877655],\n",
       "       [0.34877474, 0.35155628, 0.35085387, 0.06693593, 0.35186281],\n",
       "       ...,\n",
       "       [0.23278314, 0.23041549, 0.23462933, 0.00396711, 0.23230718],\n",
       "       [0.2323116 , 0.23001863, 0.23320743, 0.00977339, 0.23148404],\n",
       "       [0.23148852, 0.22924589, 0.23331697, 0.00605456, 0.2314714 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08213717-a303-4c9e-97bb-280204035109",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = Preprocessing.create_dataset(train,5)\n",
    "test_X, test_y = Preprocessing.create_dataset(test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aff76bd7-16f2-4bf2-8a64-f1f6a1194661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00687306, 0.00493458, 0.00899058, 0.00085515, 0.00678935],\n",
       "        [0.00681201, 0.00524115, 0.00901165, 0.00125955, 0.00716197],\n",
       "        [0.00718251, 0.00531045, 0.00934237, 0.00084925, 0.00720618],\n",
       "        [0.00722882, 0.00529155, 0.009256  , 0.00055308, 0.00706934],\n",
       "        [0.00709409, 0.00526005, 0.00930024, 0.00037848, 0.00706934]],\n",
       "\n",
       "       [[0.00681201, 0.00524115, 0.00901165, 0.00125955, 0.00716197],\n",
       "        [0.00718251, 0.00531045, 0.00934237, 0.00084925, 0.00720618],\n",
       "        [0.00722882, 0.00529155, 0.009256  , 0.00055308, 0.00706934],\n",
       "        [0.00709409, 0.00526005, 0.00930024, 0.00037848, 0.00706934],\n",
       "        [0.00709199, 0.00520336, 0.00929181, 0.00047243, 0.00709039]],\n",
       "\n",
       "       [[0.00718251, 0.00531045, 0.00934237, 0.00084925, 0.00720618],\n",
       "        [0.00722882, 0.00529155, 0.009256  , 0.00055308, 0.00706934],\n",
       "        [0.00709409, 0.00526005, 0.00930024, 0.00037848, 0.00706934],\n",
       "        [0.00709199, 0.00520336, 0.00929181, 0.00047243, 0.00709039],\n",
       "        [0.00711515, 0.00526215, 0.00932341, 0.00040919, 0.00711987]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.37613858, 0.37420496, 0.37537996, 0.04179294, 0.37471501],\n",
       "        [0.37471134, 0.37201904, 0.37311546, 0.04215226, 0.37165191],\n",
       "        [0.37165057, 0.36909399, 0.36656001, 0.07428193, 0.36419099],\n",
       "        [0.36418598, 0.36338878, 0.36362775, 0.0548782 , 0.36438046],\n",
       "        [0.36437754, 0.36627603, 0.36664216, 0.04812291, 0.36570254]],\n",
       "\n",
       "       [[0.37471134, 0.37201904, 0.37311546, 0.04215226, 0.37165191],\n",
       "        [0.37165057, 0.36909399, 0.36656001, 0.07428193, 0.36419099],\n",
       "        [0.36418598, 0.36338878, 0.36362775, 0.0548782 , 0.36438046],\n",
       "        [0.36437754, 0.36627603, 0.36664216, 0.04812291, 0.36570254],\n",
       "        [0.36569953, 0.36527651, 0.3650033 , 0.03678181, 0.36294049]],\n",
       "\n",
       "       [[0.37165057, 0.36909399, 0.36656001, 0.07428193, 0.36419099],\n",
       "        [0.36418598, 0.36338878, 0.36362775, 0.0548782 , 0.36438046],\n",
       "        [0.36437754, 0.36627603, 0.36664216, 0.04812291, 0.36570254],\n",
       "        [0.36569953, 0.36527651, 0.3650033 , 0.03678181, 0.36294049],\n",
       "        [0.36293557, 0.3619231 , 0.35881859, 0.0818867 , 0.35696376]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4efa14c4-f85e-47c3-bc04-7f0d029d3a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00709039, 0.00711987, 0.00707776, ..., 0.36294049, 0.35696376,\n",
       "       0.35310278])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51dc56af-5903-45ab-a70b-556fb3f3d97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.35310067, 0.35162768, 0.34770043, 0.15036013, 0.34664396],\n",
       "        [0.3466423 , 0.3490365 , 0.34609738, 0.1292612 , 0.34877655],\n",
       "        [0.34877474, 0.35155628, 0.35085387, 0.06693593, 0.35186281],\n",
       "        [0.35186288, 0.35105233, 0.34876   , 0.06304256, 0.34708184],\n",
       "        [0.34708226, 0.34721595, 0.34265955, 0.10696327, 0.34520188]],\n",
       "\n",
       "       [[0.3466423 , 0.3490365 , 0.34609738, 0.1292612 , 0.34877655],\n",
       "        [0.34877474, 0.35155628, 0.35085387, 0.06693593, 0.35186281],\n",
       "        [0.35186288, 0.35105233, 0.34876   , 0.06304256, 0.34708184],\n",
       "        [0.34708226, 0.34721595, 0.34265955, 0.10696327, 0.34520188],\n",
       "        [0.34520033, 0.35104603, 0.3447787 , 0.10501199, 0.35243332]],\n",
       "\n",
       "       [[0.34877474, 0.35155628, 0.35085387, 0.06693593, 0.35186281],\n",
       "        [0.35186288, 0.35105233, 0.34876   , 0.06304256, 0.34708184],\n",
       "        [0.34708226, 0.34721595, 0.34265955, 0.10696327, 0.34520188],\n",
       "        [0.34520033, 0.35104603, 0.3447787 , 0.10501199, 0.35243332],\n",
       "        [0.35243336, 0.35559214, 0.3534828 , 0.09269803, 0.35114703]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.2328926 , 0.23060868, 0.23488843, 0.00498027, 0.23287348],\n",
       "        [0.23287997, 0.23041549, 0.23443342, 0.00812339, 0.23245033],\n",
       "        [0.23245685, 0.22999343, 0.23450504, 0.00350383, 0.23220192],\n",
       "        [0.23220635, 0.23096355, 0.23454296, 0.00661101, 0.23284401],\n",
       "        [0.2328526 , 0.23056458, 0.23514964, 0.00365567, 0.23277875]],\n",
       "\n",
       "       [[0.23287997, 0.23041549, 0.23443342, 0.00812339, 0.23245033],\n",
       "        [0.23245685, 0.22999343, 0.23450504, 0.00350383, 0.23220192],\n",
       "        [0.23220635, 0.23096355, 0.23454296, 0.00661101, 0.23284401],\n",
       "        [0.2328526 , 0.23056458, 0.23514964, 0.00365567, 0.23277875],\n",
       "        [0.23278314, 0.23041549, 0.23462933, 0.00396711, 0.23230718]],\n",
       "\n",
       "       [[0.23245685, 0.22999343, 0.23450504, 0.00350383, 0.23220192],\n",
       "        [0.23220635, 0.23096355, 0.23454296, 0.00661101, 0.23284401],\n",
       "        [0.2328526 , 0.23056458, 0.23514964, 0.00365567, 0.23277875],\n",
       "        [0.23278314, 0.23041549, 0.23462933, 0.00396711, 0.23230718],\n",
       "        [0.2323116 , 0.23001863, 0.23320743, 0.00977339, 0.23148404]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d98152d5-e8c5-4645-90ea-876a042b25e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35243332, 0.35114703, 0.35150913, ..., 0.23230718, 0.23148404,\n",
       "       0.2314714 ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d80df0f9-fe70-44f0-bef3-b779d95da0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21014, 5, 5) (21014,) (5250, 5, 5) (5250,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf43011a-1b18-4fef-b638-d84109a5347b",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c6e3c5f-f40b-427b-bbf6-715de9fbfed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 100, 50),\n",
       " (32, 100, 60),\n",
       " (32, 100, 100),\n",
       " (64, 100, 50),\n",
       " (64, 100, 60),\n",
       " (64, 100, 100),\n",
       " (128, 100, 50),\n",
       " (128, 100, 60),\n",
       " (128, 100, 100)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams = []\n",
    "batch = [32, 64, 128]\n",
    "epoch = [100]\n",
    "neuron = [50, 60, 100]\n",
    "for j in batch:\n",
    "    for k in epoch:\n",
    "        for l in neuron:\n",
    "            hyperparams.append((j,k,l))\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ffd8dc1-5eb8-4d7e-aba2-cab78df020ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 09:56:06.334829: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-21 09:56:06.335301: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-03-21 09:56:06.667755: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 09:56:08.054148: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 09:56:08.231643: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 09:56:08.264737: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 09:56:10.122468: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 09:56:10.138658: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 09:56:18.988715: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 09:56:19.037925: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 09:56:19.046749: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 - 14s - loss: 2.2085e-04 - val_loss: 2.8631e-04 - 14s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "657/657 - 9s - loss: 2.5279e-04 - val_loss: 2.8620e-04 - 9s/epoch - 13ms/step\n",
      "Epoch 3/100\n",
      "657/657 - 9s - loss: 3.5138e-04 - val_loss: 2.1923e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 4/100\n",
      "657/657 - 9s - loss: 5.8333e-04 - val_loss: 3.9043e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 5/100\n",
      "657/657 - 9s - loss: 7.8875e-04 - val_loss: 8.2832e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "657/657 - 9s - loss: 7.3860e-04 - val_loss: 7.0072e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 7/100\n",
      "657/657 - 9s - loss: 6.2234e-04 - val_loss: 4.7254e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "657/657 - 9s - loss: 5.1490e-04 - val_loss: 2.9889e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 9/100\n",
      "657/657 - 9s - loss: 4.3994e-04 - val_loss: 1.9687e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 10/100\n",
      "657/657 - 9s - loss: 3.8884e-04 - val_loss: 1.4032e-04 - 9s/epoch - 13ms/step\n",
      "Epoch 11/100\n",
      "657/657 - 9s - loss: 3.5191e-04 - val_loss: 1.0922e-04 - 9s/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "657/657 - 9s - loss: 3.2386e-04 - val_loss: 8.9825e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "657/657 - 9s - loss: 3.0792e-04 - val_loss: 7.5587e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "657/657 - 9s - loss: 2.9308e-04 - val_loss: 6.6882e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 15/100\n",
      "657/657 - 9s - loss: 2.7795e-04 - val_loss: 6.0030e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "657/657 - 9s - loss: 2.6376e-04 - val_loss: 5.2731e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 17/100\n",
      "657/657 - 9s - loss: 2.5311e-04 - val_loss: 4.7956e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 18/100\n",
      "657/657 - 9s - loss: 2.4351e-04 - val_loss: 4.1929e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 19/100\n",
      "657/657 - 9s - loss: 2.3379e-04 - val_loss: 3.8814e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 20/100\n",
      "657/657 - 9s - loss: 2.2560e-04 - val_loss: 3.6019e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 21/100\n",
      "657/657 - 9s - loss: 2.1882e-04 - val_loss: 3.2935e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 22/100\n",
      "657/657 - 9s - loss: 2.1162e-04 - val_loss: 3.1321e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 23/100\n",
      "657/657 - 9s - loss: 2.0578e-04 - val_loss: 2.9317e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "657/657 - 9s - loss: 1.9993e-04 - val_loss: 2.8142e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 25/100\n",
      "657/657 - 9s - loss: 1.9430e-04 - val_loss: 2.6754e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 26/100\n",
      "657/657 - 9s - loss: 1.8927e-04 - val_loss: 2.5584e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 27/100\n",
      "657/657 - 9s - loss: 1.8452e-04 - val_loss: 2.4845e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 28/100\n",
      "657/657 - 9s - loss: 1.7983e-04 - val_loss: 2.4221e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 29/100\n",
      "657/657 - 9s - loss: 1.7603e-04 - val_loss: 2.3489e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 30/100\n",
      "657/657 - 9s - loss: 1.7220e-04 - val_loss: 2.2968e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 31/100\n",
      "657/657 - 9s - loss: 1.6835e-04 - val_loss: 2.2524e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 32/100\n",
      "657/657 - 9s - loss: 1.6470e-04 - val_loss: 2.2036e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 33/100\n",
      "657/657 - 9s - loss: 1.6155e-04 - val_loss: 2.1781e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 34/100\n",
      "657/657 - 9s - loss: 1.5841e-04 - val_loss: 2.1398e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 35/100\n",
      "657/657 - 9s - loss: 1.5529e-04 - val_loss: 2.1008e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 36/100\n",
      "657/657 - 9s - loss: 1.5242e-04 - val_loss: 2.0639e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 37/100\n",
      "657/657 - 9s - loss: 1.4927e-04 - val_loss: 2.0410e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 38/100\n",
      "657/657 - 9s - loss: 1.4614e-04 - val_loss: 2.0112e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 39/100\n",
      "657/657 - 9s - loss: 1.4337e-04 - val_loss: 1.9973e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 40/100\n",
      "657/657 - 9s - loss: 1.4078e-04 - val_loss: 1.9779e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 41/100\n",
      "657/657 - 9s - loss: 1.3848e-04 - val_loss: 1.9608e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 42/100\n",
      "657/657 - 9s - loss: 1.3617e-04 - val_loss: 1.9386e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 43/100\n",
      "657/657 - 9s - loss: 1.3372e-04 - val_loss: 1.9248e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 44/100\n",
      "657/657 - 9s - loss: 1.3151e-04 - val_loss: 1.9050e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 45/100\n",
      "657/657 - 9s - loss: 1.2896e-04 - val_loss: 1.8958e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 46/100\n",
      "657/657 - 9s - loss: 1.2665e-04 - val_loss: 1.8821e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 47/100\n",
      "657/657 - 9s - loss: 1.2428e-04 - val_loss: 1.8764e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 48/100\n",
      "657/657 - 9s - loss: 1.2206e-04 - val_loss: 1.8679e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 49/100\n",
      "657/657 - 9s - loss: 1.1989e-04 - val_loss: 1.8641e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 50/100\n",
      "657/657 - 9s - loss: 1.1790e-04 - val_loss: 1.8580e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 51/100\n",
      "657/657 - 9s - loss: 1.1594e-04 - val_loss: 1.8558e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 52/100\n",
      "657/657 - 9s - loss: 1.1423e-04 - val_loss: 1.8519e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 53/100\n",
      "657/657 - 9s - loss: 1.1260e-04 - val_loss: 1.8486e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 54/100\n",
      "657/657 - 9s - loss: 1.1110e-04 - val_loss: 1.8433e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 55/100\n",
      "657/657 - 9s - loss: 1.0954e-04 - val_loss: 1.8401e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 56/100\n",
      "657/657 - 9s - loss: 1.0808e-04 - val_loss: 1.8363e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 57/100\n",
      "657/657 - 9s - loss: 1.0655e-04 - val_loss: 1.8351e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 58/100\n",
      "657/657 - 9s - loss: 1.0511e-04 - val_loss: 1.8335e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 59/100\n",
      "657/657 - 9s - loss: 1.0361e-04 - val_loss: 1.8342e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 60/100\n",
      "657/657 - 9s - loss: 1.0218e-04 - val_loss: 1.8349e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 61/100\n",
      "657/657 - 9s - loss: 1.0074e-04 - val_loss: 1.8371e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 62/100\n",
      "657/657 - 9s - loss: 9.9378e-05 - val_loss: 1.8391e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 63/100\n",
      "657/657 - 9s - loss: 9.8035e-05 - val_loss: 1.8412e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 64/100\n",
      "657/657 - 9s - loss: 9.6783e-05 - val_loss: 1.8420e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 65/100\n",
      "657/657 - 9s - loss: 9.5528e-05 - val_loss: 1.8434e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 66/100\n",
      "657/657 - 9s - loss: 9.4357e-05 - val_loss: 1.8435e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 67/100\n",
      "657/657 - 9s - loss: 9.3185e-05 - val_loss: 1.8434e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 68/100\n",
      "657/657 - 9s - loss: 9.2078e-05 - val_loss: 1.8424e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 69/100\n",
      "657/657 - 9s - loss: 9.0951e-05 - val_loss: 1.8417e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 70/100\n",
      "657/657 - 9s - loss: 8.9900e-05 - val_loss: 1.8395e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 71/100\n",
      "657/657 - 9s - loss: 8.8829e-05 - val_loss: 1.8379e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 72/100\n",
      "657/657 - 9s - loss: 8.7826e-05 - val_loss: 1.8347e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 73/100\n",
      "657/657 - 9s - loss: 8.6806e-05 - val_loss: 1.8322e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 74/100\n",
      "657/657 - 9s - loss: 8.5847e-05 - val_loss: 1.8284e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 75/100\n",
      "657/657 - 9s - loss: 8.4887e-05 - val_loss: 1.8243e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 76/100\n",
      "657/657 - 9s - loss: 8.3973e-05 - val_loss: 1.8202e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 77/100\n",
      "657/657 - 9s - loss: 8.3065e-05 - val_loss: 1.8150e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 78/100\n",
      "657/657 - 9s - loss: 8.2196e-05 - val_loss: 1.8105e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 79/100\n",
      "657/657 - 9s - loss: 8.1347e-05 - val_loss: 1.8037e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 80/100\n",
      "657/657 - 9s - loss: 8.0530e-05 - val_loss: 1.7992e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 81/100\n",
      "657/657 - 9s - loss: 7.9731e-05 - val_loss: 1.7919e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 82/100\n",
      "657/657 - 9s - loss: 7.8966e-05 - val_loss: 1.7861e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 83/100\n",
      "657/657 - 9s - loss: 7.8212e-05 - val_loss: 1.7779e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 84/100\n",
      "657/657 - 9s - loss: 7.7497e-05 - val_loss: 1.7714e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 85/100\n",
      "657/657 - 9s - loss: 7.6771e-05 - val_loss: 1.7626e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 86/100\n",
      "657/657 - 9s - loss: 7.6088e-05 - val_loss: 1.7552e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 87/100\n",
      "657/657 - 9s - loss: 7.5395e-05 - val_loss: 1.7453e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 88/100\n",
      "657/657 - 9s - loss: 7.4742e-05 - val_loss: 1.7377e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 89/100\n",
      "657/657 - 9s - loss: 7.4080e-05 - val_loss: 1.7266e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 90/100\n",
      "657/657 - 9s - loss: 7.3455e-05 - val_loss: 1.7185e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 91/100\n",
      "657/657 - 9s - loss: 7.2825e-05 - val_loss: 1.7071e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 92/100\n",
      "657/657 - 9s - loss: 7.2231e-05 - val_loss: 1.6992e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 93/100\n",
      "657/657 - 9s - loss: 7.1635e-05 - val_loss: 1.6876e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 94/100\n",
      "657/657 - 9s - loss: 7.1073e-05 - val_loss: 1.6796e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 95/100\n",
      "657/657 - 9s - loss: 7.0499e-05 - val_loss: 1.6684e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 96/100\n",
      "657/657 - 9s - loss: 6.9961e-05 - val_loss: 1.6605e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 97/100\n",
      "657/657 - 9s - loss: 6.9408e-05 - val_loss: 1.6496e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 98/100\n",
      "657/657 - 9s - loss: 6.8895e-05 - val_loss: 1.6419e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 99/100\n",
      "657/657 - 9s - loss: 6.8366e-05 - val_loss: 1.6319e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 100/100\n",
      "657/657 - 9s - loss: 6.7868e-05 - val_loss: 1.6234e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 10:11:10.753250: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:11:10.919584: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:11:10.932885: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:11:11.043339: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:11:11.063397: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:11:19.944726: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:11:20.000193: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:11:20.009811: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 - 11s - loss: 1.4723e-04 - val_loss: 3.6804e-04 - 11s/epoch - 17ms/step\n",
      "Epoch 2/100\n",
      "657/657 - 9s - loss: 1.8044e-04 - val_loss: 2.7482e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 3/100\n",
      "657/657 - 9s - loss: 1.9044e-04 - val_loss: 2.3666e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 4/100\n",
      "657/657 - 9s - loss: 2.1233e-04 - val_loss: 2.4672e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 5/100\n",
      "657/657 - 9s - loss: 2.8919e-04 - val_loss: 1.9506e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "657/657 - 9s - loss: 4.8839e-04 - val_loss: 2.5747e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 7/100\n",
      "657/657 - 9s - loss: 7.1453e-04 - val_loss: 7.1563e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "657/657 - 9s - loss: 7.0130e-04 - val_loss: 6.7089e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 9/100\n",
      "657/657 - 9s - loss: 5.9496e-04 - val_loss: 4.6543e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 10/100\n",
      "657/657 - 9s - loss: 4.8794e-04 - val_loss: 3.0168e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 11/100\n",
      "657/657 - 9s - loss: 4.1664e-04 - val_loss: 1.9883e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 12/100\n",
      "657/657 - 9s - loss: 3.6788e-04 - val_loss: 1.4197e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "657/657 - 9s - loss: 3.3248e-04 - val_loss: 1.1049e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "657/657 - 9s - loss: 3.0598e-04 - val_loss: 9.1411e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "657/657 - 9s - loss: 2.8809e-04 - val_loss: 7.3206e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "657/657 - 9s - loss: 2.7088e-04 - val_loss: 6.4324e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 17/100\n",
      "657/657 - 9s - loss: 2.5743e-04 - val_loss: 5.7287e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 18/100\n",
      "657/657 - 9s - loss: 2.4699e-04 - val_loss: 5.2483e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 19/100\n",
      "657/657 - 9s - loss: 2.3790e-04 - val_loss: 4.8603e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 20/100\n",
      "657/657 - 9s - loss: 2.3100e-04 - val_loss: 4.4586e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 21/100\n",
      "657/657 - 9s - loss: 2.2273e-04 - val_loss: 4.2937e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 22/100\n",
      "657/657 - 9s - loss: 2.1633e-04 - val_loss: 3.9395e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "657/657 - 9s - loss: 2.0954e-04 - val_loss: 3.6836e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "657/657 - 9s - loss: 2.0288e-04 - val_loss: 3.4510e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 25/100\n",
      "657/657 - 9s - loss: 1.9786e-04 - val_loss: 3.2081e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 26/100\n",
      "657/657 - 9s - loss: 1.9149e-04 - val_loss: 3.0628e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "657/657 - 9s - loss: 1.8658e-04 - val_loss: 2.8716e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 28/100\n",
      "657/657 - 9s - loss: 1.8211e-04 - val_loss: 2.7503e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 29/100\n",
      "657/657 - 9s - loss: 1.7711e-04 - val_loss: 2.6231e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 30/100\n",
      "657/657 - 9s - loss: 1.7345e-04 - val_loss: 2.4949e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 31/100\n",
      "657/657 - 9s - loss: 1.6921e-04 - val_loss: 2.4214e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 32/100\n",
      "657/657 - 9s - loss: 1.6482e-04 - val_loss: 2.3786e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 33/100\n",
      "657/657 - 9s - loss: 1.6142e-04 - val_loss: 2.3520e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 34/100\n",
      "657/657 - 9s - loss: 1.5814e-04 - val_loss: 2.2982e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 35/100\n",
      "657/657 - 9s - loss: 1.5505e-04 - val_loss: 2.2688e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 36/100\n",
      "657/657 - 9s - loss: 1.5191e-04 - val_loss: 2.2342e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 37/100\n",
      "657/657 - 9s - loss: 1.4889e-04 - val_loss: 2.2261e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 38/100\n",
      "657/657 - 9s - loss: 1.4594e-04 - val_loss: 2.1939e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 39/100\n",
      "657/657 - 9s - loss: 1.4325e-04 - val_loss: 2.1779e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 40/100\n",
      "657/657 - 9s - loss: 1.4041e-04 - val_loss: 2.1575e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 41/100\n",
      "657/657 - 9s - loss: 1.3778e-04 - val_loss: 2.1471e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 42/100\n",
      "657/657 - 9s - loss: 1.3527e-04 - val_loss: 2.1266e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 43/100\n",
      "657/657 - 9s - loss: 1.3311e-04 - val_loss: 2.1052e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 44/100\n",
      "657/657 - 9s - loss: 1.3086e-04 - val_loss: 2.0782e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 45/100\n",
      "657/657 - 9s - loss: 1.2866e-04 - val_loss: 2.0680e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 46/100\n",
      "657/657 - 9s - loss: 1.2658e-04 - val_loss: 2.0499e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 47/100\n",
      "657/657 - 9s - loss: 1.2459e-04 - val_loss: 2.0374e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 48/100\n",
      "657/657 - 9s - loss: 1.2271e-04 - val_loss: 2.0168e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 49/100\n",
      "657/657 - 9s - loss: 1.2078e-04 - val_loss: 2.0036e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 50/100\n",
      "657/657 - 9s - loss: 1.1896e-04 - val_loss: 1.9845e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 51/100\n",
      "657/657 - 9s - loss: 1.1715e-04 - val_loss: 1.9664e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 52/100\n",
      "657/657 - 9s - loss: 1.1537e-04 - val_loss: 1.9421e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 53/100\n",
      "657/657 - 10s - loss: 1.1357e-04 - val_loss: 1.9194e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 54/100\n",
      "657/657 - 10s - loss: 1.1189e-04 - val_loss: 1.8942e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 55/100\n",
      "657/657 - 10s - loss: 1.1020e-04 - val_loss: 1.8670e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 56/100\n",
      "657/657 - 10s - loss: 1.0857e-04 - val_loss: 1.8427e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 57/100\n",
      "657/657 - 10s - loss: 1.0689e-04 - val_loss: 1.8196e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 58/100\n",
      "657/657 - 10s - loss: 1.0530e-04 - val_loss: 1.7953e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 59/100\n",
      "657/657 - 10s - loss: 1.0369e-04 - val_loss: 1.7744e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 60/100\n",
      "657/657 - 10s - loss: 1.0209e-04 - val_loss: 1.7534e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 61/100\n",
      "657/657 - 10s - loss: 1.0060e-04 - val_loss: 1.7321e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 62/100\n",
      "657/657 - 10s - loss: 9.9028e-05 - val_loss: 1.7131e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 63/100\n",
      "657/657 - 10s - loss: 9.7452e-05 - val_loss: 1.6947e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 64/100\n",
      "657/657 - 10s - loss: 9.5945e-05 - val_loss: 1.6756e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 65/100\n",
      "657/657 - 10s - loss: 9.4428e-05 - val_loss: 1.6590e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 66/100\n",
      "657/657 - 10s - loss: 9.2975e-05 - val_loss: 1.6428e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 67/100\n",
      "657/657 - 10s - loss: 9.1538e-05 - val_loss: 1.6288e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 68/100\n",
      "657/657 - 10s - loss: 9.0199e-05 - val_loss: 1.6151e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 69/100\n",
      "657/657 - 10s - loss: 8.8819e-05 - val_loss: 1.6042e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 70/100\n",
      "657/657 - 10s - loss: 8.7509e-05 - val_loss: 1.5957e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 71/100\n",
      "657/657 - 10s - loss: 8.6284e-05 - val_loss: 1.5895e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 72/100\n",
      "657/657 - 10s - loss: 8.5100e-05 - val_loss: 1.5869e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 73/100\n",
      "657/657 - 10s - loss: 8.4029e-05 - val_loss: 1.5867e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 74/100\n",
      "657/657 - 10s - loss: 8.3068e-05 - val_loss: 1.5892e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 75/100\n",
      "657/657 - 10s - loss: 8.2252e-05 - val_loss: 1.5930e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 76/100\n",
      "657/657 - 10s - loss: 8.1541e-05 - val_loss: 1.5979e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 77/100\n",
      "657/657 - 10s - loss: 8.0936e-05 - val_loss: 1.6028e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 78/100\n",
      "657/657 - 10s - loss: 8.0405e-05 - val_loss: 1.6071e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 79/100\n",
      "657/657 - 10s - loss: 7.9899e-05 - val_loss: 1.6111e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 80/100\n",
      "657/657 - 10s - loss: 7.9403e-05 - val_loss: 1.6145e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 81/100\n",
      "657/657 - 10s - loss: 7.8898e-05 - val_loss: 1.6179e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 82/100\n",
      "657/657 - 10s - loss: 7.8386e-05 - val_loss: 1.6217e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 83/100\n",
      "657/657 - 10s - loss: 7.7867e-05 - val_loss: 1.6261e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 84/100\n",
      "657/657 - 10s - loss: 7.7348e-05 - val_loss: 1.6310e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 85/100\n",
      "657/657 - 10s - loss: 7.6837e-05 - val_loss: 1.6368e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 86/100\n",
      "657/657 - 10s - loss: 7.6340e-05 - val_loss: 1.6435e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 87/100\n",
      "657/657 - 10s - loss: 7.5859e-05 - val_loss: 1.6505e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 88/100\n",
      "657/657 - 10s - loss: 7.5395e-05 - val_loss: 1.6580e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 89/100\n",
      "657/657 - 10s - loss: 7.4953e-05 - val_loss: 1.6658e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 90/100\n",
      "657/657 - 10s - loss: 7.4535e-05 - val_loss: 1.6728e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 91/100\n",
      "657/657 - 10s - loss: 7.4136e-05 - val_loss: 1.6788e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 92/100\n",
      "657/657 - 10s - loss: 7.3752e-05 - val_loss: 1.6839e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 93/100\n",
      "657/657 - 10s - loss: 7.3376e-05 - val_loss: 1.6885e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 94/100\n",
      "657/657 - 10s - loss: 7.3002e-05 - val_loss: 1.6927e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 95/100\n",
      "657/657 - 10s - loss: 7.2631e-05 - val_loss: 1.6959e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 96/100\n",
      "657/657 - 10s - loss: 7.2257e-05 - val_loss: 1.6985e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "657/657 - 10s - loss: 7.1887e-05 - val_loss: 1.7009e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 98/100\n",
      "657/657 - 10s - loss: 7.1514e-05 - val_loss: 1.7027e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 99/100\n",
      "657/657 - 10s - loss: 7.1152e-05 - val_loss: 1.7044e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 100/100\n",
      "657/657 - 10s - loss: 7.0780e-05 - val_loss: 1.7063e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 10:27:11.828574: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:27:11.992545: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:27:12.007145: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:27:12.255987: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:27:12.275330: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:27:21.974108: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:27:22.041624: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:27:22.051820: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 - 13s - loss: 1.6201e-04 - val_loss: 5.1302e-04 - 13s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "657/657 - 10s - loss: 1.8236e-04 - val_loss: 3.1605e-04 - 10s/epoch - 16ms/step\n",
      "Epoch 3/100\n",
      "657/657 - 10s - loss: 1.8740e-04 - val_loss: 3.1573e-04 - 10s/epoch - 16ms/step\n",
      "Epoch 4/100\n",
      "657/657 - 10s - loss: 2.1248e-04 - val_loss: 4.4784e-04 - 10s/epoch - 16ms/step\n",
      "Epoch 5/100\n",
      "657/657 - 10s - loss: 2.4398e-04 - val_loss: 2.5916e-04 - 10s/epoch - 16ms/step\n",
      "Epoch 6/100\n",
      "657/657 - 10s - loss: 3.5126e-04 - val_loss: 1.9026e-04 - 10s/epoch - 16ms/step\n",
      "Epoch 7/100\n",
      "657/657 - 10s - loss: 6.6379e-04 - val_loss: 4.2065e-04 - 10s/epoch - 16ms/step\n",
      "Epoch 8/100\n",
      "657/657 - 10s - loss: 9.9540e-04 - val_loss: 0.0011 - 10s/epoch - 16ms/step\n",
      "Epoch 9/100\n",
      "657/657 - 10s - loss: 9.3589e-04 - val_loss: 8.9071e-04 - 10s/epoch - 16ms/step\n",
      "Epoch 10/100\n",
      "657/657 - 10s - loss: 7.9155e-04 - val_loss: 5.7346e-04 - 10s/epoch - 16ms/step\n",
      "Epoch 11/100\n",
      "657/657 - 10s - loss: 6.4611e-04 - val_loss: 3.6802e-04 - 10s/epoch - 16ms/step\n",
      "Epoch 12/100\n",
      "657/657 - 10s - loss: 5.4733e-04 - val_loss: 2.4658e-04 - 10s/epoch - 16ms/step\n",
      "Epoch 13/100\n",
      "657/657 - 10s - loss: 4.7189e-04 - val_loss: 1.7397e-04 - 10s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "657/657 - 10s - loss: 4.1296e-04 - val_loss: 1.2822e-04 - 10s/epoch - 16ms/step\n",
      "Epoch 15/100\n",
      "657/657 - 10s - loss: 3.6479e-04 - val_loss: 9.7514e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "657/657 - 10s - loss: 3.2936e-04 - val_loss: 7.3861e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 17/100\n",
      "657/657 - 10s - loss: 2.9960e-04 - val_loss: 5.5255e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 18/100\n",
      "657/657 - 10s - loss: 2.7915e-04 - val_loss: 5.1131e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "657/657 - 10s - loss: 2.6448e-04 - val_loss: 4.3213e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 20/100\n",
      "657/657 - 10s - loss: 2.5046e-04 - val_loss: 4.0866e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 21/100\n",
      "657/657 - 10s - loss: 2.3805e-04 - val_loss: 3.9862e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 22/100\n",
      "657/657 - 10s - loss: 2.2875e-04 - val_loss: 3.6698e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 23/100\n",
      "657/657 - 10s - loss: 2.2145e-04 - val_loss: 3.3835e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 24/100\n",
      "657/657 - 10s - loss: 2.1368e-04 - val_loss: 3.2012e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 25/100\n",
      "657/657 - 10s - loss: 2.0499e-04 - val_loss: 2.8938e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 26/100\n",
      "657/657 - 10s - loss: 1.9723e-04 - val_loss: 2.7260e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 27/100\n",
      "657/657 - 11s - loss: 1.9078e-04 - val_loss: 2.6474e-05 - 11s/epoch - 16ms/step\n",
      "Epoch 28/100\n",
      "657/657 - 10s - loss: 1.8488e-04 - val_loss: 2.4566e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 29/100\n",
      "657/657 - 11s - loss: 1.7976e-04 - val_loss: 2.3696e-05 - 11s/epoch - 16ms/step\n",
      "Epoch 30/100\n",
      "657/657 - 10s - loss: 1.7427e-04 - val_loss: 2.3099e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 31/100\n",
      "657/657 - 10s - loss: 1.6931e-04 - val_loss: 2.2533e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 32/100\n",
      "657/657 - 10s - loss: 1.6449e-04 - val_loss: 2.1692e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 33/100\n",
      "657/657 - 10s - loss: 1.6023e-04 - val_loss: 2.1171e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 34/100\n",
      "657/657 - 10s - loss: 1.5565e-04 - val_loss: 2.0769e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 35/100\n",
      "657/657 - 11s - loss: 1.5193e-04 - val_loss: 2.0408e-05 - 11s/epoch - 16ms/step\n",
      "Epoch 36/100\n",
      "657/657 - 11s - loss: 1.4814e-04 - val_loss: 1.9883e-05 - 11s/epoch - 16ms/step\n",
      "Epoch 37/100\n",
      "657/657 - 10s - loss: 1.4425e-04 - val_loss: 1.9602e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 38/100\n",
      "657/657 - 10s - loss: 1.4093e-04 - val_loss: 1.9000e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 39/100\n",
      "657/657 - 10s - loss: 1.3715e-04 - val_loss: 1.8700e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 40/100\n",
      "657/657 - 10s - loss: 1.3399e-04 - val_loss: 1.8231e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 41/100\n",
      "657/657 - 10s - loss: 1.3107e-04 - val_loss: 1.7891e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 42/100\n",
      "657/657 - 10s - loss: 1.2821e-04 - val_loss: 1.7622e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 43/100\n",
      "657/657 - 10s - loss: 1.2564e-04 - val_loss: 1.7460e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 44/100\n",
      "657/657 - 10s - loss: 1.2346e-04 - val_loss: 1.7190e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 45/100\n",
      "657/657 - 10s - loss: 1.2127e-04 - val_loss: 1.7018e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 46/100\n",
      "657/657 - 10s - loss: 1.1924e-04 - val_loss: 1.6820e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 47/100\n",
      "657/657 - 10s - loss: 1.1731e-04 - val_loss: 1.6695e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 48/100\n",
      "657/657 - 11s - loss: 1.1560e-04 - val_loss: 1.6552e-05 - 11s/epoch - 16ms/step\n",
      "Epoch 49/100\n",
      "657/657 - 11s - loss: 1.1380e-04 - val_loss: 1.6448e-05 - 11s/epoch - 16ms/step\n",
      "Epoch 50/100\n",
      "657/657 - 10s - loss: 1.1212e-04 - val_loss: 1.6342e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 51/100\n",
      "657/657 - 10s - loss: 1.1042e-04 - val_loss: 1.6280e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 52/100\n",
      "657/657 - 10s - loss: 1.0883e-04 - val_loss: 1.6214e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 53/100\n",
      "657/657 - 10s - loss: 1.0732e-04 - val_loss: 1.6167e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 54/100\n",
      "657/657 - 10s - loss: 1.0585e-04 - val_loss: 1.6125e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 55/100\n",
      "657/657 - 11s - loss: 1.0441e-04 - val_loss: 1.6097e-05 - 11s/epoch - 16ms/step\n",
      "Epoch 56/100\n",
      "657/657 - 10s - loss: 1.0313e-04 - val_loss: 1.6061e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "657/657 - 11s - loss: 1.0174e-04 - val_loss: 1.6032e-05 - 11s/epoch - 16ms/step\n",
      "Epoch 58/100\n",
      "657/657 - 11s - loss: 1.0049e-04 - val_loss: 1.6028e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 59/100\n",
      "657/657 - 10s - loss: 9.9197e-05 - val_loss: 1.6004e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 60/100\n",
      "657/657 - 10s - loss: 9.8054e-05 - val_loss: 1.6008e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 61/100\n",
      "657/657 - 10s - loss: 9.6853e-05 - val_loss: 1.5979e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 62/100\n",
      "657/657 - 10s - loss: 9.5749e-05 - val_loss: 1.5986e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 63/100\n",
      "657/657 - 10s - loss: 9.4556e-05 - val_loss: 1.5970e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 64/100\n",
      "657/657 - 10s - loss: 9.3635e-05 - val_loss: 1.5974e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 65/100\n",
      "657/657 - 10s - loss: 9.2466e-05 - val_loss: 1.5947e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 66/100\n",
      "657/657 - 10s - loss: 9.1756e-05 - val_loss: 1.5945e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 67/100\n",
      "657/657 - 10s - loss: 9.0515e-05 - val_loss: 1.5938e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 68/100\n",
      "657/657 - 11s - loss: 8.9867e-05 - val_loss: 1.5945e-05 - 11s/epoch - 16ms/step\n",
      "Epoch 69/100\n",
      "657/657 - 10s - loss: 8.8659e-05 - val_loss: 1.5951e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 70/100\n",
      "657/657 - 10s - loss: 8.7791e-05 - val_loss: 1.5999e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 71/100\n",
      "657/657 - 10s - loss: 8.6620e-05 - val_loss: 1.6047e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 72/100\n",
      "657/657 - 10s - loss: 8.6174e-05 - val_loss: 1.6045e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 73/100\n",
      "657/657 - 10s - loss: 8.5205e-05 - val_loss: 1.6122e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 74/100\n",
      "657/657 - 10s - loss: 8.4118e-05 - val_loss: 1.6215e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 75/100\n",
      "657/657 - 10s - loss: 8.3240e-05 - val_loss: 1.6328e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 76/100\n",
      "657/657 - 10s - loss: 8.2387e-05 - val_loss: 1.6331e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 77/100\n",
      "657/657 - 10s - loss: 8.1644e-05 - val_loss: 1.6554e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 78/100\n",
      "657/657 - 10s - loss: 8.0690e-05 - val_loss: 1.6493e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 79/100\n",
      "657/657 - 10s - loss: 8.0068e-05 - val_loss: 1.6783e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 80/100\n",
      "657/657 - 10s - loss: 7.9058e-05 - val_loss: 1.6661e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 81/100\n",
      "657/657 - 10s - loss: 7.8541e-05 - val_loss: 1.6982e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 82/100\n",
      "657/657 - 10s - loss: 7.7456e-05 - val_loss: 1.6770e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 83/100\n",
      "657/657 - 10s - loss: 7.6831e-05 - val_loss: 1.7184e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 84/100\n",
      "657/657 - 10s - loss: 7.5855e-05 - val_loss: 1.6939e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 85/100\n",
      "657/657 - 10s - loss: 7.5258e-05 - val_loss: 1.7357e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 86/100\n",
      "657/657 - 10s - loss: 7.4386e-05 - val_loss: 1.7088e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 87/100\n",
      "657/657 - 10s - loss: 7.3750e-05 - val_loss: 1.7489e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 88/100\n",
      "657/657 - 10s - loss: 7.2946e-05 - val_loss: 1.7264e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 89/100\n",
      "657/657 - 10s - loss: 7.2336e-05 - val_loss: 1.7578e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 90/100\n",
      "657/657 - 10s - loss: 7.1649e-05 - val_loss: 1.7416e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 91/100\n",
      "657/657 - 11s - loss: 7.1132e-05 - val_loss: 1.7624e-05 - 11s/epoch - 16ms/step\n",
      "Epoch 92/100\n",
      "657/657 - 10s - loss: 7.0600e-05 - val_loss: 1.7458e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 93/100\n",
      "657/657 - 10s - loss: 7.0162e-05 - val_loss: 1.7588e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 94/100\n",
      "657/657 - 10s - loss: 6.9695e-05 - val_loss: 1.7427e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 95/100\n",
      "657/657 - 10s - loss: 6.9295e-05 - val_loss: 1.7485e-05 - 10s/epoch - 15ms/step\n",
      "Epoch 96/100\n",
      "657/657 - 10s - loss: 6.8868e-05 - val_loss: 1.7300e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "657/657 - 10s - loss: 6.8407e-05 - val_loss: 1.7305e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 98/100\n",
      "657/657 - 11s - loss: 6.7959e-05 - val_loss: 1.7113e-05 - 11s/epoch - 16ms/step\n",
      "Epoch 99/100\n",
      "657/657 - 10s - loss: 6.7560e-05 - val_loss: 1.7106e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 100/100\n",
      "657/657 - 10s - loss: 6.7216e-05 - val_loss: 1.6881e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 10:44:28.600574: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:44:28.806725: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:44:28.824004: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:44:28.969557: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:44:28.990164: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:44:34.398212: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:44:34.463722: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:44:34.474833: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 - 8s - loss: 3.4033e-04 - val_loss: 6.7056e-04 - 8s/epoch - 23ms/step\n",
      "Epoch 2/100\n",
      "329/329 - 5s - loss: 5.5623e-04 - val_loss: 4.0809e-04 - 5s/epoch - 15ms/step\n",
      "Epoch 3/100\n",
      "329/329 - 5s - loss: 3.9330e-04 - val_loss: 2.3361e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 4/100\n",
      "329/329 - 5s - loss: 3.0909e-04 - val_loss: 1.5827e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 5/100\n",
      "329/329 - 5s - loss: 2.6715e-04 - val_loss: 1.2494e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 6/100\n",
      "329/329 - 5s - loss: 2.4160e-04 - val_loss: 1.0467e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 7/100\n",
      "329/329 - 5s - loss: 2.2023e-04 - val_loss: 9.0319e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 8/100\n",
      "329/329 - 5s - loss: 2.0153e-04 - val_loss: 8.0102e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 9/100\n",
      "329/329 - 5s - loss: 1.8518e-04 - val_loss: 7.2700e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 10/100\n",
      "329/329 - 5s - loss: 1.7111e-04 - val_loss: 6.7122e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 11/100\n",
      "329/329 - 5s - loss: 1.5937e-04 - val_loss: 6.2893e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 12/100\n",
      "329/329 - 5s - loss: 1.4979e-04 - val_loss: 5.9804e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 13/100\n",
      "329/329 - 5s - loss: 1.4254e-04 - val_loss: 5.7997e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "329/329 - 5s - loss: 1.3714e-04 - val_loss: 5.7665e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 15/100\n",
      "329/329 - 5s - loss: 1.3319e-04 - val_loss: 5.9039e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "329/329 - 5s - loss: 1.3122e-04 - val_loss: 6.3210e-05 - 5s/epoch - 15ms/step\n",
      "Epoch 17/100\n",
      "329/329 - 5s - loss: 1.3102e-04 - val_loss: 7.0207e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 18/100\n",
      "329/329 - 5s - loss: 1.3151e-04 - val_loss: 7.6748e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "329/329 - 5s - loss: 1.3060e-04 - val_loss: 8.0934e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 20/100\n",
      "329/329 - 5s - loss: 1.2740e-04 - val_loss: 8.1189e-05 - 5s/epoch - 15ms/step\n",
      "Epoch 21/100\n",
      "329/329 - 5s - loss: 1.1858e-04 - val_loss: 7.5504e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 22/100\n",
      "329/329 - 5s - loss: 1.1516e-04 - val_loss: 7.3025e-05 - 5s/epoch - 15ms/step\n",
      "Epoch 23/100\n",
      "329/329 - 5s - loss: 1.1491e-04 - val_loss: 7.4409e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 24/100\n",
      "329/329 - 5s - loss: 1.1598e-04 - val_loss: 7.7787e-05 - 5s/epoch - 15ms/step\n",
      "Epoch 25/100\n",
      "329/329 - 5s - loss: 1.1236e-04 - val_loss: 7.6972e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 26/100\n",
      "329/329 - 5s - loss: 1.1116e-04 - val_loss: 7.8214e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 27/100\n",
      "329/329 - 5s - loss: 1.0746e-04 - val_loss: 7.4751e-05 - 5s/epoch - 15ms/step\n",
      "Epoch 28/100\n",
      "329/329 - 5s - loss: 1.0385e-04 - val_loss: 7.2526e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 29/100\n",
      "329/329 - 5s - loss: 1.0106e-04 - val_loss: 7.0938e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 30/100\n",
      "329/329 - 5s - loss: 1.0089e-04 - val_loss: 7.3042e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 31/100\n",
      "329/329 - 5s - loss: 1.0036e-04 - val_loss: 7.3748e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 32/100\n",
      "329/329 - 5s - loss: 9.6376e-05 - val_loss: 7.0498e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 33/100\n",
      "329/329 - 5s - loss: 9.4547e-05 - val_loss: 7.0083e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 34/100\n",
      "329/329 - 5s - loss: 9.0355e-05 - val_loss: 6.5632e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 35/100\n",
      "329/329 - 5s - loss: 8.9639e-05 - val_loss: 6.5613e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 36/100\n",
      "329/329 - 5s - loss: 8.6643e-05 - val_loss: 6.3659e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 37/100\n",
      "329/329 - 5s - loss: 8.7107e-05 - val_loss: 6.6190e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 38/100\n",
      "329/329 - 5s - loss: 8.5094e-05 - val_loss: 6.4810e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 39/100\n",
      "329/329 - 5s - loss: 8.3257e-05 - val_loss: 6.4231e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 40/100\n",
      "329/329 - 5s - loss: 8.1974e-05 - val_loss: 6.3192e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 41/100\n",
      "329/329 - 5s - loss: 8.1037e-05 - val_loss: 6.3049e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 42/100\n",
      "329/329 - 5s - loss: 7.9012e-05 - val_loss: 6.1854e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 43/100\n",
      "329/329 - 5s - loss: 8.0195e-05 - val_loss: 6.4597e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 44/100\n",
      "329/329 - 5s - loss: 7.7214e-05 - val_loss: 6.1908e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 45/100\n",
      "329/329 - 5s - loss: 7.6052e-05 - val_loss: 6.1033e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 46/100\n",
      "329/329 - 5s - loss: 7.5376e-05 - val_loss: 5.9786e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 47/100\n",
      "329/329 - 5s - loss: 7.4578e-05 - val_loss: 5.9834e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 48/100\n",
      "329/329 - 5s - loss: 7.3392e-05 - val_loss: 5.9131e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 49/100\n",
      "329/329 - 5s - loss: 7.3083e-05 - val_loss: 5.8528e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 50/100\n",
      "329/329 - 5s - loss: 7.1946e-05 - val_loss: 5.9017e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 51/100\n",
      "329/329 - 5s - loss: 7.1304e-05 - val_loss: 5.7433e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 52/100\n",
      "329/329 - 5s - loss: 7.0417e-05 - val_loss: 5.7421e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 53/100\n",
      "329/329 - 5s - loss: 6.9558e-05 - val_loss: 5.6883e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 54/100\n",
      "329/329 - 5s - loss: 6.9190e-05 - val_loss: 5.6062e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 55/100\n",
      "329/329 - 5s - loss: 6.8332e-05 - val_loss: 5.5678e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 56/100\n",
      "329/329 - 5s - loss: 6.7467e-05 - val_loss: 5.4457e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "329/329 - 5s - loss: 6.6966e-05 - val_loss: 5.4063e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 58/100\n",
      "329/329 - 5s - loss: 6.6076e-05 - val_loss: 5.4135e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 59/100\n",
      "329/329 - 5s - loss: 6.5807e-05 - val_loss: 5.3359e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 60/100\n",
      "329/329 - 5s - loss: 6.5114e-05 - val_loss: 5.3113e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 61/100\n",
      "329/329 - 5s - loss: 6.4553e-05 - val_loss: 5.2207e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 62/100\n",
      "329/329 - 5s - loss: 6.3704e-05 - val_loss: 5.1227e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 63/100\n",
      "329/329 - 5s - loss: 6.3081e-05 - val_loss: 5.0338e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 64/100\n",
      "329/329 - 5s - loss: 6.2663e-05 - val_loss: 5.1024e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 65/100\n",
      "329/329 - 5s - loss: 6.2502e-05 - val_loss: 5.0419e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 66/100\n",
      "329/329 - 5s - loss: 6.1554e-05 - val_loss: 5.0251e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 67/100\n",
      "329/329 - 5s - loss: 6.1218e-05 - val_loss: 4.9082e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 68/100\n",
      "329/329 - 5s - loss: 6.0185e-05 - val_loss: 4.8614e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 69/100\n",
      "329/329 - 5s - loss: 5.9787e-05 - val_loss: 4.7732e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 70/100\n",
      "329/329 - 5s - loss: 5.9213e-05 - val_loss: 4.6990e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 71/100\n",
      "329/329 - 5s - loss: 5.9023e-05 - val_loss: 4.6884e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 72/100\n",
      "329/329 - 5s - loss: 5.8438e-05 - val_loss: 4.6795e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 73/100\n",
      "329/329 - 5s - loss: 5.7993e-05 - val_loss: 4.6182e-05 - 5s/epoch - 15ms/step\n",
      "Epoch 74/100\n",
      "329/329 - 5s - loss: 5.7412e-05 - val_loss: 4.5834e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 75/100\n",
      "329/329 - 5s - loss: 5.7154e-05 - val_loss: 4.5277e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 76/100\n",
      "329/329 - 5s - loss: 5.6539e-05 - val_loss: 4.4867e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 77/100\n",
      "329/329 - 5s - loss: 5.6093e-05 - val_loss: 4.4453e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 78/100\n",
      "329/329 - 5s - loss: 5.5720e-05 - val_loss: 4.4178e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 79/100\n",
      "329/329 - 5s - loss: 5.5421e-05 - val_loss: 4.3799e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 80/100\n",
      "329/329 - 5s - loss: 5.4937e-05 - val_loss: 4.3582e-05 - 5s/epoch - 15ms/step\n",
      "Epoch 81/100\n",
      "329/329 - 5s - loss: 5.4544e-05 - val_loss: 4.3264e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 82/100\n",
      "329/329 - 5s - loss: 5.4254e-05 - val_loss: 4.3070e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 83/100\n",
      "329/329 - 5s - loss: 5.3728e-05 - val_loss: 4.2841e-05 - 5s/epoch - 15ms/step\n",
      "Epoch 84/100\n",
      "329/329 - 5s - loss: 5.3465e-05 - val_loss: 4.2552e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 85/100\n",
      "329/329 - 5s - loss: 5.2936e-05 - val_loss: 4.2097e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 86/100\n",
      "329/329 - 5s - loss: 5.2607e-05 - val_loss: 4.2153e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 87/100\n",
      "329/329 - 5s - loss: 5.2417e-05 - val_loss: 4.1679e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 88/100\n",
      "329/329 - 5s - loss: 5.2122e-05 - val_loss: 4.1591e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 89/100\n",
      "329/329 - 5s - loss: 5.1738e-05 - val_loss: 4.1529e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 90/100\n",
      "329/329 - 5s - loss: 5.1524e-05 - val_loss: 4.1353e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 91/100\n",
      "329/329 - 5s - loss: 5.1192e-05 - val_loss: 4.1395e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 92/100\n",
      "329/329 - 5s - loss: 5.0939e-05 - val_loss: 4.1491e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 93/100\n",
      "329/329 - 5s - loss: 5.0659e-05 - val_loss: 4.1393e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 94/100\n",
      "329/329 - 5s - loss: 5.0512e-05 - val_loss: 4.1459e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 95/100\n",
      "329/329 - 5s - loss: 5.0125e-05 - val_loss: 4.1389e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 96/100\n",
      "329/329 - 5s - loss: 4.9854e-05 - val_loss: 4.1261e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "329/329 - 5s - loss: 4.9639e-05 - val_loss: 4.1126e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 98/100\n",
      "329/329 - 5s - loss: 4.9289e-05 - val_loss: 4.1661e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 99/100\n",
      "329/329 - 5s - loss: 4.9229e-05 - val_loss: 4.1499e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 100/100\n",
      "329/329 - 5s - loss: 4.8832e-05 - val_loss: 4.2028e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 10:53:11.123618: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:53:11.304545: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:53:11.325316: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:53:11.555111: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:53:11.576374: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:53:16.920241: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:53:16.979818: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:53:16.990624: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 - 8s - loss: 1.6902e-04 - val_loss: 7.6451e-05 - 8s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "329/329 - 5s - loss: 2.1434e-04 - val_loss: 7.0830e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 3/100\n",
      "329/329 - 5s - loss: 3.8761e-04 - val_loss: 5.1012e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 4/100\n",
      "329/329 - 5s - loss: 3.6377e-04 - val_loss: 4.1492e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 5/100\n",
      "329/329 - 5s - loss: 2.7657e-04 - val_loss: 2.4021e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 6/100\n",
      "329/329 - 5s - loss: 1.9681e-04 - val_loss: 1.5613e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 7/100\n",
      "329/329 - 6s - loss: 1.6513e-04 - val_loss: 1.1405e-04 - 6s/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "329/329 - 5s - loss: 1.5482e-04 - val_loss: 9.3922e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 9/100\n",
      "329/329 - 5s - loss: 1.5270e-04 - val_loss: 8.9625e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 10/100\n",
      "329/329 - 5s - loss: 1.5317e-04 - val_loss: 9.4385e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 11/100\n",
      "329/329 - 5s - loss: 1.5342e-04 - val_loss: 1.0239e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 12/100\n",
      "329/329 - 5s - loss: 1.5240e-04 - val_loss: 1.0935e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 13/100\n",
      "329/329 - 5s - loss: 1.5114e-04 - val_loss: 1.1522e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "329/329 - 5s - loss: 1.5097e-04 - val_loss: 1.2094e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 15/100\n",
      "329/329 - 5s - loss: 1.5041e-04 - val_loss: 1.2345e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "329/329 - 5s - loss: 1.4397e-04 - val_loss: 1.1576e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 17/100\n",
      "329/329 - 5s - loss: 1.3734e-04 - val_loss: 1.0783e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 18/100\n",
      "329/329 - 5s - loss: 1.3054e-04 - val_loss: 9.9343e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "329/329 - 5s - loss: 1.2846e-04 - val_loss: 9.7349e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 20/100\n",
      "329/329 - 5s - loss: 1.2632e-04 - val_loss: 9.6232e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 21/100\n",
      "329/329 - 5s - loss: 1.2752e-04 - val_loss: 9.9897e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 22/100\n",
      "329/329 - 5s - loss: 1.2383e-04 - val_loss: 9.6926e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 23/100\n",
      "329/329 - 5s - loss: 1.1957e-04 - val_loss: 9.1964e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 24/100\n",
      "329/329 - 5s - loss: 1.1732e-04 - val_loss: 8.9822e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 25/100\n",
      "329/329 - 5s - loss: 1.1327e-04 - val_loss: 8.5202e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 26/100\n",
      "329/329 - 5s - loss: 1.1352e-04 - val_loss: 8.7429e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 27/100\n",
      "329/329 - 5s - loss: 1.1088e-04 - val_loss: 8.4194e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 28/100\n",
      "329/329 - 5s - loss: 1.0861e-04 - val_loss: 8.1441e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 29/100\n",
      "329/329 - 5s - loss: 1.0511e-04 - val_loss: 7.8888e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 30/100\n",
      "329/329 - 5s - loss: 1.0369e-04 - val_loss: 7.8162e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 31/100\n",
      "329/329 - 5s - loss: 1.0464e-04 - val_loss: 8.0701e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 32/100\n",
      "329/329 - 5s - loss: 1.0103e-04 - val_loss: 7.5955e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 33/100\n",
      "329/329 - 5s - loss: 9.8200e-05 - val_loss: 7.2571e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 34/100\n",
      "329/329 - 5s - loss: 9.5472e-05 - val_loss: 6.9544e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 35/100\n",
      "329/329 - 5s - loss: 9.4589e-05 - val_loss: 6.9485e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 36/100\n",
      "329/329 - 5s - loss: 9.3622e-05 - val_loss: 6.9804e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 37/100\n",
      "329/329 - 5s - loss: 9.2482e-05 - val_loss: 7.1121e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 38/100\n",
      "329/329 - 5s - loss: 9.2683e-05 - val_loss: 7.4124e-05 - 5s/epoch - 17ms/step\n",
      "Epoch 39/100\n",
      "329/329 - 5s - loss: 9.0998e-05 - val_loss: 7.3017e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 40/100\n",
      "329/329 - 5s - loss: 9.0017e-05 - val_loss: 7.3649e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 41/100\n",
      "329/329 - 5s - loss: 8.8533e-05 - val_loss: 7.3092e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 42/100\n",
      "329/329 - 6s - loss: 8.7600e-05 - val_loss: 7.2710e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 43/100\n",
      "329/329 - 5s - loss: 8.6308e-05 - val_loss: 7.1490e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 44/100\n",
      "329/329 - 5s - loss: 8.5327e-05 - val_loss: 7.1815e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 45/100\n",
      "329/329 - 5s - loss: 8.4871e-05 - val_loss: 7.1978e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 46/100\n",
      "329/329 - 5s - loss: 8.4386e-05 - val_loss: 7.1645e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 47/100\n",
      "329/329 - 5s - loss: 8.3366e-05 - val_loss: 7.1014e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 48/100\n",
      "329/329 - 5s - loss: 8.1672e-05 - val_loss: 6.9458e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 49/100\n",
      "329/329 - 5s - loss: 8.0572e-05 - val_loss: 6.8898e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 50/100\n",
      "329/329 - 5s - loss: 8.0021e-05 - val_loss: 6.9319e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 51/100\n",
      "329/329 - 5s - loss: 7.9521e-05 - val_loss: 7.0187e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 52/100\n",
      "329/329 - 5s - loss: 7.9546e-05 - val_loss: 7.0676e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 53/100\n",
      "329/329 - 5s - loss: 7.8140e-05 - val_loss: 6.9589e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 54/100\n",
      "329/329 - 5s - loss: 7.7084e-05 - val_loss: 6.8784e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 55/100\n",
      "329/329 - 5s - loss: 7.6716e-05 - val_loss: 6.9132e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 56/100\n",
      "329/329 - 5s - loss: 7.5751e-05 - val_loss: 6.8818e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "329/329 - 5s - loss: 7.5067e-05 - val_loss: 6.8083e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 58/100\n",
      "329/329 - 5s - loss: 7.4194e-05 - val_loss: 6.7925e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 59/100\n",
      "329/329 - 5s - loss: 7.4016e-05 - val_loss: 6.7520e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 60/100\n",
      "329/329 - 5s - loss: 7.3079e-05 - val_loss: 6.7213e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 61/100\n",
      "329/329 - 5s - loss: 7.3068e-05 - val_loss: 6.8048e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 62/100\n",
      "329/329 - 5s - loss: 7.2123e-05 - val_loss: 6.6628e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 63/100\n",
      "329/329 - 5s - loss: 7.1442e-05 - val_loss: 6.6169e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 64/100\n",
      "329/329 - 5s - loss: 7.0897e-05 - val_loss: 6.5814e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 65/100\n",
      "329/329 - 5s - loss: 7.0402e-05 - val_loss: 6.5689e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 66/100\n",
      "329/329 - 5s - loss: 6.9246e-05 - val_loss: 6.5050e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 67/100\n",
      "329/329 - 5s - loss: 6.9073e-05 - val_loss: 6.5495e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 68/100\n",
      "329/329 - 5s - loss: 6.8629e-05 - val_loss: 6.5037e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 69/100\n",
      "329/329 - 5s - loss: 6.8083e-05 - val_loss: 6.5490e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 70/100\n",
      "329/329 - 5s - loss: 6.8250e-05 - val_loss: 6.6379e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 71/100\n",
      "329/329 - 5s - loss: 6.7287e-05 - val_loss: 6.5660e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 72/100\n",
      "329/329 - 5s - loss: 6.6503e-05 - val_loss: 6.4978e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 73/100\n",
      "329/329 - 5s - loss: 6.6123e-05 - val_loss: 6.5326e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 74/100\n",
      "329/329 - 5s - loss: 6.6022e-05 - val_loss: 6.5362e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 75/100\n",
      "329/329 - 5s - loss: 6.5530e-05 - val_loss: 6.5883e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 76/100\n",
      "329/329 - 5s - loss: 6.5358e-05 - val_loss: 6.6215e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 77/100\n",
      "329/329 - 5s - loss: 6.4498e-05 - val_loss: 6.5768e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 78/100\n",
      "329/329 - 5s - loss: 6.4113e-05 - val_loss: 6.5916e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 79/100\n",
      "329/329 - 5s - loss: 6.3580e-05 - val_loss: 6.5477e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 80/100\n",
      "329/329 - 5s - loss: 6.3210e-05 - val_loss: 6.5683e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 81/100\n",
      "329/329 - 5s - loss: 6.3014e-05 - val_loss: 6.6221e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 82/100\n",
      "329/329 - 5s - loss: 6.2763e-05 - val_loss: 6.6967e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 83/100\n",
      "329/329 - 5s - loss: 6.2163e-05 - val_loss: 6.6638e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 84/100\n",
      "329/329 - 5s - loss: 6.1951e-05 - val_loss: 6.7357e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 85/100\n",
      "329/329 - 5s - loss: 6.1502e-05 - val_loss: 6.6709e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 86/100\n",
      "329/329 - 5s - loss: 6.0947e-05 - val_loss: 6.7186e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 87/100\n",
      "329/329 - 5s - loss: 6.0598e-05 - val_loss: 6.7084e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 88/100\n",
      "329/329 - 5s - loss: 6.0101e-05 - val_loss: 6.7423e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 89/100\n",
      "329/329 - 5s - loss: 6.0157e-05 - val_loss: 6.8509e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 90/100\n",
      "329/329 - 5s - loss: 5.9953e-05 - val_loss: 6.9345e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 91/100\n",
      "329/329 - 5s - loss: 5.9404e-05 - val_loss: 6.9598e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 92/100\n",
      "329/329 - 5s - loss: 5.9165e-05 - val_loss: 6.9982e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 93/100\n",
      "329/329 - 5s - loss: 5.8696e-05 - val_loss: 7.0314e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 94/100\n",
      "329/329 - 5s - loss: 5.8591e-05 - val_loss: 7.1391e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 95/100\n",
      "329/329 - 5s - loss: 5.8182e-05 - val_loss: 7.1317e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 96/100\n",
      "329/329 - 5s - loss: 5.8030e-05 - val_loss: 7.2224e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "329/329 - 5s - loss: 5.7329e-05 - val_loss: 7.1740e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 98/100\n",
      "329/329 - 5s - loss: 5.7223e-05 - val_loss: 7.2876e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 99/100\n",
      "329/329 - 5s - loss: 5.6773e-05 - val_loss: 7.3125e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 100/100\n",
      "329/329 - 5s - loss: 5.6732e-05 - val_loss: 7.4244e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:01:57.489275: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:01:57.659114: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:01:57.673396: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:01:57.994244: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:01:58.013471: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:02:03.384018: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:02:03.445262: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:02:03.456374: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 - 8s - loss: 1.9301e-04 - val_loss: 1.1784e-04 - 8s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "329/329 - 5s - loss: 2.7321e-04 - val_loss: 1.2689e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 3/100\n",
      "329/329 - 5s - loss: 5.3232e-04 - val_loss: 9.1985e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 4/100\n",
      "329/329 - 6s - loss: 4.6731e-04 - val_loss: 6.2778e-04 - 6s/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "329/329 - 5s - loss: 3.7427e-04 - val_loss: 3.8091e-04 - 5s/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "329/329 - 5s - loss: 2.6190e-04 - val_loss: 2.5873e-04 - 5s/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "329/329 - 5s - loss: 2.1125e-04 - val_loss: 1.9304e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 8/100\n",
      "329/329 - 5s - loss: 1.9071e-04 - val_loss: 1.5603e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 9/100\n",
      "329/329 - 5s - loss: 1.8461e-04 - val_loss: 1.4233e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 10/100\n",
      "329/329 - 5s - loss: 1.8345e-04 - val_loss: 1.4325e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 11/100\n",
      "329/329 - 5s - loss: 1.8266e-04 - val_loss: 1.4980e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 12/100\n",
      "329/329 - 5s - loss: 1.8050e-04 - val_loss: 1.5566e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 13/100\n",
      "329/329 - 5s - loss: 1.8011e-04 - val_loss: 1.6391e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "329/329 - 5s - loss: 1.8668e-04 - val_loss: 1.7532e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 15/100\n",
      "329/329 - 5s - loss: 1.8007e-04 - val_loss: 1.6640e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "329/329 - 5s - loss: 1.7070e-04 - val_loss: 1.5129e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 17/100\n",
      "329/329 - 5s - loss: 1.6248e-04 - val_loss: 1.3778e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 18/100\n",
      "329/329 - 5s - loss: 1.4974e-04 - val_loss: 1.2301e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "329/329 - 5s - loss: 1.4169e-04 - val_loss: 1.1319e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 20/100\n",
      "329/329 - 5s - loss: 1.4190e-04 - val_loss: 1.1521e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 21/100\n",
      "329/329 - 5s - loss: 1.4791e-04 - val_loss: 1.2407e-04 - 5s/epoch - 17ms/step\n",
      "Epoch 22/100\n",
      "329/329 - 5s - loss: 1.4260e-04 - val_loss: 1.1991e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 23/100\n",
      "329/329 - 5s - loss: 1.3658e-04 - val_loss: 1.1221e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 24/100\n",
      "329/329 - 5s - loss: 1.2611e-04 - val_loss: 1.0014e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 25/100\n",
      "329/329 - 5s - loss: 1.2546e-04 - val_loss: 9.8408e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 26/100\n",
      "329/329 - 5s - loss: 1.2452e-04 - val_loss: 1.0068e-04 - 5s/epoch - 16ms/step\n",
      "Epoch 27/100\n",
      "329/329 - 5s - loss: 1.2214e-04 - val_loss: 9.7914e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 28/100\n",
      "329/329 - 5s - loss: 1.2543e-04 - val_loss: 1.0084e-04 - 5s/epoch - 17ms/step\n",
      "Epoch 29/100\n",
      "329/329 - 6s - loss: 1.1534e-04 - val_loss: 9.1527e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 30/100\n",
      "329/329 - 5s - loss: 1.1240e-04 - val_loss: 8.3850e-05 - 5s/epoch - 17ms/step\n",
      "Epoch 31/100\n",
      "329/329 - 5s - loss: 1.0948e-04 - val_loss: 8.2492e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 32/100\n",
      "329/329 - 5s - loss: 1.0804e-04 - val_loss: 8.1753e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 33/100\n",
      "329/329 - 5s - loss: 1.0844e-04 - val_loss: 8.4750e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 34/100\n",
      "329/329 - 5s - loss: 1.0725e-04 - val_loss: 8.2146e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 35/100\n",
      "329/329 - 5s - loss: 1.0276e-04 - val_loss: 7.5286e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 36/100\n",
      "329/329 - 5s - loss: 9.9073e-05 - val_loss: 7.0675e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 37/100\n",
      "329/329 - 5s - loss: 9.7339e-05 - val_loss: 7.0344e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 38/100\n",
      "329/329 - 5s - loss: 9.7129e-05 - val_loss: 7.0798e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 39/100\n",
      "329/329 - 5s - loss: 9.6304e-05 - val_loss: 7.4672e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 40/100\n",
      "329/329 - 5s - loss: 9.7191e-05 - val_loss: 7.8477e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 41/100\n",
      "329/329 - 5s - loss: 9.5559e-05 - val_loss: 7.5133e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 42/100\n",
      "329/329 - 5s - loss: 9.2705e-05 - val_loss: 7.2868e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 43/100\n",
      "329/329 - 5s - loss: 9.0360e-05 - val_loss: 7.1129e-05 - 5s/epoch - 17ms/step\n",
      "Epoch 44/100\n",
      "329/329 - 5s - loss: 8.9310e-05 - val_loss: 7.3018e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 45/100\n",
      "329/329 - 5s - loss: 8.9351e-05 - val_loss: 7.5219e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 46/100\n",
      "329/329 - 5s - loss: 8.8743e-05 - val_loss: 7.6397e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 47/100\n",
      "329/329 - 5s - loss: 8.7124e-05 - val_loss: 7.5808e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 48/100\n",
      "329/329 - 5s - loss: 8.7044e-05 - val_loss: 7.6561e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 49/100\n",
      "329/329 - 5s - loss: 8.4729e-05 - val_loss: 7.5472e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 50/100\n",
      "329/329 - 5s - loss: 8.3538e-05 - val_loss: 7.4729e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 51/100\n",
      "329/329 - 5s - loss: 8.2752e-05 - val_loss: 7.6034e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 52/100\n",
      "329/329 - 5s - loss: 8.2613e-05 - val_loss: 7.7432e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 53/100\n",
      "329/329 - 5s - loss: 8.1873e-05 - val_loss: 7.8490e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 54/100\n",
      "329/329 - 5s - loss: 8.0780e-05 - val_loss: 7.5460e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 55/100\n",
      "329/329 - 5s - loss: 7.8503e-05 - val_loss: 7.5837e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 56/100\n",
      "329/329 - 6s - loss: 7.9222e-05 - val_loss: 7.8302e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 57/100\n",
      "329/329 - 5s - loss: 7.8527e-05 - val_loss: 7.7043e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 58/100\n",
      "329/329 - 5s - loss: 7.7045e-05 - val_loss: 7.6144e-05 - 5s/epoch - 17ms/step\n",
      "Epoch 59/100\n",
      "329/329 - 5s - loss: 7.6674e-05 - val_loss: 7.6760e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 60/100\n",
      "329/329 - 5s - loss: 7.4699e-05 - val_loss: 7.4321e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 61/100\n",
      "329/329 - 6s - loss: 7.4235e-05 - val_loss: 7.5612e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 62/100\n",
      "329/329 - 6s - loss: 7.3658e-05 - val_loss: 7.5901e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 63/100\n",
      "329/329 - 5s - loss: 7.3686e-05 - val_loss: 7.7764e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 64/100\n",
      "329/329 - 5s - loss: 7.2910e-05 - val_loss: 7.7838e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 65/100\n",
      "329/329 - 5s - loss: 7.2100e-05 - val_loss: 7.7753e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 66/100\n",
      "329/329 - 5s - loss: 7.1858e-05 - val_loss: 7.7246e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 67/100\n",
      "329/329 - 5s - loss: 7.0313e-05 - val_loss: 7.4753e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 68/100\n",
      "329/329 - 5s - loss: 6.9310e-05 - val_loss: 7.4962e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 69/100\n",
      "329/329 - 6s - loss: 6.8181e-05 - val_loss: 7.4241e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 70/100\n",
      "329/329 - 5s - loss: 6.8799e-05 - val_loss: 7.6610e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 71/100\n",
      "329/329 - 5s - loss: 6.7706e-05 - val_loss: 7.6011e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 72/100\n",
      "329/329 - 5s - loss: 6.7167e-05 - val_loss: 7.5810e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 73/100\n",
      "329/329 - 5s - loss: 6.6220e-05 - val_loss: 7.5449e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 74/100\n",
      "329/329 - 5s - loss: 6.5726e-05 - val_loss: 7.5975e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 75/100\n",
      "329/329 - 5s - loss: 6.5117e-05 - val_loss: 7.5090e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 76/100\n",
      "329/329 - 5s - loss: 6.4219e-05 - val_loss: 7.6210e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 77/100\n",
      "329/329 - 6s - loss: 6.4418e-05 - val_loss: 7.5533e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 78/100\n",
      "329/329 - 5s - loss: 6.3071e-05 - val_loss: 7.5833e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 79/100\n",
      "329/329 - 5s - loss: 6.3061e-05 - val_loss: 7.5965e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 80/100\n",
      "329/329 - 5s - loss: 6.2258e-05 - val_loss: 7.7815e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 81/100\n",
      "329/329 - 5s - loss: 6.2047e-05 - val_loss: 7.7567e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 82/100\n",
      "329/329 - 5s - loss: 6.1531e-05 - val_loss: 7.9612e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 83/100\n",
      "329/329 - 5s - loss: 6.0994e-05 - val_loss: 7.8619e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 84/100\n",
      "329/329 - 5s - loss: 6.0562e-05 - val_loss: 7.9998e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 85/100\n",
      "329/329 - 5s - loss: 6.0945e-05 - val_loss: 8.0510e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 86/100\n",
      "329/329 - 5s - loss: 5.9919e-05 - val_loss: 8.0518e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 87/100\n",
      "329/329 - 5s - loss: 5.9150e-05 - val_loss: 7.9798e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 88/100\n",
      "329/329 - 5s - loss: 5.8825e-05 - val_loss: 8.0776e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 89/100\n",
      "329/329 - 5s - loss: 5.8828e-05 - val_loss: 8.2118e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 90/100\n",
      "329/329 - 6s - loss: 5.8535e-05 - val_loss: 8.2837e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 91/100\n",
      "329/329 - 6s - loss: 5.7943e-05 - val_loss: 8.3451e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 92/100\n",
      "329/329 - 5s - loss: 5.7466e-05 - val_loss: 8.3957e-05 - 5s/epoch - 17ms/step\n",
      "Epoch 93/100\n",
      "329/329 - 6s - loss: 5.7378e-05 - val_loss: 8.5948e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 94/100\n",
      "329/329 - 5s - loss: 5.7434e-05 - val_loss: 8.6597e-05 - 5s/epoch - 17ms/step\n",
      "Epoch 95/100\n",
      "329/329 - 5s - loss: 5.6866e-05 - val_loss: 8.7666e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 96/100\n",
      "329/329 - 5s - loss: 5.6636e-05 - val_loss: 8.7597e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "329/329 - 5s - loss: 5.6396e-05 - val_loss: 8.9954e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 98/100\n",
      "329/329 - 5s - loss: 5.6339e-05 - val_loss: 8.9312e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 99/100\n",
      "329/329 - 5s - loss: 5.5526e-05 - val_loss: 9.0918e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 100/100\n",
      "329/329 - 5s - loss: 5.5514e-05 - val_loss: 9.0998e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:10:59.388612: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:10:59.585343: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:10:59.601275: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:10:59.900094: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:10:59.920420: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:11:03.151460: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:11:03.216095: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:11:03.227978: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 - 6s - loss: 4.5737e-04 - val_loss: 1.5026e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 2/100\n",
      "165/165 - 3s - loss: 0.0010 - val_loss: 0.0015 - 3s/epoch - 16ms/step\n",
      "Epoch 3/100\n",
      "165/165 - 3s - loss: 9.6717e-04 - val_loss: 9.0549e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 4/100\n",
      "165/165 - 3s - loss: 6.9162e-04 - val_loss: 7.4638e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 5/100\n",
      "165/165 - 3s - loss: 5.4427e-04 - val_loss: 5.0652e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 6/100\n",
      "165/165 - 3s - loss: 4.4481e-04 - val_loss: 3.3906e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 7/100\n",
      "165/165 - 3s - loss: 3.7927e-04 - val_loss: 2.3932e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 8/100\n",
      "165/165 - 3s - loss: 3.3314e-04 - val_loss: 1.7871e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 9/100\n",
      "165/165 - 3s - loss: 2.9684e-04 - val_loss: 1.3933e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 10/100\n",
      "165/165 - 3s - loss: 2.6508e-04 - val_loss: 1.1099e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 11/100\n",
      "165/165 - 3s - loss: 2.3549e-04 - val_loss: 8.9032e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 12/100\n",
      "165/165 - 3s - loss: 2.0773e-04 - val_loss: 7.1120e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 13/100\n",
      "165/165 - 3s - loss: 1.8313e-04 - val_loss: 5.6420e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "165/165 - 3s - loss: 1.6389e-04 - val_loss: 4.5074e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 15/100\n",
      "165/165 - 3s - loss: 1.5222e-04 - val_loss: 3.7781e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "165/165 - 3s - loss: 1.4935e-04 - val_loss: 3.4958e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 17/100\n",
      "165/165 - 3s - loss: 1.5558e-04 - val_loss: 3.6690e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 18/100\n",
      "165/165 - 3s - loss: 1.7052e-04 - val_loss: 4.3629e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "165/165 - 3s - loss: 1.9261e-04 - val_loss: 5.7323e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 20/100\n",
      "165/165 - 3s - loss: 2.1775e-04 - val_loss: 7.8553e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 21/100\n",
      "165/165 - 3s - loss: 2.5156e-04 - val_loss: 1.1370e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 22/100\n",
      "165/165 - 3s - loss: 2.7830e-04 - val_loss: 1.5078e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 23/100\n",
      "165/165 - 3s - loss: 2.7610e-04 - val_loss: 1.5499e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 24/100\n",
      "165/165 - 3s - loss: 2.4105e-04 - val_loss: 1.2047e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 25/100\n",
      "165/165 - 3s - loss: 1.9514e-04 - val_loss: 8.0470e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 26/100\n",
      "165/165 - 3s - loss: 1.5979e-04 - val_loss: 5.5636e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 27/100\n",
      "165/165 - 3s - loss: 1.4258e-04 - val_loss: 4.2840e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 28/100\n",
      "165/165 - 3s - loss: 1.3651e-04 - val_loss: 3.9083e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 29/100\n",
      "165/165 - 3s - loss: 1.4369e-04 - val_loss: 4.0337e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 30/100\n",
      "165/165 - 3s - loss: 1.5946e-04 - val_loss: 4.7096e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 31/100\n",
      "165/165 - 3s - loss: 1.8847e-04 - val_loss: 5.9736e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 32/100\n",
      "165/165 - 3s - loss: 2.2278e-04 - val_loss: 8.3340e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 33/100\n",
      "165/165 - 3s - loss: 2.4621e-04 - val_loss: 1.0887e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 34/100\n",
      "165/165 - 3s - loss: 2.5641e-04 - val_loss: 1.2639e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 35/100\n",
      "165/165 - 3s - loss: 2.2561e-04 - val_loss: 9.9223e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 36/100\n",
      "165/165 - 3s - loss: 1.7924e-04 - val_loss: 6.3869e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 37/100\n",
      "165/165 - 3s - loss: 1.4198e-04 - val_loss: 4.1551e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 38/100\n",
      "165/165 - 3s - loss: 1.2697e-04 - val_loss: 3.3945e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 39/100\n",
      "165/165 - 3s - loss: 1.2560e-04 - val_loss: 3.4122e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 40/100\n",
      "165/165 - 3s - loss: 1.4513e-04 - val_loss: 3.9563e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 41/100\n",
      "165/165 - 3s - loss: 1.6896e-04 - val_loss: 4.7411e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 42/100\n",
      "165/165 - 3s - loss: 2.0007e-04 - val_loss: 6.2312e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 43/100\n",
      "165/165 - 3s - loss: 2.0525e-04 - val_loss: 7.2063e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 44/100\n",
      "165/165 - 3s - loss: 1.9191e-04 - val_loss: 6.6183e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 45/100\n",
      "165/165 - 3s - loss: 1.6180e-04 - val_loss: 5.1354e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 46/100\n",
      "165/165 - 3s - loss: 1.4033e-04 - val_loss: 3.9077e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 47/100\n",
      "165/165 - 3s - loss: 1.2625e-04 - val_loss: 3.3349e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 48/100\n",
      "165/165 - 3s - loss: 1.2705e-04 - val_loss: 3.3002e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 49/100\n",
      "165/165 - 3s - loss: 1.3718e-04 - val_loss: 3.5912e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 50/100\n",
      "165/165 - 3s - loss: 1.5881e-04 - val_loss: 4.2585e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 51/100\n",
      "165/165 - 3s - loss: 1.7644e-04 - val_loss: 5.2897e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 52/100\n",
      "165/165 - 3s - loss: 1.8658e-04 - val_loss: 6.0563e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 53/100\n",
      "165/165 - 3s - loss: 1.7200e-04 - val_loss: 5.5215e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 54/100\n",
      "165/165 - 3s - loss: 1.4920e-04 - val_loss: 4.3206e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 55/100\n",
      "165/165 - 3s - loss: 1.2827e-04 - val_loss: 3.2425e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 56/100\n",
      "165/165 - 3s - loss: 1.1128e-04 - val_loss: 2.6952e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "165/165 - 3s - loss: 1.1009e-04 - val_loss: 2.6026e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 58/100\n",
      "165/165 - 3s - loss: 1.1447e-04 - val_loss: 2.7847e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 59/100\n",
      "165/165 - 3s - loss: 1.3382e-04 - val_loss: 3.3473e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 60/100\n",
      "165/165 - 3s - loss: 1.5966e-04 - val_loss: 4.3803e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 61/100\n",
      "165/165 - 3s - loss: 1.7686e-04 - val_loss: 5.6191e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 62/100\n",
      "165/165 - 3s - loss: 1.7441e-04 - val_loss: 5.6974e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 63/100\n",
      "165/165 - 3s - loss: 1.4226e-04 - val_loss: 4.0837e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 64/100\n",
      "165/165 - 3s - loss: 1.1493e-04 - val_loss: 2.9008e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 65/100\n",
      "165/165 - 3s - loss: 9.7882e-05 - val_loss: 2.3211e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 66/100\n",
      "165/165 - 3s - loss: 9.2674e-05 - val_loss: 2.2029e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 67/100\n",
      "165/165 - 3s - loss: 9.5856e-05 - val_loss: 2.3478e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 68/100\n",
      "165/165 - 3s - loss: 1.0865e-04 - val_loss: 2.6827e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 69/100\n",
      "165/165 - 3s - loss: 1.2906e-04 - val_loss: 3.3218e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 70/100\n",
      "165/165 - 3s - loss: 1.5255e-04 - val_loss: 4.3837e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 71/100\n",
      "165/165 - 3s - loss: 1.6396e-04 - val_loss: 5.5761e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 72/100\n",
      "165/165 - 3s - loss: 1.6229e-04 - val_loss: 5.6133e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 73/100\n",
      "165/165 - 3s - loss: 1.2810e-04 - val_loss: 3.9820e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 74/100\n",
      "165/165 - 3s - loss: 1.0038e-04 - val_loss: 2.6185e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 75/100\n",
      "165/165 - 3s - loss: 8.5607e-05 - val_loss: 2.1651e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 76/100\n",
      "165/165 - 3s - loss: 8.2583e-05 - val_loss: 2.1370e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 77/100\n",
      "165/165 - 3s - loss: 8.6106e-05 - val_loss: 2.2851e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 78/100\n",
      "165/165 - 3s - loss: 9.6549e-05 - val_loss: 2.5966e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 79/100\n",
      "165/165 - 3s - loss: 1.1544e-04 - val_loss: 3.1363e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 80/100\n",
      "165/165 - 3s - loss: 1.3974e-04 - val_loss: 4.2321e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 81/100\n",
      "165/165 - 3s - loss: 1.6099e-04 - val_loss: 5.8119e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 82/100\n",
      "165/165 - 3s - loss: 1.5074e-04 - val_loss: 5.4347e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 83/100\n",
      "165/165 - 3s - loss: 1.1719e-04 - val_loss: 3.7073e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 84/100\n",
      "165/165 - 3s - loss: 9.2454e-05 - val_loss: 2.5586e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 85/100\n",
      "165/165 - 3s - loss: 7.7152e-05 - val_loss: 2.1712e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 86/100\n",
      "165/165 - 3s - loss: 7.5846e-05 - val_loss: 2.0305e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 87/100\n",
      "165/165 - 3s - loss: 7.5258e-05 - val_loss: 2.1716e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 88/100\n",
      "165/165 - 3s - loss: 8.6714e-05 - val_loss: 2.4669e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 89/100\n",
      "165/165 - 3s - loss: 1.0171e-04 - val_loss: 3.0400e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 90/100\n",
      "165/165 - 3s - loss: 1.3231e-04 - val_loss: 4.1280e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 91/100\n",
      "165/165 - 3s - loss: 1.5512e-04 - val_loss: 5.6819e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 92/100\n",
      "165/165 - 3s - loss: 1.4066e-04 - val_loss: 5.1867e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 93/100\n",
      "165/165 - 3s - loss: 1.0993e-04 - val_loss: 3.8990e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 94/100\n",
      "165/165 - 3s - loss: 8.5628e-05 - val_loss: 2.4874e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 95/100\n",
      "165/165 - 3s - loss: 7.0928e-05 - val_loss: 2.0461e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 96/100\n",
      "165/165 - 3s - loss: 6.9267e-05 - val_loss: 1.9748e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "165/165 - 3s - loss: 7.0160e-05 - val_loss: 2.1274e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 98/100\n",
      "165/165 - 3s - loss: 8.0642e-05 - val_loss: 2.4176e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 99/100\n",
      "165/165 - 3s - loss: 9.3673e-05 - val_loss: 2.8378e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 100/100\n",
      "165/165 - 3s - loss: 1.1670e-04 - val_loss: 3.6277e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:15:30.503109: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:15:30.678135: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:15:30.697532: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:15:31.105271: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:15:31.125733: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:15:34.331215: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:15:34.392384: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:15:34.403849: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 - 6s - loss: 3.7304e-04 - val_loss: 2.2295e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 2/100\n",
      "165/165 - 3s - loss: 0.0011 - val_loss: 0.0021 - 3s/epoch - 16ms/step\n",
      "Epoch 3/100\n",
      "165/165 - 3s - loss: 0.0012 - val_loss: 0.0013 - 3s/epoch - 17ms/step\n",
      "Epoch 4/100\n",
      "165/165 - 3s - loss: 7.6272e-04 - val_loss: 9.1831e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "165/165 - 3s - loss: 5.2249e-04 - val_loss: 5.1657e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "165/165 - 3s - loss: 3.8685e-04 - val_loss: 3.0203e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "165/165 - 3s - loss: 3.0592e-04 - val_loss: 1.9477e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "165/165 - 3s - loss: 2.5023e-04 - val_loss: 1.3496e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 9/100\n",
      "165/165 - 3s - loss: 2.0673e-04 - val_loss: 9.6000e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 10/100\n",
      "165/165 - 3s - loss: 1.7227e-04 - val_loss: 6.7587e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 11/100\n",
      "165/165 - 3s - loss: 1.4845e-04 - val_loss: 4.7798e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 12/100\n",
      "165/165 - 3s - loss: 1.3723e-04 - val_loss: 3.7312e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 13/100\n",
      "165/165 - 3s - loss: 1.3883e-04 - val_loss: 3.5107e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 14/100\n",
      "165/165 - 3s - loss: 1.5279e-04 - val_loss: 3.9946e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 15/100\n",
      "165/165 - 3s - loss: 1.7880e-04 - val_loss: 5.2629e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "165/165 - 3s - loss: 2.1462e-04 - val_loss: 7.6098e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 17/100\n",
      "165/165 - 3s - loss: 2.5138e-04 - val_loss: 1.1268e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 18/100\n",
      "165/165 - 3s - loss: 2.7515e-04 - val_loss: 1.5237e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "165/165 - 3s - loss: 2.7904e-04 - val_loss: 1.7111e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 20/100\n",
      "165/165 - 3s - loss: 2.6027e-04 - val_loss: 1.5670e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 21/100\n",
      "165/165 - 3s - loss: 2.3167e-04 - val_loss: 1.2346e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 22/100\n",
      "165/165 - 3s - loss: 1.9749e-04 - val_loss: 9.2215e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 23/100\n",
      "165/165 - 3s - loss: 1.7132e-04 - val_loss: 7.0723e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 24/100\n",
      "165/165 - 3s - loss: 1.5472e-04 - val_loss: 5.9173e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 25/100\n",
      "165/165 - 3s - loss: 1.5165e-04 - val_loss: 5.5515e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 26/100\n",
      "165/165 - 3s - loss: 1.5791e-04 - val_loss: 5.8565e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 27/100\n",
      "165/165 - 3s - loss: 1.7728e-04 - val_loss: 6.7843e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 28/100\n",
      "165/165 - 3s - loss: 2.0941e-04 - val_loss: 8.7594e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 29/100\n",
      "165/165 - 3s - loss: 2.5688e-04 - val_loss: 1.2548e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 30/100\n",
      "165/165 - 3s - loss: 3.0526e-04 - val_loss: 1.8519e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 31/100\n",
      "165/165 - 3s - loss: 2.9645e-04 - val_loss: 1.8465e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 32/100\n",
      "165/165 - 3s - loss: 2.2423e-04 - val_loss: 1.1074e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 33/100\n",
      "165/165 - 3s - loss: 1.5728e-04 - val_loss: 5.8146e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 34/100\n",
      "165/165 - 3s - loss: 1.1991e-04 - val_loss: 3.6443e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 35/100\n",
      "165/165 - 3s - loss: 1.0749e-04 - val_loss: 3.1302e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 36/100\n",
      "165/165 - 3s - loss: 1.1398e-04 - val_loss: 3.6334e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 37/100\n",
      "165/165 - 3s - loss: 1.4217e-04 - val_loss: 4.4963e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 38/100\n",
      "165/165 - 3s - loss: 1.9788e-04 - val_loss: 6.4552e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 39/100\n",
      "165/165 - 3s - loss: 2.5410e-04 - val_loss: 1.0556e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 40/100\n",
      "165/165 - 3s - loss: 2.4609e-04 - val_loss: 1.1350e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 41/100\n",
      "165/165 - 3s - loss: 1.9163e-04 - val_loss: 7.3459e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 42/100\n",
      "165/165 - 3s - loss: 1.3923e-04 - val_loss: 4.1987e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 43/100\n",
      "165/165 - 3s - loss: 1.0765e-04 - val_loss: 2.8218e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 44/100\n",
      "165/165 - 3s - loss: 9.7115e-05 - val_loss: 2.4044e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 45/100\n",
      "165/165 - 3s - loss: 9.8304e-05 - val_loss: 2.4987e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 46/100\n",
      "165/165 - 3s - loss: 1.1326e-04 - val_loss: 2.9942e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 47/100\n",
      "165/165 - 3s - loss: 1.4766e-04 - val_loss: 4.0708e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 48/100\n",
      "165/165 - 3s - loss: 2.0517e-04 - val_loss: 6.5918e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 49/100\n",
      "165/165 - 3s - loss: 2.5385e-04 - val_loss: 1.0990e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 50/100\n",
      "165/165 - 3s - loss: 2.2892e-04 - val_loss: 9.1824e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 51/100\n",
      "165/165 - 3s - loss: 1.5693e-04 - val_loss: 4.5160e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 52/100\n",
      "165/165 - 3s - loss: 1.0485e-04 - val_loss: 2.4944e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 53/100\n",
      "165/165 - 3s - loss: 8.3936e-05 - val_loss: 1.9069e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 54/100\n",
      "165/165 - 3s - loss: 7.8800e-05 - val_loss: 1.8194e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 55/100\n",
      "165/165 - 3s - loss: 8.1126e-05 - val_loss: 1.9464e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 56/100\n",
      "165/165 - 3s - loss: 9.6453e-05 - val_loss: 2.3098e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "165/165 - 3s - loss: 1.2445e-04 - val_loss: 2.9993e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 58/100\n",
      "165/165 - 3s - loss: 1.7823e-04 - val_loss: 4.9161e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 59/100\n",
      "165/165 - 3s - loss: 2.2903e-04 - val_loss: 9.2515e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 60/100\n",
      "165/165 - 3s - loss: 2.2863e-04 - val_loss: 8.8010e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 61/100\n",
      "165/165 - 3s - loss: 1.5446e-04 - val_loss: 4.1030e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 62/100\n",
      "165/165 - 3s - loss: 1.0170e-04 - val_loss: 2.1242e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 63/100\n",
      "165/165 - 3s - loss: 7.5217e-05 - val_loss: 1.6444e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 64/100\n",
      "165/165 - 3s - loss: 6.8029e-05 - val_loss: 1.5874e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 65/100\n",
      "165/165 - 3s - loss: 6.7868e-05 - val_loss: 1.6540e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 66/100\n",
      "165/165 - 3s - loss: 7.4188e-05 - val_loss: 1.8109e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 67/100\n",
      "165/165 - 3s - loss: 9.0361e-05 - val_loss: 2.2399e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 68/100\n",
      "165/165 - 3s - loss: 1.2431e-04 - val_loss: 3.0611e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 69/100\n",
      "165/165 - 3s - loss: 1.9029e-04 - val_loss: 6.0675e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 70/100\n",
      "165/165 - 3s - loss: 2.4363e-04 - val_loss: 1.1205e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 71/100\n",
      "165/165 - 3s - loss: 1.8912e-04 - val_loss: 6.2654e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 72/100\n",
      "165/165 - 3s - loss: 1.1344e-04 - val_loss: 2.5701e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 73/100\n",
      "165/165 - 3s - loss: 7.7644e-05 - val_loss: 1.6366e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 74/100\n",
      "165/165 - 3s - loss: 6.3219e-05 - val_loss: 1.4898e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 75/100\n",
      "165/165 - 3s - loss: 6.0766e-05 - val_loss: 1.5181e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 76/100\n",
      "165/165 - 3s - loss: 6.2955e-05 - val_loss: 1.5930e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 77/100\n",
      "165/165 - 3s - loss: 7.1843e-05 - val_loss: 1.7728e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 78/100\n",
      "165/165 - 3s - loss: 9.0302e-05 - val_loss: 2.2318e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 79/100\n",
      "165/165 - 3s - loss: 1.3079e-04 - val_loss: 3.2840e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 80/100\n",
      "165/165 - 3s - loss: 2.0177e-04 - val_loss: 8.1286e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 81/100\n",
      "165/165 - 3s - loss: 2.2540e-04 - val_loss: 9.6747e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 82/100\n",
      "165/165 - 3s - loss: 1.4298e-04 - val_loss: 3.9901e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 83/100\n",
      "165/165 - 3s - loss: 8.6961e-05 - val_loss: 1.9356e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 84/100\n",
      "165/165 - 3s - loss: 6.3431e-05 - val_loss: 1.4341e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 85/100\n",
      "165/165 - 3s - loss: 5.6429e-05 - val_loss: 1.4261e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 86/100\n",
      "165/165 - 3s - loss: 5.6144e-05 - val_loss: 1.4754e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 87/100\n",
      "165/165 - 3s - loss: 6.0467e-05 - val_loss: 1.5706e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 88/100\n",
      "165/165 - 3s - loss: 7.0735e-05 - val_loss: 1.7872e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 89/100\n",
      "165/165 - 3s - loss: 9.1246e-05 - val_loss: 2.2379e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 90/100\n",
      "165/165 - 3s - loss: 1.2885e-04 - val_loss: 3.1533e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 91/100\n",
      "165/165 - 3s - loss: 1.8187e-04 - val_loss: 6.7726e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 92/100\n",
      "165/165 - 3s - loss: 1.9150e-04 - val_loss: 8.7153e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 93/100\n",
      "165/165 - 3s - loss: 1.3021e-04 - val_loss: 4.1831e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 94/100\n",
      "165/165 - 3s - loss: 8.1039e-05 - val_loss: 1.8113e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 95/100\n",
      "165/165 - 3s - loss: 5.8443e-05 - val_loss: 1.4099e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 96/100\n",
      "165/165 - 3s - loss: 5.2571e-05 - val_loss: 1.3927e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "165/165 - 3s - loss: 5.2729e-05 - val_loss: 1.4391e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 98/100\n",
      "165/165 - 3s - loss: 5.7583e-05 - val_loss: 1.5698e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 99/100\n",
      "165/165 - 3s - loss: 6.7849e-05 - val_loss: 1.8539e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 100/100\n",
      "165/165 - 3s - loss: 8.9948e-05 - val_loss: 2.3638e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:20:04.742143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:20:04.923919: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:20:04.939649: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:20:05.113095: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:20:05.133747: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:20:08.457393: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:20:08.524244: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:20:08.535382: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 - 6s - loss: 4.3195e-04 - val_loss: 2.1298e-04 - 6s/epoch - 34ms/step\n",
      "Epoch 2/100\n",
      "165/165 - 3s - loss: 5.1004e-04 - val_loss: 6.4612e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 3/100\n",
      "165/165 - 3s - loss: 0.0014 - val_loss: 0.0027 - 3s/epoch - 17ms/step\n",
      "Epoch 4/100\n",
      "165/165 - 3s - loss: 0.0023 - val_loss: 0.0038 - 3s/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "165/165 - 3s - loss: 0.0015 - val_loss: 0.0030 - 3s/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "165/165 - 3s - loss: 9.0385e-04 - val_loss: 0.0016 - 3s/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "165/165 - 3s - loss: 5.3801e-04 - val_loss: 6.8441e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "165/165 - 3s - loss: 3.6064e-04 - val_loss: 3.4218e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 9/100\n",
      "165/165 - 3s - loss: 2.8278e-04 - val_loss: 2.0778e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 10/100\n",
      "165/165 - 3s - loss: 2.4059e-04 - val_loss: 1.4606e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 11/100\n",
      "165/165 - 3s - loss: 2.0985e-04 - val_loss: 1.1054e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 12/100\n",
      "165/165 - 3s - loss: 1.8372e-04 - val_loss: 8.4861e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 13/100\n",
      "165/165 - 3s - loss: 1.6284e-04 - val_loss: 6.4546e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 14/100\n",
      "165/165 - 3s - loss: 1.5027e-04 - val_loss: 5.0561e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 15/100\n",
      "165/165 - 3s - loss: 1.4812e-04 - val_loss: 4.4245e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 16/100\n",
      "165/165 - 3s - loss: 1.5682e-04 - val_loss: 4.5365e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "165/165 - 3s - loss: 1.7604e-04 - val_loss: 5.3825e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 18/100\n",
      "165/165 - 3s - loss: 2.0444e-04 - val_loss: 7.0670e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 19/100\n",
      "165/165 - 3s - loss: 2.3758e-04 - val_loss: 9.7248e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 20/100\n",
      "165/165 - 3s - loss: 2.6637e-04 - val_loss: 1.3126e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 21/100\n",
      "165/165 - 3s - loss: 2.8137e-04 - val_loss: 1.6076e-04 - 3s/epoch - 18ms/step\n",
      "Epoch 22/100\n",
      "165/165 - 3s - loss: 2.8143e-04 - val_loss: 1.7268e-04 - 3s/epoch - 18ms/step\n",
      "Epoch 23/100\n",
      "165/165 - 3s - loss: 2.7007e-04 - val_loss: 1.6303e-04 - 3s/epoch - 18ms/step\n",
      "Epoch 24/100\n",
      "165/165 - 3s - loss: 2.4883e-04 - val_loss: 1.4033e-04 - 3s/epoch - 18ms/step\n",
      "Epoch 25/100\n",
      "165/165 - 3s - loss: 2.2945e-04 - val_loss: 1.1576e-04 - 3s/epoch - 18ms/step\n",
      "Epoch 26/100\n",
      "165/165 - 3s - loss: 2.0791e-04 - val_loss: 9.9973e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 27/100\n",
      "165/165 - 3s - loss: 1.9221e-04 - val_loss: 8.6953e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 28/100\n",
      "165/165 - 3s - loss: 1.8758e-04 - val_loss: 7.9979e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 29/100\n",
      "165/165 - 3s - loss: 1.9061e-04 - val_loss: 7.9516e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 30/100\n",
      "165/165 - 3s - loss: 2.0471e-04 - val_loss: 8.9086e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 31/100\n",
      "165/165 - 3s - loss: 2.3446e-04 - val_loss: 1.0746e-04 - 3s/epoch - 18ms/step\n",
      "Epoch 32/100\n",
      "165/165 - 3s - loss: 2.7907e-04 - val_loss: 1.4845e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 33/100\n",
      "165/165 - 3s - loss: 3.4984e-04 - val_loss: 2.2096e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 34/100\n",
      "165/165 - 3s - loss: 3.8243e-04 - val_loss: 2.5704e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 35/100\n",
      "165/165 - 3s - loss: 2.8652e-04 - val_loss: 1.4333e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 36/100\n",
      "165/165 - 3s - loss: 1.6017e-04 - val_loss: 6.2977e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 37/100\n",
      "165/165 - 3s - loss: 1.1010e-04 - val_loss: 3.4298e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 38/100\n",
      "165/165 - 3s - loss: 8.9955e-05 - val_loss: 2.4819e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 39/100\n",
      "165/165 - 3s - loss: 8.5824e-05 - val_loss: 2.3061e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 40/100\n",
      "165/165 - 3s - loss: 9.1773e-05 - val_loss: 2.4684e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 41/100\n",
      "165/165 - 3s - loss: 1.0816e-04 - val_loss: 3.0139e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 42/100\n",
      "165/165 - 3s - loss: 1.4164e-04 - val_loss: 4.0774e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 43/100\n",
      "165/165 - 3s - loss: 2.0271e-04 - val_loss: 6.1811e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 44/100\n",
      "165/165 - 3s - loss: 2.8652e-04 - val_loss: 1.1789e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 45/100\n",
      "165/165 - 3s - loss: 3.8478e-04 - val_loss: 2.4082e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 46/100\n",
      "165/165 - 3s - loss: 3.5966e-04 - val_loss: 1.6589e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "165/165 - 3s - loss: 1.9284e-04 - val_loss: 5.6117e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 48/100\n",
      "165/165 - 3s - loss: 1.1444e-04 - val_loss: 2.9258e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 49/100\n",
      "165/165 - 3s - loss: 8.5044e-05 - val_loss: 2.0845e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 50/100\n",
      "165/165 - 3s - loss: 7.6045e-05 - val_loss: 1.8083e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 51/100\n",
      "165/165 - 3s - loss: 7.4713e-05 - val_loss: 1.7953e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 52/100\n",
      "165/165 - 3s - loss: 8.0135e-05 - val_loss: 1.9227e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 53/100\n",
      "165/165 - 3s - loss: 9.3210e-05 - val_loss: 2.2462e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 54/100\n",
      "165/165 - 3s - loss: 1.2366e-04 - val_loss: 3.0951e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 55/100\n",
      "165/165 - 3s - loss: 1.8122e-04 - val_loss: 5.2857e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 56/100\n",
      "165/165 - 3s - loss: 2.6440e-04 - val_loss: 1.0622e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 57/100\n",
      "165/165 - 3s - loss: 2.9824e-04 - val_loss: 1.4722e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "165/165 - 3s - loss: 2.3823e-04 - val_loss: 6.9273e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 59/100\n",
      "165/165 - 3s - loss: 1.2496e-04 - val_loss: 2.7707e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 60/100\n",
      "165/165 - 3s - loss: 8.3942e-05 - val_loss: 1.8001e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 61/100\n",
      "165/165 - 3s - loss: 7.0412e-05 - val_loss: 1.6118e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 62/100\n",
      "165/165 - 3s - loss: 6.8898e-05 - val_loss: 1.6247e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 63/100\n",
      "165/165 - 3s - loss: 7.4035e-05 - val_loss: 1.7459e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 64/100\n",
      "165/165 - 3s - loss: 9.0164e-05 - val_loss: 2.1295e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 65/100\n",
      "165/165 - 3s - loss: 1.2807e-04 - val_loss: 3.3706e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 66/100\n",
      "165/165 - 3s - loss: 2.0776e-04 - val_loss: 7.1306e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 67/100\n",
      "165/165 - 3s - loss: 2.8332e-04 - val_loss: 1.3145e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 68/100\n",
      "165/165 - 3s - loss: 2.2980e-04 - val_loss: 6.7867e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 69/100\n",
      "165/165 - 3s - loss: 1.2237e-04 - val_loss: 2.5547e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 70/100\n",
      "165/165 - 3s - loss: 7.8576e-05 - val_loss: 1.6385e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 71/100\n",
      "165/165 - 3s - loss: 6.5197e-05 - val_loss: 1.4942e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 72/100\n",
      "165/165 - 3s - loss: 6.3390e-05 - val_loss: 1.5326e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 73/100\n",
      "165/165 - 3s - loss: 6.7696e-05 - val_loss: 1.6315e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 74/100\n",
      "165/165 - 3s - loss: 8.1065e-05 - val_loss: 1.9846e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 75/100\n",
      "165/165 - 3s - loss: 1.1195e-04 - val_loss: 2.9010e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 76/100\n",
      "165/165 - 3s - loss: 1.7464e-04 - val_loss: 5.6449e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 77/100\n",
      "165/165 - 3s - loss: 2.4463e-04 - val_loss: 1.0449e-04 - 3s/epoch - 18ms/step\n",
      "Epoch 78/100\n",
      "165/165 - 3s - loss: 1.9495e-04 - val_loss: 6.0423e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 79/100\n",
      "165/165 - 3s - loss: 1.0832e-04 - val_loss: 2.4416e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 80/100\n",
      "165/165 - 3s - loss: 7.1181e-05 - val_loss: 1.5909e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 81/100\n",
      "165/165 - 3s - loss: 6.0624e-05 - val_loss: 1.4796e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 82/100\n",
      "165/165 - 3s - loss: 6.0309e-05 - val_loss: 1.5342e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 83/100\n",
      "165/165 - 3s - loss: 6.5950e-05 - val_loss: 1.6945e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 84/100\n",
      "165/165 - 3s - loss: 7.9678e-05 - val_loss: 2.0856e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 85/100\n",
      "165/165 - 3s - loss: 1.0996e-04 - val_loss: 3.0622e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 86/100\n",
      "165/165 - 3s - loss: 1.6995e-04 - val_loss: 6.3623e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 87/100\n",
      "165/165 - 3s - loss: 2.3062e-04 - val_loss: 1.1187e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 88/100\n",
      "165/165 - 3s - loss: 1.6733e-04 - val_loss: 5.5494e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 89/100\n",
      "165/165 - 3s - loss: 8.9364e-05 - val_loss: 2.2598e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 90/100\n",
      "165/165 - 3s - loss: 6.0791e-05 - val_loss: 1.5527e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 91/100\n",
      "165/165 - 3s - loss: 5.4097e-05 - val_loss: 1.4666e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 92/100\n",
      "165/165 - 3s - loss: 5.4592e-05 - val_loss: 1.5415e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 93/100\n",
      "165/165 - 3s - loss: 6.0607e-05 - val_loss: 1.7798e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 94/100\n",
      "165/165 - 3s - loss: 7.4385e-05 - val_loss: 2.2999e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 95/100\n",
      "165/165 - 3s - loss: 1.0312e-04 - val_loss: 3.2661e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 96/100\n",
      "165/165 - 3s - loss: 1.5841e-04 - val_loss: 5.7490e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 97/100\n",
      "165/165 - 3s - loss: 1.9745e-04 - val_loss: 9.1406e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 98/100\n",
      "165/165 - 3s - loss: 1.4732e-04 - val_loss: 5.9846e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 99/100\n",
      "165/165 - 3s - loss: 8.5910e-05 - val_loss: 2.7934e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 100/100\n",
      "165/165 - 3s - loss: 5.9310e-05 - val_loss: 1.7489e-05 - 3s/epoch - 17ms/step\n"
     ]
    }
   ],
   "source": [
    "bilstms = []\n",
    "models = []\n",
    "for batch, epoch, neuron in hyperparams:\n",
    "    model, bilstm = LSTMUnit.train_bilstm(train_X, train_y, test_X, test_y, neuron, epoch, batch)\n",
    "    bilstms.append(bilstm)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebe15d8d-6bc9-4220-a7db-48e4d4c7cd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:24:54.331249: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:24:54.403892: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:24:54.415420: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 2s 7ms/step\n",
      "(32, 100, 50)\n",
      "Epoch: 100\n",
      "Neurons: 50\n",
      "0.9727266741287748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:24:56.079185: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:24:56.137552: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:24:56.149079: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 2s 8ms/step\n",
      "(32, 100, 60)\n",
      "Epoch: 100\n",
      "Neurons: 60\n",
      "1.0082270394459278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:24:57.787692: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:24:57.846823: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:24:57.858077: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 2s 8ms/step\n",
      "(32, 100, 100)\n",
      "Epoch: 100\n",
      "Neurons: 100\n",
      "1.0379958780592569\n",
      "  1/165 [..............................] - ETA: 1:04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:24:59.524843: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:24:59.587680: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:24:59.599964: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 2s 7ms/step\n",
      "(64, 100, 50)\n",
      "Epoch: 100\n",
      "Neurons: 50\n",
      "2.0638392753576222\n",
      "  1/165 [..............................] - ETA: 1:05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:25:01.195198: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:01.252147: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:01.263544: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 2s 7ms/step\n",
      "(64, 100, 60)\n",
      "Epoch: 100\n",
      "Neurons: 60\n",
      "2.8234429415994184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:25:02.853156: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:02.918053: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:02.929640: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 2s 8ms/step\n",
      "(64, 100, 100)\n",
      "Epoch: 100\n",
      "Neurons: 100\n",
      "3.1398352932233515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:25:04.593692: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:04.659717: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:04.671374: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 2s 7ms/step\n",
      "(128, 100, 50)\n",
      "Epoch: 100\n",
      "Neurons: 50\n",
      "1.8051899506852735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:25:06.260393: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:06.320696: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:06.334888: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 2s 8ms/step\n",
      "(128, 100, 60)\n",
      "Epoch: 100\n",
      "Neurons: 60\n",
      "1.3700601023841479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:25:07.969425: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:08.026983: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:08.038600: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 2s 8ms/step\n",
      "(128, 100, 100)\n",
      "Epoch: 100\n",
      "Neurons: 100\n",
      "1.1039634961397684\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "i=0\n",
    "for m in models:\n",
    "    test_x2 = test_X\n",
    "    yhat = m.predict(test_x2)\n",
    "    inv_yhat = Preprocessing.inverse_scaler(yhat, scaler)\n",
    "    inv_y = Preprocessing.inverse_scaler(test_y.reshape(-1,1), scaler)\n",
    "    print(hyperparams[i])\n",
    "    print(\"Epoch: \"+ str(bilstms[i].params['epochs']))\n",
    "    print(\"Neurons: \"+str(m.layers[0].layer.units))\n",
    "    print(Evaluation.mape(inv_y,inv_yhat)[0])\n",
    "    with open('BiLSTM_ETH'+str(hyperparams[i])+'.pkl', 'wb') as f:\n",
    "        pickle.dump(bilstms[i].history, f)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3723ed97-4baa-4c5e-9dac-aa107e173d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BiLSTM_ETH(32, 100, 50).pkl', \"rb\") as file_pi:\n",
    "    history = pickle.load(file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb32a172-5a13-4cfc-b543-96f48fe9f368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
