{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499ef9d1-2655-483e-9f50-0badccf17d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Skripsi import Preprocessing\n",
    "from Skripsi import Evaluation\n",
    "from Skripsi import LSTMUnit\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openpyxl.workbook import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ed0706-d5c2-4868-beee-6933c00b0a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unix</th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume LTC</th>\n",
       "      <th>Volume USDT</th>\n",
       "      <th>tradecount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1672527600000</td>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>LTCUSDT</td>\n",
       "      <td>70.08</td>\n",
       "      <td>70.30</td>\n",
       "      <td>69.79</td>\n",
       "      <td>70.14</td>\n",
       "      <td>13547.20800</td>\n",
       "      <td>9.486568e+05</td>\n",
       "      <td>2306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1672524000000</td>\n",
       "      <td>2022-12-31 22:00:00</td>\n",
       "      <td>LTCUSDT</td>\n",
       "      <td>70.24</td>\n",
       "      <td>70.24</td>\n",
       "      <td>69.71</td>\n",
       "      <td>70.09</td>\n",
       "      <td>12617.98300</td>\n",
       "      <td>8.838422e+05</td>\n",
       "      <td>2288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1672520400000</td>\n",
       "      <td>2022-12-31 21:00:00</td>\n",
       "      <td>LTCUSDT</td>\n",
       "      <td>70.40</td>\n",
       "      <td>70.45</td>\n",
       "      <td>70.19</td>\n",
       "      <td>70.23</td>\n",
       "      <td>9698.22600</td>\n",
       "      <td>6.820723e+05</td>\n",
       "      <td>1580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1672516800000</td>\n",
       "      <td>2022-12-31 20:00:00</td>\n",
       "      <td>LTCUSDT</td>\n",
       "      <td>70.15</td>\n",
       "      <td>70.53</td>\n",
       "      <td>70.08</td>\n",
       "      <td>70.39</td>\n",
       "      <td>16666.36600</td>\n",
       "      <td>1.173164e+06</td>\n",
       "      <td>2150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1672513200000</td>\n",
       "      <td>2022-12-31 19:00:00</td>\n",
       "      <td>LTCUSDT</td>\n",
       "      <td>69.93</td>\n",
       "      <td>70.32</td>\n",
       "      <td>69.93</td>\n",
       "      <td>70.15</td>\n",
       "      <td>14214.55000</td>\n",
       "      <td>9.964355e+05</td>\n",
       "      <td>2499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26269</th>\n",
       "      <td>1577851200000</td>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>LTCUSDT</td>\n",
       "      <td>41.53</td>\n",
       "      <td>41.85</td>\n",
       "      <td>41.45</td>\n",
       "      <td>41.59</td>\n",
       "      <td>5317.81964</td>\n",
       "      <td>2.214516e+05</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>1577847600000</td>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>LTCUSDT</td>\n",
       "      <td>41.84</td>\n",
       "      <td>41.85</td>\n",
       "      <td>41.49</td>\n",
       "      <td>41.53</td>\n",
       "      <td>3873.02370</td>\n",
       "      <td>1.613043e+05</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26271</th>\n",
       "      <td>1577844000000</td>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>LTCUSDT</td>\n",
       "      <td>41.63</td>\n",
       "      <td>41.88</td>\n",
       "      <td>41.62</td>\n",
       "      <td>41.85</td>\n",
       "      <td>5757.19484</td>\n",
       "      <td>2.402871e+05</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>1577840400000</td>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>LTCUSDT</td>\n",
       "      <td>41.28</td>\n",
       "      <td>41.70</td>\n",
       "      <td>41.27</td>\n",
       "      <td>41.62</td>\n",
       "      <td>6814.68608</td>\n",
       "      <td>2.830715e+05</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26273</th>\n",
       "      <td>1577836800000</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>LTCUSDT</td>\n",
       "      <td>41.29</td>\n",
       "      <td>41.29</td>\n",
       "      <td>41.16</td>\n",
       "      <td>41.28</td>\n",
       "      <td>2828.06038</td>\n",
       "      <td>1.165827e+05</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26274 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Unix                 Date   Symbol   Open   High    Low  \\\n",
       "0      1672527600000  2022-12-31 23:00:00  LTCUSDT  70.08  70.30  69.79   \n",
       "1      1672524000000  2022-12-31 22:00:00  LTCUSDT  70.24  70.24  69.71   \n",
       "2      1672520400000  2022-12-31 21:00:00  LTCUSDT  70.40  70.45  70.19   \n",
       "3      1672516800000  2022-12-31 20:00:00  LTCUSDT  70.15  70.53  70.08   \n",
       "4      1672513200000  2022-12-31 19:00:00  LTCUSDT  69.93  70.32  69.93   \n",
       "...              ...                  ...      ...    ...    ...    ...   \n",
       "26269  1577851200000  2020-01-01 04:00:00  LTCUSDT  41.53  41.85  41.45   \n",
       "26270  1577847600000  2020-01-01 03:00:00  LTCUSDT  41.84  41.85  41.49   \n",
       "26271  1577844000000  2020-01-01 02:00:00  LTCUSDT  41.63  41.88  41.62   \n",
       "26272  1577840400000  2020-01-01 01:00:00  LTCUSDT  41.28  41.70  41.27   \n",
       "26273  1577836800000  2020-01-01 00:00:00  LTCUSDT  41.29  41.29  41.16   \n",
       "\n",
       "       Close   Volume LTC   Volume USDT  tradecount  \n",
       "0      70.14  13547.20800  9.486568e+05        2306  \n",
       "1      70.09  12617.98300  8.838422e+05        2288  \n",
       "2      70.23   9698.22600  6.820723e+05        1580  \n",
       "3      70.39  16666.36600  1.173164e+06        2150  \n",
       "4      70.15  14214.55000  9.964355e+05        2499  \n",
       "...      ...          ...           ...         ...  \n",
       "26269  41.59   5317.81964  2.214516e+05         668  \n",
       "26270  41.53   3873.02370  1.613043e+05         400  \n",
       "26271  41.85   5757.19484  2.402871e+05         762  \n",
       "26272  41.62   6814.68608  2.830715e+05         997  \n",
       "26273  41.28   2828.06038  1.165827e+05         396  \n",
       "\n",
       "[26274 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltc_dfd = pd.read_csv('../Dataset/Binance_LTCUSDT_1h.csv')\n",
    "ltc_dfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41062755-9cca-4348-91bc-e80d46b79c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume USDT</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.29</td>\n",
       "      <td>41.29</td>\n",
       "      <td>41.16</td>\n",
       "      <td>1.165827e+05</td>\n",
       "      <td>41.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.28</td>\n",
       "      <td>41.70</td>\n",
       "      <td>41.27</td>\n",
       "      <td>2.830715e+05</td>\n",
       "      <td>41.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.63</td>\n",
       "      <td>41.88</td>\n",
       "      <td>41.62</td>\n",
       "      <td>2.402871e+05</td>\n",
       "      <td>41.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.84</td>\n",
       "      <td>41.85</td>\n",
       "      <td>41.49</td>\n",
       "      <td>1.613043e+05</td>\n",
       "      <td>41.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.53</td>\n",
       "      <td>41.85</td>\n",
       "      <td>41.45</td>\n",
       "      <td>2.214516e+05</td>\n",
       "      <td>41.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26269</th>\n",
       "      <td>69.93</td>\n",
       "      <td>70.32</td>\n",
       "      <td>69.93</td>\n",
       "      <td>9.964355e+05</td>\n",
       "      <td>70.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>70.15</td>\n",
       "      <td>70.53</td>\n",
       "      <td>70.08</td>\n",
       "      <td>1.173164e+06</td>\n",
       "      <td>70.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26271</th>\n",
       "      <td>70.40</td>\n",
       "      <td>70.45</td>\n",
       "      <td>70.19</td>\n",
       "      <td>6.820723e+05</td>\n",
       "      <td>70.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>70.24</td>\n",
       "      <td>70.24</td>\n",
       "      <td>69.71</td>\n",
       "      <td>8.838422e+05</td>\n",
       "      <td>70.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26273</th>\n",
       "      <td>70.08</td>\n",
       "      <td>70.30</td>\n",
       "      <td>69.79</td>\n",
       "      <td>9.486568e+05</td>\n",
       "      <td>70.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26274 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open   High    Low   Volume USDT  Close\n",
       "0      41.29  41.29  41.16  1.165827e+05  41.28\n",
       "1      41.28  41.70  41.27  2.830715e+05  41.62\n",
       "2      41.63  41.88  41.62  2.402871e+05  41.85\n",
       "3      41.84  41.85  41.49  1.613043e+05  41.53\n",
       "4      41.53  41.85  41.45  2.214516e+05  41.59\n",
       "...      ...    ...    ...           ...    ...\n",
       "26269  69.93  70.32  69.93  9.964355e+05  70.15\n",
       "26270  70.15  70.53  70.08  1.173164e+06  70.39\n",
       "26271  70.40  70.45  70.19  6.820723e+05  70.23\n",
       "26272  70.24  70.24  69.71  8.838422e+05  70.09\n",
       "26273  70.08  70.30  69.79  9.486568e+05  70.14\n",
       "\n",
       "[26274 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Preprocessing.feature_selection(ltc_dfd)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc368c1b-a82f-4dbf-85c4-f19ebff7a21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume USDT</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.29</td>\n",
       "      <td>41.29</td>\n",
       "      <td>41.16</td>\n",
       "      <td>1.165827e+05</td>\n",
       "      <td>41.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.28</td>\n",
       "      <td>41.70</td>\n",
       "      <td>41.27</td>\n",
       "      <td>2.830715e+05</td>\n",
       "      <td>41.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.63</td>\n",
       "      <td>41.88</td>\n",
       "      <td>41.62</td>\n",
       "      <td>2.402871e+05</td>\n",
       "      <td>41.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.84</td>\n",
       "      <td>41.85</td>\n",
       "      <td>41.49</td>\n",
       "      <td>1.613043e+05</td>\n",
       "      <td>41.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.53</td>\n",
       "      <td>41.85</td>\n",
       "      <td>41.45</td>\n",
       "      <td>2.214516e+05</td>\n",
       "      <td>41.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26269</th>\n",
       "      <td>69.93</td>\n",
       "      <td>70.32</td>\n",
       "      <td>69.93</td>\n",
       "      <td>9.964355e+05</td>\n",
       "      <td>70.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>70.15</td>\n",
       "      <td>70.53</td>\n",
       "      <td>70.08</td>\n",
       "      <td>1.173164e+06</td>\n",
       "      <td>70.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26271</th>\n",
       "      <td>70.40</td>\n",
       "      <td>70.45</td>\n",
       "      <td>70.19</td>\n",
       "      <td>6.820723e+05</td>\n",
       "      <td>70.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26272</th>\n",
       "      <td>70.24</td>\n",
       "      <td>70.24</td>\n",
       "      <td>69.71</td>\n",
       "      <td>8.838422e+05</td>\n",
       "      <td>70.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26273</th>\n",
       "      <td>70.08</td>\n",
       "      <td>70.30</td>\n",
       "      <td>69.79</td>\n",
       "      <td>9.486568e+05</td>\n",
       "      <td>70.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26274 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open   High    Low   Volume USDT  Close\n",
       "0      41.29  41.29  41.16  1.165827e+05  41.28\n",
       "1      41.28  41.70  41.27  2.830715e+05  41.62\n",
       "2      41.63  41.88  41.62  2.402871e+05  41.85\n",
       "3      41.84  41.85  41.49  1.613043e+05  41.53\n",
       "4      41.53  41.85  41.45  2.214516e+05  41.59\n",
       "...      ...    ...    ...           ...    ...\n",
       "26269  69.93  70.32  69.93  9.964355e+05  70.15\n",
       "26270  70.15  70.53  70.08  1.173164e+06  70.39\n",
       "26271  70.40  70.45  70.19  6.820723e+05  70.23\n",
       "26272  70.24  70.24  69.71  8.838422e+05  70.09\n",
       "26273  70.08  70.30  69.79  9.486568e+05  70.14\n",
       "\n",
       "[26274 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_dup = Preprocessing.handle_duplicate(df)\n",
    "df_no_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "483f3731-9efb-47c6-af9c-6eadc95287e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss = Preprocessing.handle_missing_value(df_no_dup)\n",
    "miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "140ecfee-f8cf-45f6-b3c6-49e8e7458101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04173275, 0.03083012, 0.04530095, 0.00027277, 0.04170567],\n",
       "       [0.04170675, 0.03189772, 0.04559134, 0.00066231, 0.0425897 ],\n",
       "       [0.04261681, 0.03236642, 0.04651531, 0.0005622 , 0.04318773],\n",
       "       ...,\n",
       "       [0.11742375, 0.10675971, 0.1219377 , 0.00159586, 0.11697868],\n",
       "       [0.11700772, 0.10621289, 0.12067054, 0.00206794, 0.11661466],\n",
       "       [0.1165917 , 0.10636913, 0.12088173, 0.00221959, 0.11674467]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, scaler = Preprocessing.minmax_scale(df_no_dup)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c42a7847-70b8-4487-a874-67e370666724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04173275, 0.03083012, 0.04530095, 0.00027277, 0.04170567],\n",
       "       [0.04170675, 0.03189772, 0.04559134, 0.00066231, 0.0425897 ],\n",
       "       [0.04261681, 0.03236642, 0.04651531, 0.0005622 , 0.04318773],\n",
       "       ...,\n",
       "       [0.10182272, 0.09230809, 0.1061246 , 0.00158488, 0.10208008],\n",
       "       [0.10182272, 0.09178731, 0.10374868, 0.00463816, 0.09947998],\n",
       "       [0.09922255, 0.09022498, 0.10295671, 0.00463943, 0.09869995]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = Preprocessing.splitting_data(x)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8e525a6-83d0-4c8b-9875-33e0e15480ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0984425 , 0.08866264, 0.09873284, 0.00605067, 0.09427977],\n",
       "       [0.09454224, 0.08579835, 0.09794087, 0.00786288, 0.09557982],\n",
       "       [0.09584233, 0.08892303, 0.1000528 , 0.00411582, 0.09791992],\n",
       "       ...,\n",
       "       [0.11742375, 0.10675971, 0.1219377 , 0.00159586, 0.11697868],\n",
       "       [0.11700772, 0.10621289, 0.12067054, 0.00206794, 0.11661466],\n",
       "       [0.1165917 , 0.10636913, 0.12088173, 0.00221959, 0.11674467]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08213717-a303-4c9e-97bb-280204035109",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = Preprocessing.create_dataset(train,5)\n",
    "test_X, test_y = Preprocessing.create_dataset(test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aff76bd7-16f2-4bf2-8a64-f1f6a1194661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.04173275, 0.03083012, 0.04530095, 0.00027277, 0.04170567],\n",
       "        [0.04170675, 0.03189772, 0.04559134, 0.00066231, 0.0425897 ],\n",
       "        [0.04261681, 0.03236642, 0.04651531, 0.0005622 , 0.04318773],\n",
       "        [0.04316285, 0.0322883 , 0.04617212, 0.00037741, 0.04235569],\n",
       "        [0.0423568 , 0.0322883 , 0.04606653, 0.00051813, 0.0425117 ]],\n",
       "\n",
       "       [[0.04170675, 0.03189772, 0.04559134, 0.00066231, 0.0425897 ],\n",
       "        [0.04261681, 0.03236642, 0.04651531, 0.0005622 , 0.04318773],\n",
       "        [0.04316285, 0.0322883 , 0.04617212, 0.00037741, 0.04235569],\n",
       "        [0.0423568 , 0.0322883 , 0.04606653, 0.00051813, 0.0425117 ],\n",
       "        [0.04256481, 0.03226226, 0.04643611, 0.00024607, 0.04300572]],\n",
       "\n",
       "       [[0.04261681, 0.03236642, 0.04651531, 0.0005622 , 0.04318773],\n",
       "        [0.04316285, 0.0322883 , 0.04617212, 0.00037741, 0.04235569],\n",
       "        [0.0423568 , 0.0322883 , 0.04606653, 0.00051813, 0.0425117 ],\n",
       "        [0.04256481, 0.03226226, 0.04643611, 0.00024607, 0.04300572],\n",
       "        [0.04303284, 0.03221019, 0.04619852, 0.00071414, 0.0425897 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.10338282, 0.09361004, 0.10744456, 0.00213417, 0.10338014],\n",
       "        [0.10338282, 0.09282887, 0.10718057, 0.00250514, 0.10286011],\n",
       "        [0.10312281, 0.09230809, 0.10454065, 0.00278656, 0.09973999],\n",
       "        [0.09974258, 0.09074576, 0.10401267, 0.00305138, 0.10104004],\n",
       "        [0.10130269, 0.0920477 , 0.10586061, 0.0014772 , 0.10182007]],\n",
       "\n",
       "       [[0.10338282, 0.09282887, 0.10718057, 0.00250514, 0.10286011],\n",
       "        [0.10312281, 0.09230809, 0.10454065, 0.00278656, 0.09973999],\n",
       "        [0.09974258, 0.09074576, 0.10401267, 0.00305138, 0.10104004],\n",
       "        [0.10130269, 0.0920477 , 0.10586061, 0.0014772 , 0.10182007],\n",
       "        [0.10182272, 0.09230809, 0.1061246 , 0.00158488, 0.10208008]],\n",
       "\n",
       "       [[0.10312281, 0.09230809, 0.10454065, 0.00278656, 0.09973999],\n",
       "        [0.09974258, 0.09074576, 0.10401267, 0.00305138, 0.10104004],\n",
       "        [0.10130269, 0.0920477 , 0.10586061, 0.0014772 , 0.10182007],\n",
       "        [0.10182272, 0.09230809, 0.1061246 , 0.00158488, 0.10208008],\n",
       "        [0.10182272, 0.09178731, 0.10374868, 0.00463816, 0.09947998]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4efa14c4-f85e-47c3-bc04-7f0d029d3a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04300572, 0.0425897 , 0.0424857 , ..., 0.10208008, 0.09947998,\n",
       "       0.09869995])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51dc56af-5903-45ab-a70b-556fb3f3d97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.0984425 , 0.08866264, 0.09873284, 0.00605067, 0.09427977],\n",
       "        [0.09454224, 0.08579835, 0.09794087, 0.00786288, 0.09557982],\n",
       "        [0.09584233, 0.08892303, 0.1000528 , 0.00411582, 0.09791992],\n",
       "        [0.09818248, 0.08840225, 0.10058078, 0.00425213, 0.09635985],\n",
       "        [0.09610234, 0.08683991, 0.09794087, 0.00731901, 0.0950598 ]],\n",
       "\n",
       "       [[0.09454224, 0.08579835, 0.09794087, 0.00786288, 0.09557982],\n",
       "        [0.09584233, 0.08892303, 0.1000528 , 0.00411582, 0.09791992],\n",
       "        [0.09818248, 0.08840225, 0.10058078, 0.00425213, 0.09635985],\n",
       "        [0.09610234, 0.08683991, 0.09794087, 0.00731901, 0.0950598 ],\n",
       "        [0.09480226, 0.08736069, 0.09794087, 0.00717084, 0.09791992]],\n",
       "\n",
       "       [[0.09584233, 0.08892303, 0.1000528 , 0.00411582, 0.09791992],\n",
       "        [0.09818248, 0.08840225, 0.10058078, 0.00425213, 0.09635985],\n",
       "        [0.09610234, 0.08683991, 0.09794087, 0.00731901, 0.0950598 ],\n",
       "        [0.09480226, 0.08736069, 0.09794087, 0.00717084, 0.09791992],\n",
       "        [0.09792246, 0.08944381, 0.10190074, 0.00467747, 0.09713989]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.11656569, 0.1066816 , 0.12125132, 0.00331899, 0.11690068],\n",
       "        [0.11687771, 0.10644725, 0.12088173, 0.00279403, 0.11679667],\n",
       "        [0.11679971, 0.10618686, 0.12111932, 0.00139576, 0.11619865],\n",
       "        [0.11620167, 0.10642121, 0.12125132, 0.00233138, 0.11677067],\n",
       "        [0.11677371, 0.10696802, 0.12164731, 0.00274487, 0.1173947 ]],\n",
       "\n",
       "       [[0.11687771, 0.10644725, 0.12088173, 0.00279403, 0.11679667],\n",
       "        [0.11679971, 0.10618686, 0.12111932, 0.00139576, 0.11619865],\n",
       "        [0.11620167, 0.10642121, 0.12125132, 0.00233138, 0.11677067],\n",
       "        [0.11677371, 0.10696802, 0.12164731, 0.00274487, 0.1173947 ],\n",
       "        [0.11742375, 0.10675971, 0.1219377 , 0.00159586, 0.11697868]],\n",
       "\n",
       "       [[0.11679971, 0.10618686, 0.12111932, 0.00139576, 0.11619865],\n",
       "        [0.11620167, 0.10642121, 0.12125132, 0.00233138, 0.11677067],\n",
       "        [0.11677371, 0.10696802, 0.12164731, 0.00274487, 0.1173947 ],\n",
       "        [0.11742375, 0.10675971, 0.1219377 , 0.00159586, 0.11697868],\n",
       "        [0.11700772, 0.10621289, 0.12067054, 0.00206794, 0.11661466]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d98152d5-e8c5-4645-90ea-876a042b25e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09791992, 0.09713989, 0.09687988, ..., 0.11697868, 0.11661466,\n",
       "       0.11674467])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d80df0f9-fe70-44f0-bef3-b779d95da0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21014, 5, 5) (21014,) (5250, 5, 5) (5250,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf43011a-1b18-4fef-b638-d84109a5347b",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c6e3c5f-f40b-427b-bbf6-715de9fbfed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 100, 50),\n",
       " (32, 100, 60),\n",
       " (32, 100, 100),\n",
       " (64, 100, 50),\n",
       " (64, 100, 60),\n",
       " (64, 100, 100),\n",
       " (128, 100, 50),\n",
       " (128, 100, 60),\n",
       " (128, 100, 100)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams = []\n",
    "batch = [32, 64, 128]\n",
    "epoch = [100]\n",
    "neuron = [50, 60, 100]\n",
    "for j in batch:\n",
    "    for k in epoch:\n",
    "        for l in neuron:\n",
    "            hyperparams.append((j,k,l))\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ffd8dc1-5eb8-4d7e-aba2-cab78df020ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 09:56:09.834197: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-21 09:56:09.834286: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-03-21 09:56:09.996910: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-03-21 09:56:11.246326: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 09:56:11.424121: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 09:56:11.455380: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 09:56:13.348253: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 09:56:13.364200: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 09:56:22.535433: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 09:56:22.602245: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 09:56:22.612536: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 - 14s - loss: 1.7017e-04 - val_loss: 1.9705e-05 - 14s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "657/657 - 9s - loss: 1.7733e-04 - val_loss: 2.6717e-05 - 9s/epoch - 13ms/step\n",
      "Epoch 3/100\n",
      "657/657 - 9s - loss: 3.1728e-04 - val_loss: 3.5580e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 4/100\n",
      "657/657 - 9s - loss: 7.1563e-04 - val_loss: 6.5755e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 5/100\n",
      "657/657 - 9s - loss: 7.5823e-04 - val_loss: 7.0399e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "657/657 - 9s - loss: 5.1108e-04 - val_loss: 3.4501e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 7/100\n",
      "657/657 - 9s - loss: 3.5233e-04 - val_loss: 1.6399e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "657/657 - 9s - loss: 2.6809e-04 - val_loss: 1.0274e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 9/100\n",
      "657/657 - 9s - loss: 2.3261e-04 - val_loss: 8.5641e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 10/100\n",
      "657/657 - 9s - loss: 2.2347e-04 - val_loss: 8.7530e-06 - 9s/epoch - 13ms/step\n",
      "Epoch 11/100\n",
      "657/657 - 9s - loss: 2.2838e-04 - val_loss: 9.4862e-06 - 9s/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "657/657 - 9s - loss: 2.3453e-04 - val_loss: 9.6415e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "657/657 - 9s - loss: 2.3237e-04 - val_loss: 9.1568e-06 - 9s/epoch - 13ms/step\n",
      "Epoch 14/100\n",
      "657/657 - 9s - loss: 2.2269e-04 - val_loss: 8.4109e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "657/657 - 9s - loss: 2.0954e-04 - val_loss: 8.0241e-06 - 9s/epoch - 13ms/step\n",
      "Epoch 16/100\n",
      "657/657 - 9s - loss: 1.9936e-04 - val_loss: 7.7634e-06 - 9s/epoch - 13ms/step\n",
      "Epoch 17/100\n",
      "657/657 - 9s - loss: 1.9324e-04 - val_loss: 7.4558e-06 - 9s/epoch - 13ms/step\n",
      "Epoch 18/100\n",
      "657/657 - 9s - loss: 1.8632e-04 - val_loss: 7.1852e-06 - 9s/epoch - 13ms/step\n",
      "Epoch 19/100\n",
      "657/657 - 9s - loss: 1.8026e-04 - val_loss: 6.9534e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 20/100\n",
      "657/657 - 9s - loss: 1.7496e-04 - val_loss: 6.7506e-06 - 9s/epoch - 13ms/step\n",
      "Epoch 21/100\n",
      "657/657 - 9s - loss: 1.6960e-04 - val_loss: 6.5276e-06 - 9s/epoch - 13ms/step\n",
      "Epoch 22/100\n",
      "657/657 - 9s - loss: 1.6370e-04 - val_loss: 6.3757e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "657/657 - 9s - loss: 1.5911e-04 - val_loss: 6.1715e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "657/657 - 9s - loss: 1.5419e-04 - val_loss: 6.0483e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 25/100\n",
      "657/657 - 9s - loss: 1.4912e-04 - val_loss: 5.8465e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 26/100\n",
      "657/657 - 9s - loss: 1.4546e-04 - val_loss: 5.7356e-06 - 9s/epoch - 13ms/step\n",
      "Epoch 27/100\n",
      "657/657 - 9s - loss: 1.4167e-04 - val_loss: 5.3554e-06 - 9s/epoch - 13ms/step\n",
      "Epoch 28/100\n",
      "657/657 - 9s - loss: 1.3817e-04 - val_loss: 5.4006e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 29/100\n",
      "657/657 - 9s - loss: 1.3272e-04 - val_loss: 4.8474e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 30/100\n",
      "657/657 - 9s - loss: 1.3062e-04 - val_loss: 5.0628e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 31/100\n",
      "657/657 - 9s - loss: 1.2914e-04 - val_loss: 4.6983e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 32/100\n",
      "657/657 - 9s - loss: 1.2384e-04 - val_loss: 4.7167e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 33/100\n",
      "657/657 - 9s - loss: 1.1860e-04 - val_loss: 4.3441e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 34/100\n",
      "657/657 - 9s - loss: 1.1896e-04 - val_loss: 4.6342e-06 - 9s/epoch - 13ms/step\n",
      "Epoch 35/100\n",
      "657/657 - 9s - loss: 1.1983e-04 - val_loss: 4.2068e-06 - 9s/epoch - 13ms/step\n",
      "Epoch 36/100\n",
      "657/657 - 9s - loss: 1.1301e-04 - val_loss: 4.2322e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 37/100\n",
      "657/657 - 9s - loss: 1.0685e-04 - val_loss: 3.8901e-06 - 9s/epoch - 13ms/step\n",
      "Epoch 38/100\n",
      "657/657 - 9s - loss: 1.0917e-04 - val_loss: 4.2331e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 39/100\n",
      "657/657 - 9s - loss: 1.1377e-04 - val_loss: 3.9041e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 40/100\n",
      "657/657 - 9s - loss: 1.0395e-04 - val_loss: 3.7526e-06 - 9s/epoch - 13ms/step\n",
      "Epoch 41/100\n",
      "657/657 - 9s - loss: 1.0297e-04 - val_loss: 3.8019e-06 - 9s/epoch - 13ms/step\n",
      "Epoch 42/100\n",
      "657/657 - 9s - loss: 9.6996e-05 - val_loss: 3.5743e-06 - 9s/epoch - 13ms/step\n",
      "Epoch 43/100\n",
      "657/657 - 9s - loss: 1.0075e-04 - val_loss: 3.8931e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 44/100\n",
      "657/657 - 9s - loss: 1.0602e-04 - val_loss: 3.6044e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 45/100\n",
      "657/657 - 9s - loss: 9.6092e-05 - val_loss: 3.4410e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 46/100\n",
      "657/657 - 9s - loss: 9.5380e-05 - val_loss: 3.5135e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 47/100\n",
      "657/657 - 9s - loss: 9.0614e-05 - val_loss: 3.3337e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 48/100\n",
      "657/657 - 9s - loss: 9.4261e-05 - val_loss: 3.5504e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 49/100\n",
      "657/657 - 9s - loss: 9.8975e-05 - val_loss: 3.3036e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 50/100\n",
      "657/657 - 9s - loss: 9.0723e-05 - val_loss: 3.1679e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 51/100\n",
      "657/657 - 9s - loss: 9.0135e-05 - val_loss: 3.2056e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 52/100\n",
      "657/657 - 9s - loss: 8.6526e-05 - val_loss: 3.0945e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 53/100\n",
      "657/657 - 9s - loss: 8.9071e-05 - val_loss: 3.2169e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 54/100\n",
      "657/657 - 9s - loss: 9.1984e-05 - val_loss: 3.0555e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 55/100\n",
      "657/657 - 9s - loss: 8.6431e-05 - val_loss: 2.9772e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 56/100\n",
      "657/657 - 9s - loss: 8.5594e-05 - val_loss: 2.9782e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 57/100\n",
      "657/657 - 9s - loss: 8.1982e-05 - val_loss: 2.9345e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 58/100\n",
      "657/657 - 9s - loss: 8.4380e-05 - val_loss: 3.0198e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 59/100\n",
      "657/657 - 9s - loss: 8.7018e-05 - val_loss: 2.8969e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 60/100\n",
      "657/657 - 9s - loss: 8.2441e-05 - val_loss: 2.8381e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 61/100\n",
      "657/657 - 9s - loss: 8.1351e-05 - val_loss: 2.8362e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 62/100\n",
      "657/657 - 9s - loss: 7.8576e-05 - val_loss: 2.8231e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 63/100\n",
      "657/657 - 9s - loss: 8.0194e-05 - val_loss: 2.8822e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 64/100\n",
      "657/657 - 9s - loss: 8.1844e-05 - val_loss: 2.7946e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 65/100\n",
      "657/657 - 9s - loss: 7.9137e-05 - val_loss: 2.7628e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 66/100\n",
      "657/657 - 9s - loss: 7.6246e-05 - val_loss: 2.7608e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 67/100\n",
      "657/657 - 9s - loss: 7.6902e-05 - val_loss: 2.8114e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 68/100\n",
      "657/657 - 9s - loss: 7.6810e-05 - val_loss: 2.7670e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 69/100\n",
      "657/657 - 9s - loss: 7.6094e-05 - val_loss: 2.7898e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 70/100\n",
      "657/657 - 9s - loss: 7.5007e-05 - val_loss: 2.7521e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 71/100\n",
      "657/657 - 9s - loss: 7.4418e-05 - val_loss: 2.7920e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 72/100\n",
      "657/657 - 9s - loss: 7.3650e-05 - val_loss: 2.7584e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 73/100\n",
      "657/657 - 9s - loss: 7.3195e-05 - val_loss: 2.8053e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 74/100\n",
      "657/657 - 9s - loss: 7.2393e-05 - val_loss: 2.7712e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 75/100\n",
      "657/657 - 9s - loss: 7.1985e-05 - val_loss: 2.8283e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 76/100\n",
      "657/657 - 9s - loss: 7.1356e-05 - val_loss: 2.7924e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 77/100\n",
      "657/657 - 9s - loss: 7.0848e-05 - val_loss: 2.8562e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 78/100\n",
      "657/657 - 9s - loss: 7.0051e-05 - val_loss: 2.8242e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 79/100\n",
      "657/657 - 9s - loss: 6.9751e-05 - val_loss: 2.9072e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 80/100\n",
      "657/657 - 9s - loss: 6.9313e-05 - val_loss: 2.8688e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 81/100\n",
      "657/657 - 9s - loss: 6.8836e-05 - val_loss: 2.9533e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 82/100\n",
      "657/657 - 9s - loss: 6.8079e-05 - val_loss: 2.9162e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 83/100\n",
      "657/657 - 9s - loss: 6.7903e-05 - val_loss: 3.0192e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 84/100\n",
      "657/657 - 9s - loss: 6.7648e-05 - val_loss: 2.9646e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 85/100\n",
      "657/657 - 9s - loss: 6.7196e-05 - val_loss: 3.0499e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 86/100\n",
      "657/657 - 9s - loss: 6.6505e-05 - val_loss: 2.9965e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 87/100\n",
      "657/657 - 9s - loss: 6.6443e-05 - val_loss: 3.0962e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 88/100\n",
      "657/657 - 9s - loss: 6.6382e-05 - val_loss: 3.0263e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 89/100\n",
      "657/657 - 9s - loss: 6.5951e-05 - val_loss: 3.1036e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 90/100\n",
      "657/657 - 9s - loss: 6.5335e-05 - val_loss: 3.0434e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 91/100\n",
      "657/657 - 9s - loss: 6.5267e-05 - val_loss: 3.1427e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 92/100\n",
      "657/657 - 9s - loss: 6.5288e-05 - val_loss: 3.0671e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 93/100\n",
      "657/657 - 9s - loss: 6.4802e-05 - val_loss: 3.1461e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 94/100\n",
      "657/657 - 9s - loss: 6.4238e-05 - val_loss: 3.0816e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 95/100\n",
      "657/657 - 9s - loss: 6.4151e-05 - val_loss: 3.1855e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 96/100\n",
      "657/657 - 9s - loss: 6.4225e-05 - val_loss: 3.1027e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 97/100\n",
      "657/657 - 9s - loss: 6.3732e-05 - val_loss: 3.1839e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 98/100\n",
      "657/657 - 9s - loss: 6.3252e-05 - val_loss: 3.1106e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 99/100\n",
      "657/657 - 9s - loss: 6.3127e-05 - val_loss: 3.2133e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 100/100\n",
      "657/657 - 9s - loss: 6.3214e-05 - val_loss: 3.1220e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 10:11:15.386911: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:11:15.544594: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:11:15.557123: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:11:15.666783: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:11:15.685310: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:11:24.429733: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:11:24.485585: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:11:24.495528: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 - 11s - loss: 1.4739e-04 - val_loss: 2.0457e-05 - 11s/epoch - 17ms/step\n",
      "Epoch 2/100\n",
      "657/657 - 9s - loss: 1.3827e-04 - val_loss: 2.3643e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 3/100\n",
      "657/657 - 9s - loss: 1.9092e-04 - val_loss: 3.1788e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 4/100\n",
      "657/657 - 9s - loss: 3.4513e-04 - val_loss: 5.9606e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 5/100\n",
      "657/657 - 9s - loss: 7.8759e-04 - val_loss: 1.0708e-04 - 9s/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "657/657 - 9s - loss: 7.9080e-04 - val_loss: 9.6466e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 7/100\n",
      "657/657 - 9s - loss: 5.1834e-04 - val_loss: 4.5348e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "657/657 - 9s - loss: 3.4612e-04 - val_loss: 1.9224e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 9/100\n",
      "657/657 - 9s - loss: 2.5460e-04 - val_loss: 1.0919e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 10/100\n",
      "657/657 - 9s - loss: 2.1632e-04 - val_loss: 8.8960e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 11/100\n",
      "657/657 - 9s - loss: 2.0743e-04 - val_loss: 8.8751e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 12/100\n",
      "657/657 - 9s - loss: 2.1347e-04 - val_loss: 9.7171e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "657/657 - 9s - loss: 2.2152e-04 - val_loss: 1.0269e-05 - 9s/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "657/657 - 9s - loss: 2.2157e-04 - val_loss: 9.9026e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "657/657 - 9s - loss: 2.1372e-04 - val_loss: 9.1124e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "657/657 - 9s - loss: 2.0106e-04 - val_loss: 8.4210e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 17/100\n",
      "657/657 - 9s - loss: 1.9030e-04 - val_loss: 7.9314e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 18/100\n",
      "657/657 - 9s - loss: 1.8392e-04 - val_loss: 7.7289e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 19/100\n",
      "657/657 - 9s - loss: 1.8000e-04 - val_loss: 7.5499e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 20/100\n",
      "657/657 - 9s - loss: 1.7656e-04 - val_loss: 7.3822e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 21/100\n",
      "657/657 - 9s - loss: 1.7092e-04 - val_loss: 7.0229e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 22/100\n",
      "657/657 - 9s - loss: 1.6658e-04 - val_loss: 6.6792e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "657/657 - 9s - loss: 1.6139e-04 - val_loss: 6.4627e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "657/657 - 9s - loss: 1.5902e-04 - val_loss: 6.1330e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 25/100\n",
      "657/657 - 9s - loss: 1.5475e-04 - val_loss: 5.8970e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 26/100\n",
      "657/657 - 9s - loss: 1.5033e-04 - val_loss: 5.5905e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "657/657 - 9s - loss: 1.4633e-04 - val_loss: 5.4040e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 28/100\n",
      "657/657 - 9s - loss: 1.4321e-04 - val_loss: 5.2034e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 29/100\n",
      "657/657 - 9s - loss: 1.4070e-04 - val_loss: 5.1191e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 30/100\n",
      "657/657 - 10s - loss: 1.3746e-04 - val_loss: 4.7878e-06 - 10s/epoch - 14ms/step\n",
      "Epoch 31/100\n",
      "657/657 - 9s - loss: 1.3356e-04 - val_loss: 4.7911e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 32/100\n",
      "657/657 - 9s - loss: 1.3138e-04 - val_loss: 4.4757e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 33/100\n",
      "657/657 - 9s - loss: 1.2860e-04 - val_loss: 4.4721e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 34/100\n",
      "657/657 - 9s - loss: 1.2490e-04 - val_loss: 4.1318e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 35/100\n",
      "657/657 - 9s - loss: 1.2217e-04 - val_loss: 4.2445e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 36/100\n",
      "657/657 - 9s - loss: 1.2086e-04 - val_loss: 3.8902e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 37/100\n",
      "657/657 - 9s - loss: 1.1842e-04 - val_loss: 3.9471e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 38/100\n",
      "657/657 - 9s - loss: 1.1562e-04 - val_loss: 3.6227e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 39/100\n",
      "657/657 - 9s - loss: 1.1337e-04 - val_loss: 3.7044e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 40/100\n",
      "657/657 - 9s - loss: 1.1107e-04 - val_loss: 3.4426e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 41/100\n",
      "657/657 - 9s - loss: 1.0943e-04 - val_loss: 3.5422e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 42/100\n",
      "657/657 - 9s - loss: 1.0744e-04 - val_loss: 3.2953e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 43/100\n",
      "657/657 - 9s - loss: 1.0602e-04 - val_loss: 3.3731e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 44/100\n",
      "657/657 - 9s - loss: 1.0337e-04 - val_loss: 3.1785e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 45/100\n",
      "657/657 - 9s - loss: 1.0271e-04 - val_loss: 3.2525e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 46/100\n",
      "657/657 - 9s - loss: 1.0002e-04 - val_loss: 3.0762e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 47/100\n",
      "657/657 - 9s - loss: 9.9469e-05 - val_loss: 3.1212e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 48/100\n",
      "657/657 - 9s - loss: 9.6476e-05 - val_loss: 3.0158e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 49/100\n",
      "657/657 - 9s - loss: 9.6911e-05 - val_loss: 3.0575e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 50/100\n",
      "657/657 - 10s - loss: 9.3399e-05 - val_loss: 2.9573e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 51/100\n",
      "657/657 - 9s - loss: 9.3984e-05 - val_loss: 3.0087e-06 - 9s/epoch - 14ms/step\n",
      "Epoch 52/100\n",
      "657/657 - 10s - loss: 9.0341e-05 - val_loss: 2.9272e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 53/100\n",
      "657/657 - 10s - loss: 9.1569e-05 - val_loss: 2.9716e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 54/100\n",
      "657/657 - 10s - loss: 8.7491e-05 - val_loss: 2.9122e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 55/100\n",
      "657/657 - 10s - loss: 8.9100e-05 - val_loss: 2.9668e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 56/100\n",
      "657/657 - 10s - loss: 8.4885e-05 - val_loss: 2.9174e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 57/100\n",
      "657/657 - 10s - loss: 8.6978e-05 - val_loss: 2.9969e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 58/100\n",
      "657/657 - 10s - loss: 8.2583e-05 - val_loss: 2.9378e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 59/100\n",
      "657/657 - 10s - loss: 8.4928e-05 - val_loss: 3.0270e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 60/100\n",
      "657/657 - 10s - loss: 8.0592e-05 - val_loss: 2.9755e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 61/100\n",
      "657/657 - 10s - loss: 8.3147e-05 - val_loss: 3.0688e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 62/100\n",
      "657/657 - 10s - loss: 7.8855e-05 - val_loss: 3.0052e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 63/100\n",
      "657/657 - 10s - loss: 8.1595e-05 - val_loss: 3.0886e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 64/100\n",
      "657/657 - 10s - loss: 7.7433e-05 - val_loss: 2.9902e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 65/100\n",
      "657/657 - 10s - loss: 8.0289e-05 - val_loss: 3.0450e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 66/100\n",
      "657/657 - 10s - loss: 7.6340e-05 - val_loss: 2.9475e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 67/100\n",
      "657/657 - 10s - loss: 7.9242e-05 - val_loss: 2.9908e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 68/100\n",
      "657/657 - 10s - loss: 7.5392e-05 - val_loss: 2.9063e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 69/100\n",
      "657/657 - 10s - loss: 7.8216e-05 - val_loss: 2.9569e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 70/100\n",
      "657/657 - 10s - loss: 7.4428e-05 - val_loss: 2.8781e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 71/100\n",
      "657/657 - 10s - loss: 7.7163e-05 - val_loss: 2.9304e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 72/100\n",
      "657/657 - 10s - loss: 7.3512e-05 - val_loss: 2.8635e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 73/100\n",
      "657/657 - 10s - loss: 7.6207e-05 - val_loss: 2.9174e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 74/100\n",
      "657/657 - 10s - loss: 7.2691e-05 - val_loss: 2.8533e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 75/100\n",
      "657/657 - 10s - loss: 7.5301e-05 - val_loss: 2.9063e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 76/100\n",
      "657/657 - 10s - loss: 7.1937e-05 - val_loss: 2.8450e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 77/100\n",
      "657/657 - 10s - loss: 7.4464e-05 - val_loss: 2.8946e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 78/100\n",
      "657/657 - 10s - loss: 7.1258e-05 - val_loss: 2.8360e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 79/100\n",
      "657/657 - 10s - loss: 7.3644e-05 - val_loss: 2.8850e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 80/100\n",
      "657/657 - 10s - loss: 7.0560e-05 - val_loss: 2.8271e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 81/100\n",
      "657/657 - 10s - loss: 7.2816e-05 - val_loss: 2.8836e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 82/100\n",
      "657/657 - 10s - loss: 6.9899e-05 - val_loss: 2.8212e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 83/100\n",
      "657/657 - 10s - loss: 7.2017e-05 - val_loss: 2.8777e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 84/100\n",
      "657/657 - 10s - loss: 6.9266e-05 - val_loss: 2.8178e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 85/100\n",
      "657/657 - 10s - loss: 7.1250e-05 - val_loss: 2.8809e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 86/100\n",
      "657/657 - 10s - loss: 6.8680e-05 - val_loss: 2.8172e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 87/100\n",
      "657/657 - 10s - loss: 7.0518e-05 - val_loss: 2.8788e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 88/100\n",
      "657/657 - 10s - loss: 6.8104e-05 - val_loss: 2.8182e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 89/100\n",
      "657/657 - 10s - loss: 6.9807e-05 - val_loss: 2.8840e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 90/100\n",
      "657/657 - 10s - loss: 6.7554e-05 - val_loss: 2.8205e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 91/100\n",
      "657/657 - 10s - loss: 6.9120e-05 - val_loss: 2.8816e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 92/100\n",
      "657/657 - 10s - loss: 6.7017e-05 - val_loss: 2.8240e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 93/100\n",
      "657/657 - 10s - loss: 6.8455e-05 - val_loss: 2.8875e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 94/100\n",
      "657/657 - 10s - loss: 6.6503e-05 - val_loss: 2.8283e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 95/100\n",
      "657/657 - 10s - loss: 6.7812e-05 - val_loss: 2.8892e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 96/100\n",
      "657/657 - 10s - loss: 6.5999e-05 - val_loss: 2.8333e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "657/657 - 10s - loss: 6.7189e-05 - val_loss: 2.8901e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 98/100\n",
      "657/657 - 10s - loss: 6.5509e-05 - val_loss: 2.8400e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 99/100\n",
      "657/657 - 10s - loss: 6.6586e-05 - val_loss: 2.8943e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 100/100\n",
      "657/657 - 10s - loss: 6.5032e-05 - val_loss: 2.8449e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 10:27:19.717695: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:27:19.884034: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:27:19.897708: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:27:20.149684: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:27:20.170574: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:27:29.941401: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:27:30.000450: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:27:30.010800: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 - 13s - loss: 1.8262e-04 - val_loss: 3.0670e-05 - 13s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "657/657 - 10s - loss: 1.6937e-04 - val_loss: 4.0253e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 3/100\n",
      "657/657 - 10s - loss: 2.3307e-04 - val_loss: 4.6204e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 4/100\n",
      "657/657 - 10s - loss: 4.1608e-04 - val_loss: 6.9242e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 5/100\n",
      "657/657 - 10s - loss: 8.4385e-04 - val_loss: 2.1969e-04 - 10s/epoch - 16ms/step\n",
      "Epoch 6/100\n",
      "657/657 - 10s - loss: 0.0011 - val_loss: 2.8032e-04 - 10s/epoch - 16ms/step\n",
      "Epoch 7/100\n",
      "657/657 - 10s - loss: 7.2418e-04 - val_loss: 1.7209e-04 - 10s/epoch - 16ms/step\n",
      "Epoch 8/100\n",
      "657/657 - 10s - loss: 4.6839e-04 - val_loss: 6.7044e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 9/100\n",
      "657/657 - 10s - loss: 3.1450e-04 - val_loss: 2.4292e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 10/100\n",
      "657/657 - 10s - loss: 2.3757e-04 - val_loss: 1.2498e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 11/100\n",
      "657/657 - 10s - loss: 2.1008e-04 - val_loss: 9.6688e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 12/100\n",
      "657/657 - 10s - loss: 2.0882e-04 - val_loss: 9.5561e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 13/100\n",
      "657/657 - 10s - loss: 2.1722e-04 - val_loss: 1.0208e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "657/657 - 10s - loss: 2.2676e-04 - val_loss: 1.0260e-05 - 10s/epoch - 16ms/step\n",
      "Epoch 15/100\n",
      "657/657 - 10s - loss: 2.2666e-04 - val_loss: 8.9756e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "657/657 - 10s - loss: 2.0644e-04 - val_loss: 7.5934e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 17/100\n",
      "657/657 - 10s - loss: 1.9018e-04 - val_loss: 6.6726e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 18/100\n",
      "657/657 - 10s - loss: 1.7909e-04 - val_loss: 6.3078e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "657/657 - 10s - loss: 1.7310e-04 - val_loss: 6.0944e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 20/100\n",
      "657/657 - 10s - loss: 1.6800e-04 - val_loss: 5.9345e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 21/100\n",
      "657/657 - 10s - loss: 1.6354e-04 - val_loss: 5.7111e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 22/100\n",
      "657/657 - 10s - loss: 1.5769e-04 - val_loss: 5.3787e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 23/100\n",
      "657/657 - 10s - loss: 1.5096e-04 - val_loss: 5.1943e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 24/100\n",
      "657/657 - 10s - loss: 1.4552e-04 - val_loss: 5.0292e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 25/100\n",
      "657/657 - 10s - loss: 1.4194e-04 - val_loss: 4.9996e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 26/100\n",
      "657/657 - 11s - loss: 1.3873e-04 - val_loss: 4.8327e-06 - 11s/epoch - 16ms/step\n",
      "Epoch 27/100\n",
      "657/657 - 10s - loss: 1.3464e-04 - val_loss: 4.7210e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 28/100\n",
      "657/657 - 11s - loss: 1.3083e-04 - val_loss: 4.5910e-06 - 11s/epoch - 16ms/step\n",
      "Epoch 29/100\n",
      "657/657 - 11s - loss: 1.2749e-04 - val_loss: 4.5711e-06 - 11s/epoch - 16ms/step\n",
      "Epoch 30/100\n",
      "657/657 - 10s - loss: 1.2444e-04 - val_loss: 4.3932e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 31/100\n",
      "657/657 - 10s - loss: 1.2224e-04 - val_loss: 4.3929e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 32/100\n",
      "657/657 - 10s - loss: 1.1818e-04 - val_loss: 4.1269e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 33/100\n",
      "657/657 - 10s - loss: 1.1894e-04 - val_loss: 4.3537e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 34/100\n",
      "657/657 - 11s - loss: 1.1875e-04 - val_loss: 4.0191e-06 - 11s/epoch - 16ms/step\n",
      "Epoch 35/100\n",
      "657/657 - 11s - loss: 1.1211e-04 - val_loss: 3.9942e-06 - 11s/epoch - 16ms/step\n",
      "Epoch 36/100\n",
      "657/657 - 10s - loss: 1.0795e-04 - val_loss: 3.7476e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 37/100\n",
      "657/657 - 10s - loss: 1.0859e-04 - val_loss: 3.9724e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 38/100\n",
      "657/657 - 10s - loss: 1.0695e-04 - val_loss: 3.5639e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 39/100\n",
      "657/657 - 10s - loss: 1.0671e-04 - val_loss: 3.7846e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 40/100\n",
      "657/657 - 10s - loss: 1.0680e-04 - val_loss: 3.4235e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 41/100\n",
      "657/657 - 10s - loss: 1.0193e-04 - val_loss: 3.4661e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 42/100\n",
      "657/657 - 10s - loss: 9.5934e-05 - val_loss: 3.1705e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 43/100\n",
      "657/657 - 10s - loss: 1.0001e-04 - val_loss: 3.4449e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 44/100\n",
      "657/657 - 10s - loss: 1.0510e-04 - val_loss: 3.1504e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 45/100\n",
      "657/657 - 10s - loss: 9.5390e-05 - val_loss: 3.0274e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 46/100\n",
      "657/657 - 10s - loss: 9.5156e-05 - val_loss: 3.1096e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 47/100\n",
      "657/657 - 11s - loss: 8.9233e-05 - val_loss: 2.8670e-06 - 11s/epoch - 16ms/step\n",
      "Epoch 48/100\n",
      "657/657 - 11s - loss: 9.4386e-05 - val_loss: 3.1162e-06 - 11s/epoch - 16ms/step\n",
      "Epoch 49/100\n",
      "657/657 - 10s - loss: 1.0034e-04 - val_loss: 2.9423e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 50/100\n",
      "657/657 - 10s - loss: 8.9759e-05 - val_loss: 2.7605e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 51/100\n",
      "657/657 - 10s - loss: 8.9602e-05 - val_loss: 2.8918e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 52/100\n",
      "657/657 - 10s - loss: 8.8939e-05 - val_loss: 2.7441e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 53/100\n",
      "657/657 - 10s - loss: 8.8949e-05 - val_loss: 2.8451e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 54/100\n",
      "657/657 - 11s - loss: 8.6335e-05 - val_loss: 2.6661e-06 - 11s/epoch - 16ms/step\n",
      "Epoch 55/100\n",
      "657/657 - 10s - loss: 8.6967e-05 - val_loss: 2.7950e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 56/100\n",
      "657/657 - 11s - loss: 8.8949e-05 - val_loss: 2.6884e-06 - 11s/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "657/657 - 11s - loss: 8.4554e-05 - val_loss: 2.6583e-06 - 11s/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "657/657 - 10s - loss: 8.3249e-05 - val_loss: 2.6558e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 59/100\n",
      "657/657 - 10s - loss: 8.2700e-05 - val_loss: 2.6358e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 60/100\n",
      "657/657 - 10s - loss: 8.2538e-05 - val_loss: 2.6461e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 61/100\n",
      "657/657 - 10s - loss: 8.0054e-05 - val_loss: 2.5551e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 62/100\n",
      "657/657 - 10s - loss: 8.0414e-05 - val_loss: 2.6958e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 63/100\n",
      "657/657 - 10s - loss: 8.3777e-05 - val_loss: 2.5912e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 64/100\n",
      "657/657 - 10s - loss: 7.8592e-05 - val_loss: 2.5424e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 65/100\n",
      "657/657 - 10s - loss: 7.7237e-05 - val_loss: 2.6076e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 66/100\n",
      "657/657 - 10s - loss: 7.4573e-05 - val_loss: 2.5058e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 67/100\n",
      "657/657 - 11s - loss: 7.6581e-05 - val_loss: 2.6824e-06 - 11s/epoch - 16ms/step\n",
      "Epoch 68/100\n",
      "657/657 - 10s - loss: 8.0737e-05 - val_loss: 2.6008e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 69/100\n",
      "657/657 - 10s - loss: 7.4773e-05 - val_loss: 2.5086e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 70/100\n",
      "657/657 - 10s - loss: 7.4096e-05 - val_loss: 2.6310e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 71/100\n",
      "657/657 - 10s - loss: 7.5085e-05 - val_loss: 2.5621e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 72/100\n",
      "657/657 - 10s - loss: 7.3551e-05 - val_loss: 2.6194e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 73/100\n",
      "657/657 - 10s - loss: 7.1081e-05 - val_loss: 2.5453e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 74/100\n",
      "657/657 - 10s - loss: 7.2386e-05 - val_loss: 2.7383e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 75/100\n",
      "657/657 - 10s - loss: 7.5628e-05 - val_loss: 2.6371e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 76/100\n",
      "657/657 - 10s - loss: 7.0954e-05 - val_loss: 2.5636e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 77/100\n",
      "657/657 - 10s - loss: 7.0768e-05 - val_loss: 2.6889e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 78/100\n",
      "657/657 - 10s - loss: 7.1479e-05 - val_loss: 2.6139e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 79/100\n",
      "657/657 - 10s - loss: 7.0527e-05 - val_loss: 2.6874e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 80/100\n",
      "657/657 - 10s - loss: 6.9253e-05 - val_loss: 2.6207e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 81/100\n",
      "657/657 - 10s - loss: 6.9673e-05 - val_loss: 2.7753e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 82/100\n",
      "657/657 - 10s - loss: 7.1826e-05 - val_loss: 2.6651e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 83/100\n",
      "657/657 - 10s - loss: 6.8906e-05 - val_loss: 2.6437e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 84/100\n",
      "657/657 - 10s - loss: 6.8427e-05 - val_loss: 2.6969e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 85/100\n",
      "657/657 - 10s - loss: 6.6959e-05 - val_loss: 2.6785e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 86/100\n",
      "657/657 - 10s - loss: 6.8073e-05 - val_loss: 2.8558e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 87/100\n",
      "657/657 - 10s - loss: 7.0437e-05 - val_loss: 2.7287e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 88/100\n",
      "657/657 - 10s - loss: 6.7058e-05 - val_loss: 2.7002e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 89/100\n",
      "657/657 - 10s - loss: 6.6824e-05 - val_loss: 2.7757e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 90/100\n",
      "657/657 - 11s - loss: 6.6327e-05 - val_loss: 2.7460e-06 - 11s/epoch - 16ms/step\n",
      "Epoch 91/100\n",
      "657/657 - 10s - loss: 6.6537e-05 - val_loss: 2.8684e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 92/100\n",
      "657/657 - 10s - loss: 6.7786e-05 - val_loss: 2.7682e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 93/100\n",
      "657/657 - 10s - loss: 6.6060e-05 - val_loss: 2.7698e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 94/100\n",
      "657/657 - 10s - loss: 6.5124e-05 - val_loss: 2.7819e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 95/100\n",
      "657/657 - 10s - loss: 6.5266e-05 - val_loss: 2.8871e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 96/100\n",
      "657/657 - 10s - loss: 6.5984e-05 - val_loss: 2.8178e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "657/657 - 11s - loss: 6.4981e-05 - val_loss: 2.8732e-06 - 11s/epoch - 16ms/step\n",
      "Epoch 98/100\n",
      "657/657 - 10s - loss: 6.4698e-05 - val_loss: 2.8284e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 99/100\n",
      "657/657 - 10s - loss: 6.4231e-05 - val_loss: 2.9045e-06 - 10s/epoch - 16ms/step\n",
      "Epoch 100/100\n",
      "657/657 - 10s - loss: 6.4614e-05 - val_loss: 2.8487e-06 - 10s/epoch - 15ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 10:44:38.227372: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:44:38.397757: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:44:38.412682: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:44:38.568901: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:44:38.588489: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:44:43.881751: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:44:43.941251: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:44:43.952132: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 - 8s - loss: 5.5081e-04 - val_loss: 6.2668e-05 - 8s/epoch - 23ms/step\n",
      "Epoch 2/100\n",
      "329/329 - 5s - loss: 1.9719e-04 - val_loss: 1.1597e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 3/100\n",
      "329/329 - 5s - loss: 1.5082e-04 - val_loss: 7.2931e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 4/100\n",
      "329/329 - 5s - loss: 1.3832e-04 - val_loss: 7.1243e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 5/100\n",
      "329/329 - 5s - loss: 1.4385e-04 - val_loss: 7.5917e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 6/100\n",
      "329/329 - 5s - loss: 1.5380e-04 - val_loss: 8.0030e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 7/100\n",
      "329/329 - 5s - loss: 1.5892e-04 - val_loss: 8.0406e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 8/100\n",
      "329/329 - 5s - loss: 1.5577e-04 - val_loss: 7.8489e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 9/100\n",
      "329/329 - 5s - loss: 1.4842e-04 - val_loss: 7.6399e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 10/100\n",
      "329/329 - 5s - loss: 1.4114e-04 - val_loss: 7.5320e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 11/100\n",
      "329/329 - 5s - loss: 1.3578e-04 - val_loss: 7.5157e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 12/100\n",
      "329/329 - 5s - loss: 1.3238e-04 - val_loss: 7.5887e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 13/100\n",
      "329/329 - 5s - loss: 1.3017e-04 - val_loss: 7.6679e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "329/329 - 5s - loss: 1.2788e-04 - val_loss: 7.7545e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 15/100\n",
      "329/329 - 5s - loss: 1.2550e-04 - val_loss: 7.7477e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "329/329 - 5s - loss: 1.2247e-04 - val_loss: 7.7697e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 17/100\n",
      "329/329 - 5s - loss: 1.1977e-04 - val_loss: 7.6990e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 18/100\n",
      "329/329 - 5s - loss: 1.1665e-04 - val_loss: 7.5671e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "329/329 - 5s - loss: 1.1317e-04 - val_loss: 7.4340e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 20/100\n",
      "329/329 - 5s - loss: 1.0958e-04 - val_loss: 7.2463e-06 - 5s/epoch - 15ms/step\n",
      "Epoch 21/100\n",
      "329/329 - 5s - loss: 1.0664e-04 - val_loss: 7.1601e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 22/100\n",
      "329/329 - 5s - loss: 1.0401e-04 - val_loss: 7.0251e-06 - 5s/epoch - 15ms/step\n",
      "Epoch 23/100\n",
      "329/329 - 5s - loss: 1.0097e-04 - val_loss: 6.8670e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 24/100\n",
      "329/329 - 5s - loss: 9.8130e-05 - val_loss: 6.7119e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 25/100\n",
      "329/329 - 5s - loss: 9.5188e-05 - val_loss: 6.5894e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 26/100\n",
      "329/329 - 5s - loss: 9.2667e-05 - val_loss: 6.4551e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 27/100\n",
      "329/329 - 5s - loss: 8.9748e-05 - val_loss: 6.2686e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 28/100\n",
      "329/329 - 5s - loss: 8.6248e-05 - val_loss: 6.0243e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 29/100\n",
      "329/329 - 5s - loss: 8.2973e-05 - val_loss: 5.8195e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 30/100\n",
      "329/329 - 5s - loss: 8.0632e-05 - val_loss: 5.6159e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 31/100\n",
      "329/329 - 5s - loss: 7.8849e-05 - val_loss: 5.5217e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 32/100\n",
      "329/329 - 5s - loss: 7.7984e-05 - val_loss: 5.4594e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 33/100\n",
      "329/329 - 5s - loss: 7.6822e-05 - val_loss: 5.3840e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 34/100\n",
      "329/329 - 5s - loss: 7.4845e-05 - val_loss: 5.2429e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 35/100\n",
      "329/329 - 5s - loss: 7.2500e-05 - val_loss: 5.1248e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 36/100\n",
      "329/329 - 5s - loss: 7.0139e-05 - val_loss: 5.0041e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 37/100\n",
      "329/329 - 5s - loss: 6.8578e-05 - val_loss: 4.9230e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 38/100\n",
      "329/329 - 5s - loss: 6.7618e-05 - val_loss: 4.9150e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 39/100\n",
      "329/329 - 5s - loss: 6.7877e-05 - val_loss: 4.9096e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 40/100\n",
      "329/329 - 5s - loss: 6.5358e-05 - val_loss: 4.8125e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 41/100\n",
      "329/329 - 5s - loss: 6.6875e-05 - val_loss: 4.9457e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 42/100\n",
      "329/329 - 5s - loss: 6.8422e-05 - val_loss: 4.8064e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 43/100\n",
      "329/329 - 5s - loss: 6.6027e-05 - val_loss: 4.6193e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 44/100\n",
      "329/329 - 5s - loss: 6.2537e-05 - val_loss: 4.4754e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 45/100\n",
      "329/329 - 5s - loss: 6.1584e-05 - val_loss: 4.4494e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 46/100\n",
      "329/329 - 5s - loss: 5.9684e-05 - val_loss: 4.4489e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 47/100\n",
      "329/329 - 5s - loss: 6.1849e-05 - val_loss: 4.5439e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 48/100\n",
      "329/329 - 5s - loss: 6.1344e-05 - val_loss: 4.5239e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 49/100\n",
      "329/329 - 5s - loss: 6.2155e-05 - val_loss: 4.4799e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 50/100\n",
      "329/329 - 5s - loss: 5.9214e-05 - val_loss: 4.3927e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 51/100\n",
      "329/329 - 5s - loss: 5.9689e-05 - val_loss: 4.3025e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 52/100\n",
      "329/329 - 5s - loss: 5.6960e-05 - val_loss: 4.2847e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 53/100\n",
      "329/329 - 5s - loss: 5.8572e-05 - val_loss: 4.2633e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 54/100\n",
      "329/329 - 5s - loss: 5.6254e-05 - val_loss: 4.2653e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 55/100\n",
      "329/329 - 5s - loss: 5.7953e-05 - val_loss: 4.2333e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 56/100\n",
      "329/329 - 5s - loss: 5.5450e-05 - val_loss: 4.2359e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "329/329 - 5s - loss: 5.7176e-05 - val_loss: 4.1853e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 58/100\n",
      "329/329 - 5s - loss: 5.4337e-05 - val_loss: 4.1696e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 59/100\n",
      "329/329 - 5s - loss: 5.5792e-05 - val_loss: 4.1006e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 60/100\n",
      "329/329 - 5s - loss: 5.2846e-05 - val_loss: 4.0932e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 61/100\n",
      "329/329 - 5s - loss: 5.4857e-05 - val_loss: 4.0544e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 62/100\n",
      "329/329 - 5s - loss: 5.2285e-05 - val_loss: 4.0922e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 63/100\n",
      "329/329 - 5s - loss: 5.4682e-05 - val_loss: 4.0600e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 64/100\n",
      "329/329 - 5s - loss: 5.2148e-05 - val_loss: 4.1062e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 65/100\n",
      "329/329 - 5s - loss: 5.4389e-05 - val_loss: 4.0328e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 66/100\n",
      "329/329 - 5s - loss: 5.1363e-05 - val_loss: 4.0371e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 67/100\n",
      "329/329 - 5s - loss: 5.3066e-05 - val_loss: 3.9821e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 68/100\n",
      "329/329 - 5s - loss: 5.0100e-05 - val_loss: 3.9867e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 69/100\n",
      "329/329 - 5s - loss: 5.2084e-05 - val_loss: 3.9543e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 70/100\n",
      "329/329 - 5s - loss: 4.9497e-05 - val_loss: 3.9847e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 71/100\n",
      "329/329 - 5s - loss: 5.1921e-05 - val_loss: 3.9578e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 72/100\n",
      "329/329 - 5s - loss: 4.9431e-05 - val_loss: 3.9831e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 73/100\n",
      "329/329 - 5s - loss: 5.1500e-05 - val_loss: 3.9414e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 74/100\n",
      "329/329 - 5s - loss: 4.9067e-05 - val_loss: 3.9642e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 75/100\n",
      "329/329 - 5s - loss: 5.1018e-05 - val_loss: 3.9093e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 76/100\n",
      "329/329 - 5s - loss: 4.8177e-05 - val_loss: 3.8949e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 77/100\n",
      "329/329 - 5s - loss: 4.9805e-05 - val_loss: 3.8435e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 78/100\n",
      "329/329 - 5s - loss: 4.7460e-05 - val_loss: 3.8546e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 79/100\n",
      "329/329 - 5s - loss: 4.9225e-05 - val_loss: 3.8418e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 80/100\n",
      "329/329 - 5s - loss: 4.7321e-05 - val_loss: 3.8713e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 81/100\n",
      "329/329 - 5s - loss: 4.9301e-05 - val_loss: 3.8543e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 82/100\n",
      "329/329 - 5s - loss: 4.7209e-05 - val_loss: 3.8531e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 83/100\n",
      "329/329 - 5s - loss: 4.8600e-05 - val_loss: 3.8074e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 84/100\n",
      "329/329 - 5s - loss: 4.6375e-05 - val_loss: 3.7939e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 85/100\n",
      "329/329 - 5s - loss: 4.7828e-05 - val_loss: 3.7544e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 86/100\n",
      "329/329 - 5s - loss: 4.6038e-05 - val_loss: 3.7604e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 87/100\n",
      "329/329 - 5s - loss: 4.7568e-05 - val_loss: 3.7786e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 88/100\n",
      "329/329 - 5s - loss: 4.6189e-05 - val_loss: 3.7632e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 89/100\n",
      "329/329 - 5s - loss: 4.7264e-05 - val_loss: 3.7188e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 90/100\n",
      "329/329 - 5s - loss: 4.5384e-05 - val_loss: 3.6981e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 91/100\n",
      "329/329 - 5s - loss: 4.6492e-05 - val_loss: 3.6778e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 92/100\n",
      "329/329 - 5s - loss: 4.5134e-05 - val_loss: 3.6851e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 93/100\n",
      "329/329 - 5s - loss: 4.6306e-05 - val_loss: 3.6747e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 94/100\n",
      "329/329 - 5s - loss: 4.5142e-05 - val_loss: 3.6917e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 95/100\n",
      "329/329 - 5s - loss: 4.6229e-05 - val_loss: 3.6864e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 96/100\n",
      "329/329 - 5s - loss: 4.5074e-05 - val_loss: 3.6779e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "329/329 - 5s - loss: 4.5550e-05 - val_loss: 3.6441e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 98/100\n",
      "329/329 - 5s - loss: 4.4234e-05 - val_loss: 3.6341e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 99/100\n",
      "329/329 - 5s - loss: 4.4880e-05 - val_loss: 3.6295e-06 - 5s/epoch - 15ms/step\n",
      "Epoch 100/100\n",
      "329/329 - 5s - loss: 4.4269e-05 - val_loss: 3.6555e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 10:53:21.221748: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:53:21.394192: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:53:21.409114: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:53:21.589823: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:53:21.610823: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:53:26.939018: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:53:27.000775: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 10:53:27.011508: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 - 8s - loss: 5.9197e-04 - val_loss: 1.6848e-04 - 8s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "329/329 - 5s - loss: 3.8526e-04 - val_loss: 3.9050e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 3/100\n",
      "329/329 - 5s - loss: 1.9440e-04 - val_loss: 9.5092e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 4/100\n",
      "329/329 - 5s - loss: 1.3998e-04 - val_loss: 6.5005e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 5/100\n",
      "329/329 - 6s - loss: 1.2487e-04 - val_loss: 6.5049e-06 - 6s/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "329/329 - 5s - loss: 1.3000e-04 - val_loss: 7.2545e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 7/100\n",
      "329/329 - 5s - loss: 1.4271e-04 - val_loss: 8.1165e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 8/100\n",
      "329/329 - 5s - loss: 1.5310e-04 - val_loss: 8.4806e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 9/100\n",
      "329/329 - 5s - loss: 1.5359e-04 - val_loss: 8.3217e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 10/100\n",
      "329/329 - 5s - loss: 1.4616e-04 - val_loss: 8.0152e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 11/100\n",
      "329/329 - 5s - loss: 1.3716e-04 - val_loss: 7.8290e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 12/100\n",
      "329/329 - 5s - loss: 1.3068e-04 - val_loss: 7.8330e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 13/100\n",
      "329/329 - 5s - loss: 1.2721e-04 - val_loss: 7.9887e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "329/329 - 5s - loss: 1.2566e-04 - val_loss: 8.2327e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 15/100\n",
      "329/329 - 5s - loss: 1.2386e-04 - val_loss: 8.4339e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "329/329 - 5s - loss: 1.2080e-04 - val_loss: 8.4948e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 17/100\n",
      "329/329 - 5s - loss: 1.1772e-04 - val_loss: 8.5311e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 18/100\n",
      "329/329 - 5s - loss: 1.1551e-04 - val_loss: 8.6097e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "329/329 - 5s - loss: 1.1274e-04 - val_loss: 8.5949e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 20/100\n",
      "329/329 - 5s - loss: 1.0971e-04 - val_loss: 8.5296e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 21/100\n",
      "329/329 - 5s - loss: 1.0675e-04 - val_loss: 8.4406e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 22/100\n",
      "329/329 - 5s - loss: 1.0341e-04 - val_loss: 8.2896e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 23/100\n",
      "329/329 - 5s - loss: 1.0043e-04 - val_loss: 8.1038e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 24/100\n",
      "329/329 - 5s - loss: 9.7447e-05 - val_loss: 7.8582e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 25/100\n",
      "329/329 - 5s - loss: 9.5166e-05 - val_loss: 7.6829e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 26/100\n",
      "329/329 - 5s - loss: 9.2749e-05 - val_loss: 7.5372e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 27/100\n",
      "329/329 - 5s - loss: 8.9764e-05 - val_loss: 7.3319e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 28/100\n",
      "329/329 - 5s - loss: 8.6195e-05 - val_loss: 7.1441e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 29/100\n",
      "329/329 - 5s - loss: 8.3963e-05 - val_loss: 7.0183e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 30/100\n",
      "329/329 - 5s - loss: 8.2213e-05 - val_loss: 6.8281e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 31/100\n",
      "329/329 - 5s - loss: 8.1374e-05 - val_loss: 6.7873e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 32/100\n",
      "329/329 - 5s - loss: 7.9858e-05 - val_loss: 6.5967e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 33/100\n",
      "329/329 - 5s - loss: 8.0071e-05 - val_loss: 6.7136e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 34/100\n",
      "329/329 - 5s - loss: 7.6057e-05 - val_loss: 6.2503e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 35/100\n",
      "329/329 - 5s - loss: 7.9658e-05 - val_loss: 6.6707e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 36/100\n",
      "329/329 - 5s - loss: 7.9030e-05 - val_loss: 6.1425e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 37/100\n",
      "329/329 - 5s - loss: 7.4966e-05 - val_loss: 6.0692e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 38/100\n",
      "329/329 - 5s - loss: 6.8581e-05 - val_loss: 5.6174e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 39/100\n",
      "329/329 - 5s - loss: 7.2001e-05 - val_loss: 6.1164e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 40/100\n",
      "329/329 - 6s - loss: 7.1811e-05 - val_loss: 5.6003e-06 - 6s/epoch - 17ms/step\n",
      "Epoch 41/100\n",
      "329/329 - 5s - loss: 7.0329e-05 - val_loss: 5.6842e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 42/100\n",
      "329/329 - 5s - loss: 6.4952e-05 - val_loss: 5.2490e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 43/100\n",
      "329/329 - 5s - loss: 6.9131e-05 - val_loss: 5.7084e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 44/100\n",
      "329/329 - 5s - loss: 7.0461e-05 - val_loss: 5.3418e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 45/100\n",
      "329/329 - 5s - loss: 6.4473e-05 - val_loss: 5.0315e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 46/100\n",
      "329/329 - 5s - loss: 6.4659e-05 - val_loss: 5.1211e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 47/100\n",
      "329/329 - 5s - loss: 6.0541e-05 - val_loss: 4.8078e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 48/100\n",
      "329/329 - 5s - loss: 6.5339e-05 - val_loss: 5.1900e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 49/100\n",
      "329/329 - 5s - loss: 6.6854e-05 - val_loss: 4.9300e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 50/100\n",
      "329/329 - 5s - loss: 6.1514e-05 - val_loss: 4.6851e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 51/100\n",
      "329/329 - 5s - loss: 6.1927e-05 - val_loss: 4.7521e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 52/100\n",
      "329/329 - 5s - loss: 5.8057e-05 - val_loss: 4.4914e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 53/100\n",
      "329/329 - 5s - loss: 6.1443e-05 - val_loss: 4.6680e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 54/100\n",
      "329/329 - 5s - loss: 6.1088e-05 - val_loss: 4.5012e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 55/100\n",
      "329/329 - 5s - loss: 5.9176e-05 - val_loss: 4.4147e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 56/100\n",
      "329/329 - 5s - loss: 5.8514e-05 - val_loss: 4.3621e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "329/329 - 5s - loss: 5.7907e-05 - val_loss: 4.3095e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 58/100\n",
      "329/329 - 5s - loss: 5.8023e-05 - val_loss: 4.2847e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 59/100\n",
      "329/329 - 5s - loss: 5.6931e-05 - val_loss: 4.2034e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 60/100\n",
      "329/329 - 5s - loss: 5.8378e-05 - val_loss: 4.2901e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 61/100\n",
      "329/329 - 5s - loss: 5.4995e-05 - val_loss: 4.0888e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 62/100\n",
      "329/329 - 5s - loss: 5.8885e-05 - val_loss: 4.2730e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 63/100\n",
      "329/329 - 5s - loss: 5.9036e-05 - val_loss: 4.0581e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 64/100\n",
      "329/329 - 5s - loss: 5.4922e-05 - val_loss: 3.8792e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 65/100\n",
      "329/329 - 5s - loss: 5.4180e-05 - val_loss: 3.8197e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 66/100\n",
      "329/329 - 5s - loss: 5.2478e-05 - val_loss: 3.7690e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 67/100\n",
      "329/329 - 5s - loss: 5.4140e-05 - val_loss: 3.8281e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 68/100\n",
      "329/329 - 5s - loss: 5.2922e-05 - val_loss: 3.8043e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 69/100\n",
      "329/329 - 5s - loss: 5.5522e-05 - val_loss: 3.8762e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 70/100\n",
      "329/329 - 5s - loss: 5.3791e-05 - val_loss: 3.8019e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 71/100\n",
      "329/329 - 5s - loss: 5.4812e-05 - val_loss: 3.7953e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 72/100\n",
      "329/329 - 5s - loss: 5.2174e-05 - val_loss: 3.6904e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 73/100\n",
      "329/329 - 5s - loss: 5.3097e-05 - val_loss: 3.7064e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 74/100\n",
      "329/329 - 5s - loss: 5.1142e-05 - val_loss: 3.6442e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 75/100\n",
      "329/329 - 5s - loss: 5.2481e-05 - val_loss: 3.6759e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 76/100\n",
      "329/329 - 5s - loss: 5.1011e-05 - val_loss: 3.6419e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 77/100\n",
      "329/329 - 5s - loss: 5.2350e-05 - val_loss: 3.6681e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 78/100\n",
      "329/329 - 5s - loss: 5.0789e-05 - val_loss: 3.6208e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 79/100\n",
      "329/329 - 5s - loss: 5.1868e-05 - val_loss: 3.6326e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 80/100\n",
      "329/329 - 5s - loss: 5.0214e-05 - val_loss: 3.5989e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 81/100\n",
      "329/329 - 5s - loss: 5.1097e-05 - val_loss: 3.6068e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 82/100\n",
      "329/329 - 5s - loss: 4.9467e-05 - val_loss: 3.5779e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 83/100\n",
      "329/329 - 5s - loss: 5.0476e-05 - val_loss: 3.5965e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 84/100\n",
      "329/329 - 5s - loss: 4.9097e-05 - val_loss: 3.5713e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 85/100\n",
      "329/329 - 5s - loss: 5.0066e-05 - val_loss: 3.5865e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 86/100\n",
      "329/329 - 5s - loss: 4.8719e-05 - val_loss: 3.5552e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 87/100\n",
      "329/329 - 5s - loss: 4.9671e-05 - val_loss: 3.5618e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 88/100\n",
      "329/329 - 5s - loss: 4.8424e-05 - val_loss: 3.5519e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 89/100\n",
      "329/329 - 5s - loss: 4.9315e-05 - val_loss: 3.5617e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 90/100\n",
      "329/329 - 5s - loss: 4.8074e-05 - val_loss: 3.5533e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 91/100\n",
      "329/329 - 5s - loss: 4.8931e-05 - val_loss: 3.5653e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 92/100\n",
      "329/329 - 5s - loss: 4.7672e-05 - val_loss: 3.5550e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 93/100\n",
      "329/329 - 5s - loss: 4.8507e-05 - val_loss: 3.5604e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 94/100\n",
      "329/329 - 5s - loss: 4.7177e-05 - val_loss: 3.5416e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 95/100\n",
      "329/329 - 5s - loss: 4.8071e-05 - val_loss: 3.5601e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 96/100\n",
      "329/329 - 5s - loss: 4.6828e-05 - val_loss: 3.5572e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "329/329 - 5s - loss: 4.7853e-05 - val_loss: 3.5713e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 98/100\n",
      "329/329 - 5s - loss: 4.6545e-05 - val_loss: 3.5648e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 99/100\n",
      "329/329 - 5s - loss: 4.7561e-05 - val_loss: 3.5726e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 100/100\n",
      "329/329 - 5s - loss: 4.6169e-05 - val_loss: 3.5659e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:02:07.957228: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:02:08.133389: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:02:08.147916: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:02:08.441559: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:02:08.461438: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:02:14.090092: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:02:14.151270: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:02:14.162512: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 - 8s - loss: 4.1793e-04 - val_loss: 8.7205e-05 - 8s/epoch - 25ms/step\n",
      "Epoch 2/100\n",
      "329/329 - 6s - loss: 5.5282e-04 - val_loss: 1.0143e-04 - 6s/epoch - 17ms/step\n",
      "Epoch 3/100\n",
      "329/329 - 6s - loss: 3.6207e-04 - val_loss: 4.5228e-05 - 6s/epoch - 17ms/step\n",
      "Epoch 4/100\n",
      "329/329 - 5s - loss: 2.2638e-04 - val_loss: 1.5235e-05 - 5s/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "329/329 - 5s - loss: 1.6889e-04 - val_loss: 9.1892e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 6/100\n",
      "329/329 - 5s - loss: 1.5125e-04 - val_loss: 8.5066e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "329/329 - 5s - loss: 1.5374e-04 - val_loss: 9.1271e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 8/100\n",
      "329/329 - 5s - loss: 1.6288e-04 - val_loss: 9.7569e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 9/100\n",
      "329/329 - 5s - loss: 1.7130e-04 - val_loss: 1.0208e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 10/100\n",
      "329/329 - 5s - loss: 1.7414e-04 - val_loss: 1.0480e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 11/100\n",
      "329/329 - 5s - loss: 1.7082e-04 - val_loss: 1.0254e-05 - 5s/epoch - 16ms/step\n",
      "Epoch 12/100\n",
      "329/329 - 5s - loss: 1.5940e-04 - val_loss: 9.6710e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 13/100\n",
      "329/329 - 5s - loss: 1.4728e-04 - val_loss: 9.1149e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "329/329 - 5s - loss: 1.3996e-04 - val_loss: 8.8292e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 15/100\n",
      "329/329 - 5s - loss: 1.3609e-04 - val_loss: 8.7858e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 16/100\n",
      "329/329 - 5s - loss: 1.3326e-04 - val_loss: 8.7805e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "329/329 - 5s - loss: 1.2977e-04 - val_loss: 8.6678e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 18/100\n",
      "329/329 - 5s - loss: 1.2800e-04 - val_loss: 8.7877e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 19/100\n",
      "329/329 - 6s - loss: 1.2601e-04 - val_loss: 8.7694e-06 - 6s/epoch - 17ms/step\n",
      "Epoch 20/100\n",
      "329/329 - 5s - loss: 1.2296e-04 - val_loss: 8.6225e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 21/100\n",
      "329/329 - 5s - loss: 1.1817e-04 - val_loss: 8.4084e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 22/100\n",
      "329/329 - 5s - loss: 1.1365e-04 - val_loss: 8.1632e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 23/100\n",
      "329/329 - 5s - loss: 1.0876e-04 - val_loss: 7.7365e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 24/100\n",
      "329/329 - 5s - loss: 1.0500e-04 - val_loss: 7.5161e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 25/100\n",
      "329/329 - 5s - loss: 1.0280e-04 - val_loss: 7.3136e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 26/100\n",
      "329/329 - 6s - loss: 1.0062e-04 - val_loss: 7.2228e-06 - 6s/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "329/329 - 6s - loss: 9.9285e-05 - val_loss: 7.2125e-06 - 6s/epoch - 17ms/step\n",
      "Epoch 28/100\n",
      "329/329 - 5s - loss: 9.6562e-05 - val_loss: 6.8283e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 29/100\n",
      "329/329 - 5s - loss: 9.3452e-05 - val_loss: 6.6822e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 30/100\n",
      "329/329 - 5s - loss: 9.0504e-05 - val_loss: 6.3800e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 31/100\n",
      "329/329 - 5s - loss: 8.9067e-05 - val_loss: 6.3555e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 32/100\n",
      "329/329 - 5s - loss: 8.5389e-05 - val_loss: 5.9311e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 33/100\n",
      "329/329 - 5s - loss: 8.6588e-05 - val_loss: 6.3635e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 34/100\n",
      "329/329 - 5s - loss: 8.7727e-05 - val_loss: 5.9506e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 35/100\n",
      "329/329 - 5s - loss: 8.2826e-05 - val_loss: 5.7081e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 36/100\n",
      "329/329 - 5s - loss: 7.9698e-05 - val_loss: 5.6733e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 37/100\n",
      "329/329 - 5s - loss: 7.4629e-05 - val_loss: 5.2405e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 38/100\n",
      "329/329 - 5s - loss: 7.6864e-05 - val_loss: 5.8578e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 39/100\n",
      "329/329 - 5s - loss: 8.2003e-05 - val_loss: 5.4861e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 40/100\n",
      "329/329 - 5s - loss: 7.6596e-05 - val_loss: 5.1352e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 41/100\n",
      "329/329 - 5s - loss: 7.3809e-05 - val_loss: 5.2037e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 42/100\n",
      "329/329 - 5s - loss: 6.9794e-05 - val_loss: 4.7844e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 43/100\n",
      "329/329 - 5s - loss: 6.9872e-05 - val_loss: 5.0432e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 44/100\n",
      "329/329 - 5s - loss: 7.0603e-05 - val_loss: 4.7097e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 45/100\n",
      "329/329 - 5s - loss: 6.7715e-05 - val_loss: 4.6468e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 46/100\n",
      "329/329 - 5s - loss: 6.7104e-05 - val_loss: 4.5018e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "329/329 - 5s - loss: 6.3959e-05 - val_loss: 4.4190e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 48/100\n",
      "329/329 - 5s - loss: 6.7092e-05 - val_loss: 4.7105e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 49/100\n",
      "329/329 - 5s - loss: 7.0106e-05 - val_loss: 4.5790e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 50/100\n",
      "329/329 - 5s - loss: 6.7476e-05 - val_loss: 4.4051e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 51/100\n",
      "329/329 - 5s - loss: 6.4888e-05 - val_loss: 4.2694e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 52/100\n",
      "329/329 - 5s - loss: 6.1305e-05 - val_loss: 4.0674e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 53/100\n",
      "329/329 - 5s - loss: 6.2549e-05 - val_loss: 4.2262e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 54/100\n",
      "329/329 - 6s - loss: 6.2909e-05 - val_loss: 4.0557e-06 - 6s/epoch - 17ms/step\n",
      "Epoch 55/100\n",
      "329/329 - 6s - loss: 6.1841e-05 - val_loss: 4.0738e-06 - 6s/epoch - 17ms/step\n",
      "Epoch 56/100\n",
      "329/329 - 5s - loss: 6.0054e-05 - val_loss: 3.9417e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 57/100\n",
      "329/329 - 5s - loss: 6.1142e-05 - val_loss: 4.0918e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 58/100\n",
      "329/329 - 6s - loss: 6.0669e-05 - val_loss: 3.9195e-06 - 6s/epoch - 17ms/step\n",
      "Epoch 59/100\n",
      "329/329 - 6s - loss: 6.0135e-05 - val_loss: 3.9628e-06 - 6s/epoch - 17ms/step\n",
      "Epoch 60/100\n",
      "329/329 - 6s - loss: 5.8179e-05 - val_loss: 3.8140e-06 - 6s/epoch - 17ms/step\n",
      "Epoch 61/100\n",
      "329/329 - 5s - loss: 5.9039e-05 - val_loss: 3.9001e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 62/100\n",
      "329/329 - 5s - loss: 5.8248e-05 - val_loss: 3.7489e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 63/100\n",
      "329/329 - 5s - loss: 5.7815e-05 - val_loss: 3.7614e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 64/100\n",
      "329/329 - 5s - loss: 5.6340e-05 - val_loss: 3.6733e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 65/100\n",
      "329/329 - 5s - loss: 5.7273e-05 - val_loss: 3.7456e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 66/100\n",
      "329/329 - 6s - loss: 5.6323e-05 - val_loss: 3.6556e-06 - 6s/epoch - 17ms/step\n",
      "Epoch 67/100\n",
      "329/329 - 5s - loss: 5.6910e-05 - val_loss: 3.6974e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 68/100\n",
      "329/329 - 5s - loss: 5.5507e-05 - val_loss: 3.6031e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 69/100\n",
      "329/329 - 5s - loss: 5.5792e-05 - val_loss: 3.5946e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 70/100\n",
      "329/329 - 5s - loss: 5.4105e-05 - val_loss: 3.5261e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 71/100\n",
      "329/329 - 5s - loss: 5.4699e-05 - val_loss: 3.5470e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 72/100\n",
      "329/329 - 5s - loss: 5.3560e-05 - val_loss: 3.5014e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 73/100\n",
      "329/329 - 5s - loss: 5.4445e-05 - val_loss: 3.5272e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 74/100\n",
      "329/329 - 6s - loss: 5.3355e-05 - val_loss: 3.4682e-06 - 6s/epoch - 17ms/step\n",
      "Epoch 75/100\n",
      "329/329 - 5s - loss: 5.3958e-05 - val_loss: 3.4689e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 76/100\n",
      "329/329 - 5s - loss: 5.2557e-05 - val_loss: 3.4127e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 77/100\n",
      "329/329 - 5s - loss: 5.3161e-05 - val_loss: 3.4246e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 78/100\n",
      "329/329 - 5s - loss: 5.1900e-05 - val_loss: 3.3803e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 79/100\n",
      "329/329 - 5s - loss: 5.2527e-05 - val_loss: 3.3880e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 80/100\n",
      "329/329 - 5s - loss: 5.1346e-05 - val_loss: 3.3501e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 81/100\n",
      "329/329 - 5s - loss: 5.2007e-05 - val_loss: 3.3547e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 82/100\n",
      "329/329 - 5s - loss: 5.0898e-05 - val_loss: 3.3162e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 83/100\n",
      "329/329 - 5s - loss: 5.1555e-05 - val_loss: 3.3326e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 84/100\n",
      "329/329 - 5s - loss: 5.0537e-05 - val_loss: 3.3027e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 85/100\n",
      "329/329 - 5s - loss: 5.1130e-05 - val_loss: 3.3050e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 86/100\n",
      "329/329 - 5s - loss: 5.0036e-05 - val_loss: 3.2764e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 87/100\n",
      "329/329 - 6s - loss: 5.0586e-05 - val_loss: 3.2804e-06 - 6s/epoch - 17ms/step\n",
      "Epoch 88/100\n",
      "329/329 - 6s - loss: 4.9569e-05 - val_loss: 3.2511e-06 - 6s/epoch - 17ms/step\n",
      "Epoch 89/100\n",
      "329/329 - 5s - loss: 5.0078e-05 - val_loss: 3.2454e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 90/100\n",
      "329/329 - 6s - loss: 4.9005e-05 - val_loss: 3.2216e-06 - 6s/epoch - 17ms/step\n",
      "Epoch 91/100\n",
      "329/329 - 5s - loss: 4.9520e-05 - val_loss: 3.2241e-06 - 5s/epoch - 17ms/step\n",
      "Epoch 92/100\n",
      "329/329 - 5s - loss: 4.8641e-05 - val_loss: 3.2046e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 93/100\n",
      "329/329 - 5s - loss: 4.9219e-05 - val_loss: 3.2000e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 94/100\n",
      "329/329 - 5s - loss: 4.8406e-05 - val_loss: 3.1943e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 95/100\n",
      "329/329 - 5s - loss: 4.9136e-05 - val_loss: 3.2052e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 96/100\n",
      "329/329 - 5s - loss: 4.8355e-05 - val_loss: 3.1741e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "329/329 - 5s - loss: 4.8627e-05 - val_loss: 3.1694e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 98/100\n",
      "329/329 - 5s - loss: 4.7682e-05 - val_loss: 3.1575e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 99/100\n",
      "329/329 - 5s - loss: 4.8176e-05 - val_loss: 3.1625e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 100/100\n",
      "329/329 - 5s - loss: 4.7421e-05 - val_loss: 3.1565e-06 - 5s/epoch - 16ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:11:15.285684: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:11:15.478364: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:11:15.494462: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:11:15.772523: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:11:15.792751: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:11:19.028469: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:11:19.090370: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:11:19.101455: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 - 6s - loss: 9.7019e-04 - val_loss: 7.2386e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 2/100\n",
      "165/165 - 3s - loss: 5.2722e-04 - val_loss: 2.8726e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 3/100\n",
      "165/165 - 3s - loss: 3.0349e-04 - val_loss: 1.2526e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 4/100\n",
      "165/165 - 3s - loss: 1.8430e-04 - val_loss: 6.5168e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "165/165 - 3s - loss: 1.3850e-04 - val_loss: 4.0316e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "165/165 - 3s - loss: 1.3018e-04 - val_loss: 3.8357e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "165/165 - 3s - loss: 1.4264e-04 - val_loss: 5.1021e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "165/165 - 3s - loss: 1.7098e-04 - val_loss: 7.7040e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 9/100\n",
      "165/165 - 3s - loss: 2.1341e-04 - val_loss: 1.2181e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 10/100\n",
      "165/165 - 3s - loss: 2.7278e-04 - val_loss: 2.1282e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 11/100\n",
      "165/165 - 3s - loss: 3.1986e-04 - val_loss: 3.0954e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 12/100\n",
      "165/165 - 3s - loss: 3.7648e-04 - val_loss: 4.0392e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 13/100\n",
      "165/165 - 3s - loss: 3.1319e-04 - val_loss: 2.4846e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "165/165 - 3s - loss: 2.1015e-04 - val_loss: 1.3416e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 15/100\n",
      "165/165 - 3s - loss: 1.4694e-04 - val_loss: 8.6995e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "165/165 - 3s - loss: 1.1716e-04 - val_loss: 6.6714e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 17/100\n",
      "165/165 - 3s - loss: 1.0729e-04 - val_loss: 6.1389e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 18/100\n",
      "165/165 - 3s - loss: 1.0864e-04 - val_loss: 6.5839e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 19/100\n",
      "165/165 - 3s - loss: 1.1786e-04 - val_loss: 7.8408e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 20/100\n",
      "165/165 - 3s - loss: 1.3401e-04 - val_loss: 1.0014e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 21/100\n",
      "165/165 - 3s - loss: 1.5649e-04 - val_loss: 1.3439e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 22/100\n",
      "165/165 - 3s - loss: 1.8292e-04 - val_loss: 1.8335e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 23/100\n",
      "165/165 - 3s - loss: 2.0860e-04 - val_loss: 2.3428e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 24/100\n",
      "165/165 - 3s - loss: 2.2695e-04 - val_loss: 2.5331e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 25/100\n",
      "165/165 - 3s - loss: 2.6975e-04 - val_loss: 3.2417e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 26/100\n",
      "165/165 - 3s - loss: 2.9439e-04 - val_loss: 3.7339e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 27/100\n",
      "165/165 - 3s - loss: 2.3643e-04 - val_loss: 2.5043e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 28/100\n",
      "165/165 - 3s - loss: 1.6723e-04 - val_loss: 1.5374e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 29/100\n",
      "165/165 - 3s - loss: 1.2228e-04 - val_loss: 1.0941e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 30/100\n",
      "165/165 - 3s - loss: 1.0140e-04 - val_loss: 8.9388e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 31/100\n",
      "165/165 - 3s - loss: 9.4108e-05 - val_loss: 8.1941e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 32/100\n",
      "165/165 - 3s - loss: 9.4551e-05 - val_loss: 8.2724e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 33/100\n",
      "165/165 - 3s - loss: 1.0027e-04 - val_loss: 8.9981e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 34/100\n",
      "165/165 - 3s - loss: 1.1041e-04 - val_loss: 1.0368e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 35/100\n",
      "165/165 - 3s - loss: 1.2444e-04 - val_loss: 1.2498e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 36/100\n",
      "165/165 - 3s - loss: 1.4108e-04 - val_loss: 1.5369e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 37/100\n",
      "165/165 - 3s - loss: 1.5688e-04 - val_loss: 1.7666e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 38/100\n",
      "165/165 - 3s - loss: 1.7996e-04 - val_loss: 1.8381e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 39/100\n",
      "165/165 - 3s - loss: 1.9651e-04 - val_loss: 2.3530e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 40/100\n",
      "165/165 - 3s - loss: 2.1208e-04 - val_loss: 2.8537e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 41/100\n",
      "165/165 - 3s - loss: 1.8906e-04 - val_loss: 2.2681e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 42/100\n",
      "165/165 - 3s - loss: 1.4453e-04 - val_loss: 1.4211e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 43/100\n",
      "165/165 - 3s - loss: 1.0779e-04 - val_loss: 9.9914e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 44/100\n",
      "165/165 - 3s - loss: 8.9015e-05 - val_loss: 7.8696e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 45/100\n",
      "165/165 - 3s - loss: 8.1674e-05 - val_loss: 6.9466e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 46/100\n",
      "165/165 - 3s - loss: 8.1071e-05 - val_loss: 6.8079e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 47/100\n",
      "165/165 - 3s - loss: 8.5053e-05 - val_loss: 7.2608e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 48/100\n",
      "165/165 - 3s - loss: 9.2644e-05 - val_loss: 8.2329e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 49/100\n",
      "165/165 - 3s - loss: 1.0300e-04 - val_loss: 9.6998e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 50/100\n",
      "165/165 - 3s - loss: 1.1473e-04 - val_loss: 1.1599e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 51/100\n",
      "165/165 - 3s - loss: 1.2534e-04 - val_loss: 1.2885e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 52/100\n",
      "165/165 - 3s - loss: 1.2502e-04 - val_loss: 1.1177e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 53/100\n",
      "165/165 - 3s - loss: 1.2981e-04 - val_loss: 1.2318e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 54/100\n",
      "165/165 - 3s - loss: 1.2714e-04 - val_loss: 1.3379e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 55/100\n",
      "165/165 - 3s - loss: 1.2081e-04 - val_loss: 1.2762e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 56/100\n",
      "165/165 - 3s - loss: 1.1109e-04 - val_loss: 1.1723e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 57/100\n",
      "165/165 - 3s - loss: 9.9819e-05 - val_loss: 9.8186e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "165/165 - 3s - loss: 9.0318e-05 - val_loss: 8.3530e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 59/100\n",
      "165/165 - 3s - loss: 8.4801e-05 - val_loss: 7.4714e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 60/100\n",
      "165/165 - 3s - loss: 8.2582e-05 - val_loss: 7.0448e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 61/100\n",
      "165/165 - 3s - loss: 8.3402e-05 - val_loss: 7.0478e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 62/100\n",
      "165/165 - 3s - loss: 8.6127e-05 - val_loss: 7.3283e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 63/100\n",
      "165/165 - 3s - loss: 9.0036e-05 - val_loss: 7.7815e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 64/100\n",
      "165/165 - 3s - loss: 9.3514e-05 - val_loss: 8.2451e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 65/100\n",
      "165/165 - 3s - loss: 9.4612e-05 - val_loss: 7.6031e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 66/100\n",
      "165/165 - 3s - loss: 9.4281e-05 - val_loss: 7.4606e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 67/100\n",
      "165/165 - 3s - loss: 9.1809e-05 - val_loss: 7.8480e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 68/100\n",
      "165/165 - 3s - loss: 9.1035e-05 - val_loss: 7.8092e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 69/100\n",
      "165/165 - 3s - loss: 8.8544e-05 - val_loss: 7.4782e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 70/100\n",
      "165/165 - 3s - loss: 8.8837e-05 - val_loss: 7.6855e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 71/100\n",
      "165/165 - 3s - loss: 8.7364e-05 - val_loss: 7.4985e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 72/100\n",
      "165/165 - 3s - loss: 8.4968e-05 - val_loss: 7.2295e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 73/100\n",
      "165/165 - 3s - loss: 8.4530e-05 - val_loss: 7.1176e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 74/100\n",
      "165/165 - 3s - loss: 8.1761e-05 - val_loss: 6.6934e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 75/100\n",
      "165/165 - 3s - loss: 7.9403e-05 - val_loss: 6.3678e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 76/100\n",
      "165/165 - 3s - loss: 7.7307e-05 - val_loss: 6.1115e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 77/100\n",
      "165/165 - 3s - loss: 7.7036e-05 - val_loss: 5.9925e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 78/100\n",
      "165/165 - 3s - loss: 7.7393e-05 - val_loss: 5.9810e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 79/100\n",
      "165/165 - 3s - loss: 7.8787e-05 - val_loss: 6.1984e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 80/100\n",
      "165/165 - 3s - loss: 7.8302e-05 - val_loss: 5.8860e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 81/100\n",
      "165/165 - 3s - loss: 7.7698e-05 - val_loss: 5.7307e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 82/100\n",
      "165/165 - 3s - loss: 7.5152e-05 - val_loss: 5.4475e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 83/100\n",
      "165/165 - 3s - loss: 7.5642e-05 - val_loss: 5.7166e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 84/100\n",
      "165/165 - 3s - loss: 7.4799e-05 - val_loss: 5.7258e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 85/100\n",
      "165/165 - 3s - loss: 7.4600e-05 - val_loss: 5.5300e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 86/100\n",
      "165/165 - 3s - loss: 7.3964e-05 - val_loss: 5.5445e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 87/100\n",
      "165/165 - 3s - loss: 7.4302e-05 - val_loss: 5.5160e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 88/100\n",
      "165/165 - 3s - loss: 7.3435e-05 - val_loss: 5.4602e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 89/100\n",
      "165/165 - 3s - loss: 7.2090e-05 - val_loss: 5.0799e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 90/100\n",
      "165/165 - 3s - loss: 7.0286e-05 - val_loss: 5.1034e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 91/100\n",
      "165/165 - 3s - loss: 7.1056e-05 - val_loss: 5.1695e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 92/100\n",
      "165/165 - 3s - loss: 7.0586e-05 - val_loss: 4.9931e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 93/100\n",
      "165/165 - 3s - loss: 7.1372e-05 - val_loss: 5.0022e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 94/100\n",
      "165/165 - 3s - loss: 6.9737e-05 - val_loss: 4.9537e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 95/100\n",
      "165/165 - 3s - loss: 7.0899e-05 - val_loss: 5.0584e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 96/100\n",
      "165/165 - 3s - loss: 6.9413e-05 - val_loss: 4.8588e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "165/165 - 3s - loss: 6.9788e-05 - val_loss: 4.8792e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 98/100\n",
      "165/165 - 3s - loss: 6.7940e-05 - val_loss: 4.6805e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 99/100\n",
      "165/165 - 3s - loss: 6.8281e-05 - val_loss: 4.5949e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 100/100\n",
      "165/165 - 3s - loss: 6.6815e-05 - val_loss: 4.4978e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:15:48.829380: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:15:49.011662: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:15:49.027236: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:15:49.358515: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:15:49.378840: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:15:52.756814: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:15:52.819724: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:15:52.831863: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 - 6s - loss: 5.0689e-04 - val_loss: 2.0815e-04 - 6s/epoch - 35ms/step\n",
      "Epoch 2/100\n",
      "165/165 - 3s - loss: 2.6012e-04 - val_loss: 1.8644e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 3/100\n",
      "165/165 - 3s - loss: 3.0698e-04 - val_loss: 2.1280e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 4/100\n",
      "165/165 - 3s - loss: 4.0728e-04 - val_loss: 4.0882e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "165/165 - 3s - loss: 5.6649e-04 - val_loss: 7.7780e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "165/165 - 3s - loss: 5.2248e-04 - val_loss: 4.0865e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "165/165 - 3s - loss: 3.1094e-04 - val_loss: 1.6106e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "165/165 - 3s - loss: 1.7820e-04 - val_loss: 8.5702e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 9/100\n",
      "165/165 - 3s - loss: 1.1654e-04 - val_loss: 5.6368e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 10/100\n",
      "165/165 - 3s - loss: 9.4406e-05 - val_loss: 4.5051e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 11/100\n",
      "165/165 - 3s - loss: 9.0167e-05 - val_loss: 4.4565e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 12/100\n",
      "165/165 - 3s - loss: 9.5444e-05 - val_loss: 5.2102e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 13/100\n",
      "165/165 - 3s - loss: 1.0855e-04 - val_loss: 6.7507e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "165/165 - 3s - loss: 1.3013e-04 - val_loss: 9.3663e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 15/100\n",
      "165/165 - 3s - loss: 1.6141e-04 - val_loss: 1.3728e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "165/165 - 3s - loss: 2.0270e-04 - val_loss: 2.1079e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "165/165 - 3s - loss: 2.4817e-04 - val_loss: 2.9512e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 18/100\n",
      "165/165 - 3s - loss: 2.7301e-04 - val_loss: 3.1756e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "165/165 - 3s - loss: 3.2140e-04 - val_loss: 4.5351e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 20/100\n",
      "165/165 - 3s - loss: 3.3459e-04 - val_loss: 4.8261e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 21/100\n",
      "165/165 - 3s - loss: 2.8165e-04 - val_loss: 2.6664e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 22/100\n",
      "165/165 - 3s - loss: 1.7452e-04 - val_loss: 1.5623e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 23/100\n",
      "165/165 - 3s - loss: 1.1832e-04 - val_loss: 1.0789e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 24/100\n",
      "165/165 - 3s - loss: 9.3303e-05 - val_loss: 8.4544e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 25/100\n",
      "165/165 - 3s - loss: 8.4638e-05 - val_loss: 7.4835e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 26/100\n",
      "165/165 - 3s - loss: 8.4260e-05 - val_loss: 7.3846e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "165/165 - 3s - loss: 8.9209e-05 - val_loss: 7.9643e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 28/100\n",
      "165/165 - 3s - loss: 9.8874e-05 - val_loss: 9.2322e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 29/100\n",
      "165/165 - 3s - loss: 1.1347e-04 - val_loss: 1.1368e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 30/100\n",
      "165/165 - 3s - loss: 1.3312e-04 - val_loss: 1.4679e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 31/100\n",
      "165/165 - 3s - loss: 1.5663e-04 - val_loss: 1.9443e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 32/100\n",
      "165/165 - 3s - loss: 1.7938e-04 - val_loss: 2.4420e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 33/100\n",
      "165/165 - 3s - loss: 1.8930e-04 - val_loss: 2.1453e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 34/100\n",
      "165/165 - 3s - loss: 2.0295e-04 - val_loss: 2.4515e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 35/100\n",
      "165/165 - 3s - loss: 2.2151e-04 - val_loss: 3.1773e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 36/100\n",
      "165/165 - 3s - loss: 2.0370e-04 - val_loss: 2.7529e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 37/100\n",
      "165/165 - 3s - loss: 1.5905e-04 - val_loss: 1.7736e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 38/100\n",
      "165/165 - 3s - loss: 1.1364e-04 - val_loss: 1.1674e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 39/100\n",
      "165/165 - 3s - loss: 8.9314e-05 - val_loss: 8.7939e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 40/100\n",
      "165/165 - 3s - loss: 7.8999e-05 - val_loss: 7.3878e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 41/100\n",
      "165/165 - 3s - loss: 7.6520e-05 - val_loss: 6.9141e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 42/100\n",
      "165/165 - 3s - loss: 7.8997e-05 - val_loss: 7.1156e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 43/100\n",
      "165/165 - 3s - loss: 8.5430e-05 - val_loss: 7.9106e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 44/100\n",
      "165/165 - 3s - loss: 9.5497e-05 - val_loss: 9.3401e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 45/100\n",
      "165/165 - 3s - loss: 1.0875e-04 - val_loss: 1.1522e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 46/100\n",
      "165/165 - 3s - loss: 1.2372e-04 - val_loss: 1.4442e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 47/100\n",
      "165/165 - 3s - loss: 1.3677e-04 - val_loss: 1.6385e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 48/100\n",
      "165/165 - 3s - loss: 1.2976e-04 - val_loss: 1.0524e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 49/100\n",
      "165/165 - 3s - loss: 1.4399e-04 - val_loss: 1.4911e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 50/100\n",
      "165/165 - 3s - loss: 1.4305e-04 - val_loss: 1.7623e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 51/100\n",
      "165/165 - 3s - loss: 1.2504e-04 - val_loss: 1.5734e-04 - 3s/epoch - 17ms/step\n",
      "Epoch 52/100\n",
      "165/165 - 3s - loss: 1.0816e-04 - val_loss: 1.2899e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 53/100\n",
      "165/165 - 3s - loss: 9.5396e-05 - val_loss: 1.0508e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 54/100\n",
      "165/165 - 3s - loss: 8.6130e-05 - val_loss: 8.8195e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 55/100\n",
      "165/165 - 3s - loss: 8.2246e-05 - val_loss: 7.9342e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 56/100\n",
      "165/165 - 3s - loss: 8.1758e-05 - val_loss: 7.6210e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "165/165 - 3s - loss: 8.4344e-05 - val_loss: 7.8110e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 58/100\n",
      "165/165 - 3s - loss: 8.8978e-05 - val_loss: 8.3951e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 59/100\n",
      "165/165 - 3s - loss: 9.4935e-05 - val_loss: 9.2916e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 60/100\n",
      "165/165 - 3s - loss: 1.0064e-04 - val_loss: 1.0059e-04 - 3s/epoch - 16ms/step\n",
      "Epoch 61/100\n",
      "165/165 - 3s - loss: 1.0456e-04 - val_loss: 9.9788e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 62/100\n",
      "165/165 - 3s - loss: 1.0042e-04 - val_loss: 8.5770e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 63/100\n",
      "165/165 - 3s - loss: 9.0494e-05 - val_loss: 7.8936e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 64/100\n",
      "165/165 - 3s - loss: 8.9730e-05 - val_loss: 8.0454e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 65/100\n",
      "165/165 - 3s - loss: 8.2957e-05 - val_loss: 6.9265e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 66/100\n",
      "165/165 - 3s - loss: 8.6752e-05 - val_loss: 7.2078e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 67/100\n",
      "165/165 - 3s - loss: 8.6346e-05 - val_loss: 7.4053e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 68/100\n",
      "165/165 - 3s - loss: 8.9723e-05 - val_loss: 8.0064e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 69/100\n",
      "165/165 - 3s - loss: 8.8010e-05 - val_loss: 7.8131e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 70/100\n",
      "165/165 - 3s - loss: 8.8661e-05 - val_loss: 7.3690e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 71/100\n",
      "165/165 - 3s - loss: 8.2293e-05 - val_loss: 6.6272e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 72/100\n",
      "165/165 - 3s - loss: 8.3358e-05 - val_loss: 7.0273e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 73/100\n",
      "165/165 - 3s - loss: 7.9689e-05 - val_loss: 6.3018e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 74/100\n",
      "165/165 - 3s - loss: 8.1951e-05 - val_loss: 6.6134e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 75/100\n",
      "165/165 - 3s - loss: 7.8911e-05 - val_loss: 6.1942e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 76/100\n",
      "165/165 - 3s - loss: 8.1708e-05 - val_loss: 6.5103e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 77/100\n",
      "165/165 - 3s - loss: 8.0418e-05 - val_loss: 6.3611e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 78/100\n",
      "165/165 - 3s - loss: 8.1332e-05 - val_loss: 6.4089e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 79/100\n",
      "165/165 - 3s - loss: 7.6075e-05 - val_loss: 5.7223e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 80/100\n",
      "165/165 - 3s - loss: 7.7517e-05 - val_loss: 5.9946e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 81/100\n",
      "165/165 - 3s - loss: 7.5203e-05 - val_loss: 5.7387e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 82/100\n",
      "165/165 - 3s - loss: 7.8306e-05 - val_loss: 5.9778e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 83/100\n",
      "165/165 - 3s - loss: 7.6364e-05 - val_loss: 5.7680e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 84/100\n",
      "165/165 - 3s - loss: 7.8683e-05 - val_loss: 5.8152e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 85/100\n",
      "165/165 - 3s - loss: 7.5914e-05 - val_loss: 5.6421e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 86/100\n",
      "165/165 - 3s - loss: 7.6298e-05 - val_loss: 5.7670e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 87/100\n",
      "165/165 - 3s - loss: 7.2767e-05 - val_loss: 5.3758e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 88/100\n",
      "165/165 - 3s - loss: 7.2977e-05 - val_loss: 5.1585e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 89/100\n",
      "165/165 - 3s - loss: 7.1512e-05 - val_loss: 5.1283e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 90/100\n",
      "165/165 - 3s - loss: 7.2955e-05 - val_loss: 5.2543e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 91/100\n",
      "165/165 - 3s - loss: 7.2578e-05 - val_loss: 5.1049e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 92/100\n",
      "165/165 - 3s - loss: 7.2951e-05 - val_loss: 5.2314e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 93/100\n",
      "165/165 - 3s - loss: 7.1775e-05 - val_loss: 5.0453e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 94/100\n",
      "165/165 - 3s - loss: 7.1084e-05 - val_loss: 4.9559e-05 - 3s/epoch - 16ms/step\n",
      "Epoch 95/100\n",
      "165/165 - 3s - loss: 7.0154e-05 - val_loss: 4.9497e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 96/100\n",
      "165/165 - 3s - loss: 6.9611e-05 - val_loss: 4.7124e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 97/100\n",
      "165/165 - 3s - loss: 6.9321e-05 - val_loss: 4.6294e-05 - 3s/epoch - 17ms/step\n",
      "Epoch 98/100\n",
      "165/165 - 3s - loss: 6.9290e-05 - val_loss: 4.6648e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 99/100\n",
      "165/165 - 3s - loss: 6.9519e-05 - val_loss: 4.5503e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 100/100\n",
      "165/165 - 3s - loss: 6.9474e-05 - val_loss: 4.4122e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:20:24.843641: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:20:25.034518: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:20:25.049567: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:20:25.224826: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:20:25.245135: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:20:28.690008: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:20:28.751425: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:20:28.763670: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 - 6s - loss: 2.3221e-04 - val_loss: 1.8749e-05 - 6s/epoch - 35ms/step\n",
      "Epoch 2/100\n",
      "165/165 - 3s - loss: 1.7737e-04 - val_loss: 1.8395e-05 - 3s/epoch - 18ms/step\n",
      "Epoch 3/100\n",
      "165/165 - 3s - loss: 1.6095e-04 - val_loss: 7.7439e-06 - 3s/epoch - 19ms/step\n",
      "Epoch 4/100\n",
      "165/165 - 3s - loss: 9.6451e-05 - val_loss: 6.2617e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 5/100\n",
      "165/165 - 3s - loss: 9.1698e-05 - val_loss: 7.5819e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 6/100\n",
      "165/165 - 3s - loss: 9.0008e-05 - val_loss: 7.9259e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 7/100\n",
      "165/165 - 3s - loss: 8.8741e-05 - val_loss: 7.8869e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 8/100\n",
      "165/165 - 3s - loss: 8.7226e-05 - val_loss: 7.7609e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 9/100\n",
      "165/165 - 3s - loss: 8.5541e-05 - val_loss: 7.6159e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 10/100\n",
      "165/165 - 3s - loss: 8.3824e-05 - val_loss: 7.4688e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 11/100\n",
      "165/165 - 3s - loss: 8.2126e-05 - val_loss: 7.3240e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 12/100\n",
      "165/165 - 3s - loss: 8.0445e-05 - val_loss: 7.1810e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 13/100\n",
      "165/165 - 3s - loss: 7.8756e-05 - val_loss: 7.0372e-06 - 3s/epoch - 19ms/step\n",
      "Epoch 14/100\n",
      "165/165 - 3s - loss: 7.7022e-05 - val_loss: 6.8892e-06 - 3s/epoch - 19ms/step\n",
      "Epoch 15/100\n",
      "165/165 - 3s - loss: 7.5203e-05 - val_loss: 6.7330e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 16/100\n",
      "165/165 - 3s - loss: 7.3273e-05 - val_loss: 6.5663e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 17/100\n",
      "165/165 - 3s - loss: 7.1240e-05 - val_loss: 6.3900e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 18/100\n",
      "165/165 - 3s - loss: 6.9150e-05 - val_loss: 6.2078e-06 - 3s/epoch - 19ms/step\n",
      "Epoch 19/100\n",
      "165/165 - 3s - loss: 6.7053e-05 - val_loss: 6.0235e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 20/100\n",
      "165/165 - 3s - loss: 6.4934e-05 - val_loss: 5.8390e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 21/100\n",
      "165/165 - 3s - loss: 6.3103e-05 - val_loss: 5.6844e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 22/100\n",
      "165/165 - 3s - loss: 6.1193e-05 - val_loss: 5.5100e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 23/100\n",
      "165/165 - 3s - loss: 5.9159e-05 - val_loss: 5.3274e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 24/100\n",
      "165/165 - 3s - loss: 5.7125e-05 - val_loss: 5.1398e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 25/100\n",
      "165/165 - 3s - loss: 5.5258e-05 - val_loss: 4.9813e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 26/100\n",
      "165/165 - 3s - loss: 5.3693e-05 - val_loss: 4.8576e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 27/100\n",
      "165/165 - 3s - loss: 5.2342e-05 - val_loss: 4.7632e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 28/100\n",
      "165/165 - 3s - loss: 5.1171e-05 - val_loss: 4.6952e-06 - 3s/epoch - 19ms/step\n",
      "Epoch 29/100\n",
      "165/165 - 3s - loss: 5.0043e-05 - val_loss: 4.6237e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 30/100\n",
      "165/165 - 3s - loss: 4.9038e-05 - val_loss: 4.6763e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 31/100\n",
      "165/165 - 3s - loss: 4.8523e-05 - val_loss: 4.7028e-06 - 3s/epoch - 19ms/step\n",
      "Epoch 32/100\n",
      "165/165 - 3s - loss: 4.7936e-05 - val_loss: 4.7682e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 33/100\n",
      "165/165 - 3s - loss: 4.7756e-05 - val_loss: 4.8489e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 34/100\n",
      "165/165 - 3s - loss: 4.7535e-05 - val_loss: 4.9457e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 35/100\n",
      "165/165 - 3s - loss: 4.7116e-05 - val_loss: 5.0763e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 36/100\n",
      "165/165 - 3s - loss: 4.7135e-05 - val_loss: 5.1509e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 37/100\n",
      "165/165 - 3s - loss: 4.7054e-05 - val_loss: 5.1683e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 38/100\n",
      "165/165 - 3s - loss: 4.6878e-05 - val_loss: 5.1395e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 39/100\n",
      "165/165 - 3s - loss: 4.6868e-05 - val_loss: 5.1525e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 40/100\n",
      "165/165 - 3s - loss: 4.6752e-05 - val_loss: 5.0424e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 41/100\n",
      "165/165 - 3s - loss: 4.6764e-05 - val_loss: 4.9941e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 42/100\n",
      "165/165 - 3s - loss: 4.6296e-05 - val_loss: 4.8250e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 43/100\n",
      "165/165 - 3s - loss: 4.5565e-05 - val_loss: 4.7654e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 44/100\n",
      "165/165 - 3s - loss: 4.5220e-05 - val_loss: 4.6816e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 45/100\n",
      "165/165 - 3s - loss: 4.4796e-05 - val_loss: 4.6254e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 46/100\n",
      "165/165 - 3s - loss: 4.4094e-05 - val_loss: 4.5068e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 47/100\n",
      "165/165 - 3s - loss: 4.3624e-05 - val_loss: 4.4416e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 48/100\n",
      "165/165 - 3s - loss: 4.3280e-05 - val_loss: 4.3895e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 49/100\n",
      "165/165 - 3s - loss: 4.2939e-05 - val_loss: 4.4054e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 50/100\n",
      "165/165 - 3s - loss: 4.2839e-05 - val_loss: 4.4954e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 51/100\n",
      "165/165 - 3s - loss: 4.2516e-05 - val_loss: 4.3991e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 52/100\n",
      "165/165 - 3s - loss: 4.2451e-05 - val_loss: 4.3273e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 53/100\n",
      "165/165 - 3s - loss: 4.2063e-05 - val_loss: 4.2781e-06 - 3s/epoch - 19ms/step\n",
      "Epoch 54/100\n",
      "165/165 - 3s - loss: 4.1827e-05 - val_loss: 4.2232e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 55/100\n",
      "165/165 - 3s - loss: 4.1493e-05 - val_loss: 4.1667e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 56/100\n",
      "165/165 - 3s - loss: 4.1050e-05 - val_loss: 4.1268e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 57/100\n",
      "165/165 - 3s - loss: 4.0583e-05 - val_loss: 4.0610e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 58/100\n",
      "165/165 - 3s - loss: 3.9876e-05 - val_loss: 4.0523e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 59/100\n",
      "165/165 - 3s - loss: 3.9481e-05 - val_loss: 4.1057e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 60/100\n",
      "165/165 - 3s - loss: 3.9697e-05 - val_loss: 4.2478e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 61/100\n",
      "165/165 - 3s - loss: 4.0470e-05 - val_loss: 4.3806e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 62/100\n",
      "165/165 - 3s - loss: 4.1534e-05 - val_loss: 4.5534e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 63/100\n",
      "165/165 - 3s - loss: 4.1152e-05 - val_loss: 4.4719e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 64/100\n",
      "165/165 - 3s - loss: 4.0216e-05 - val_loss: 4.4425e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 65/100\n",
      "165/165 - 3s - loss: 4.0450e-05 - val_loss: 4.4657e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 66/100\n",
      "165/165 - 3s - loss: 4.0448e-05 - val_loss: 4.3731e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 67/100\n",
      "165/165 - 3s - loss: 3.9819e-05 - val_loss: 4.2908e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 68/100\n",
      "165/165 - 3s - loss: 3.9835e-05 - val_loss: 4.2604e-06 - 3s/epoch - 19ms/step\n",
      "Epoch 69/100\n",
      "165/165 - 3s - loss: 3.9320e-05 - val_loss: 4.1787e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 70/100\n",
      "165/165 - 3s - loss: 3.8983e-05 - val_loss: 4.1581e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 71/100\n",
      "165/165 - 3s - loss: 3.8991e-05 - val_loss: 4.1142e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 72/100\n",
      "165/165 - 3s - loss: 3.8630e-05 - val_loss: 4.1354e-06 - 3s/epoch - 19ms/step\n",
      "Epoch 73/100\n",
      "165/165 - 3s - loss: 3.8722e-05 - val_loss: 4.1359e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 74/100\n",
      "165/165 - 3s - loss: 3.8504e-05 - val_loss: 4.1517e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 75/100\n",
      "165/165 - 3s - loss: 3.8565e-05 - val_loss: 4.1378e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 76/100\n",
      "165/165 - 3s - loss: 3.8255e-05 - val_loss: 4.1147e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 77/100\n",
      "165/165 - 3s - loss: 3.8022e-05 - val_loss: 4.0390e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 78/100\n",
      "165/165 - 3s - loss: 3.7568e-05 - val_loss: 4.0665e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 79/100\n",
      "165/165 - 3s - loss: 3.7961e-05 - val_loss: 4.0290e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 80/100\n",
      "165/165 - 3s - loss: 3.7336e-05 - val_loss: 4.0179e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 81/100\n",
      "165/165 - 3s - loss: 3.7346e-05 - val_loss: 3.9692e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 82/100\n",
      "165/165 - 3s - loss: 3.7071e-05 - val_loss: 3.9734e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 83/100\n",
      "165/165 - 3s - loss: 3.7038e-05 - val_loss: 3.9665e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 84/100\n",
      "165/165 - 3s - loss: 3.7122e-05 - val_loss: 3.9899e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 85/100\n",
      "165/165 - 3s - loss: 3.7055e-05 - val_loss: 4.0111e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 86/100\n",
      "165/165 - 3s - loss: 3.6938e-05 - val_loss: 3.9749e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 87/100\n",
      "165/165 - 3s - loss: 3.6640e-05 - val_loss: 3.9734e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 88/100\n",
      "165/165 - 3s - loss: 3.6766e-05 - val_loss: 3.9426e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 89/100\n",
      "165/165 - 3s - loss: 3.6427e-05 - val_loss: 3.9544e-06 - 3s/epoch - 18ms/step\n",
      "Epoch 90/100\n",
      "165/165 - 3s - loss: 3.6416e-05 - val_loss: 3.9029e-06 - 3s/epoch - 17ms/step\n",
      "Epoch 91/100\n",
      "165/165 - 3s - loss: 3.6216e-05 - val_loss: 3.8901e-06 - 3s/epoch - 17ms/step\n",
      "Epoch 92/100\n",
      "165/165 - 3s - loss: 3.6234e-05 - val_loss: 3.8878e-06 - 3s/epoch - 16ms/step\n",
      "Epoch 93/100\n",
      "165/165 - 3s - loss: 3.5989e-05 - val_loss: 3.8900e-06 - 3s/epoch - 16ms/step\n",
      "Epoch 94/100\n",
      "165/165 - 3s - loss: 3.6033e-05 - val_loss: 3.8864e-06 - 3s/epoch - 16ms/step\n",
      "Epoch 95/100\n",
      "165/165 - 2s - loss: 3.5943e-05 - val_loss: 3.8910e-06 - 2s/epoch - 15ms/step\n",
      "Epoch 96/100\n",
      "165/165 - 2s - loss: 3.5942e-05 - val_loss: 3.8771e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 97/100\n",
      "165/165 - 2s - loss: 3.5707e-05 - val_loss: 3.8623e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 98/100\n",
      "165/165 - 2s - loss: 3.5627e-05 - val_loss: 3.8762e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 99/100\n",
      "165/165 - 2s - loss: 3.5734e-05 - val_loss: 3.8307e-06 - 2s/epoch - 13ms/step\n",
      "Epoch 100/100\n",
      "165/165 - 2s - loss: 3.5349e-05 - val_loss: 3.8594e-06 - 2s/epoch - 13ms/step\n"
     ]
    }
   ],
   "source": [
    "bilstms = []\n",
    "models = []\n",
    "for batch, epoch, neuron in hyperparams:\n",
    "    model, bilstm = LSTMUnit.train_bilstm(train_X, train_y, test_X, test_y, neuron, epoch, batch)\n",
    "    bilstms.append(bilstm)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebe15d8d-6bc9-4220-a7db-48e4d4c7cd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/165 [..............................] - ETA: 1:33"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:25:21.931906: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:21.984149: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:21.992353: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 1s 5ms/step\n",
      "(32, 100, 50)\n",
      "Epoch: 100\n",
      "Neurons: 50\n",
      "0.7770220056128813\n",
      "  1/165 [..............................] - ETA: 49s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:25:23.157423: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:23.202178: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:23.210308: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 1s 5ms/step\n",
      "(32, 100, 60)\n",
      "Epoch: 100\n",
      "Neurons: 60\n",
      "0.7280671044116247\n",
      "  1/165 [..............................] - ETA: 48s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:25:24.315969: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:24.357560: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:24.365977: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 1s 5ms/step\n",
      "(32, 100, 100)\n",
      "Epoch: 100\n",
      "Neurons: 100\n",
      "0.7380658879830945\n",
      "  1/165 [..............................] - ETA: 47s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:25:25.515421: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:25.559100: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:25.567385: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 1s 5ms/step\n",
      "(64, 100, 50)\n",
      "Epoch: 100\n",
      "Neurons: 50\n",
      "0.9293664757803509\n",
      "  1/165 [..............................] - ETA: 47s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:25:26.661175: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:26.703883: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:26.712419: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 1s 5ms/step\n",
      "(64, 100, 60)\n",
      "Epoch: 100\n",
      "Neurons: 60\n",
      "0.9065518074965541\n",
      "  1/165 [..............................] - ETA: 47s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:25:27.790752: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:27.834339: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:27.842849: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 1s 5ms/step\n",
      "(64, 100, 100)\n",
      "Epoch: 100\n",
      "Neurons: 100\n",
      "0.8105218143526441\n",
      "  1/165 [..............................] - ETA: 49s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:25:28.994292: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:29.044246: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:29.052476: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 1s 5ms/step\n",
      "(128, 100, 50)\n",
      "Epoch: 100\n",
      "Neurons: 50\n",
      "4.333149706743311\n",
      "  4/165 [..............................] - ETA: 2s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:25:30.152294: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:30.194184: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:30.202388: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 1s 5ms/step\n",
      "(128, 100, 60)\n",
      "Epoch: 100\n",
      "Neurons: 60\n",
      "4.289900325950248\n",
      "  1/165 [..............................] - ETA: 48s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:25:31.293631: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:31.335573: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-21 11:25:31.343758: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 1s 5ms/step\n",
      "(128, 100, 100)\n",
      "Epoch: 100\n",
      "Neurons: 100\n",
      "0.8854880516837641\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "i=0\n",
    "for m in models:\n",
    "    test_x2 = test_X\n",
    "    yhat = m.predict(test_x2)\n",
    "    inv_yhat = Preprocessing.inverse_scaler(yhat, scaler)\n",
    "    inv_y = Preprocessing.inverse_scaler(test_y.reshape(-1,1), scaler)\n",
    "    print(hyperparams[i])\n",
    "    print(\"Epoch: \"+ str(bilstms[i].params['epochs']))\n",
    "    print(\"Neurons: \"+str(m.layers[0].layer.units))\n",
    "    print(Evaluation.mape(inv_y,inv_yhat)[0])\n",
    "    with open('BiLSTM_LTC'+str(hyperparams[i])+'.pkl', 'wb') as f:\n",
    "        pickle.dump(bilstms[i].history, f)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3723ed97-4baa-4c5e-9dac-aa107e173d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BiLSTM_LTC(32, 100, 50).pkl', \"rb\") as file_pi:\n",
    "    history = pickle.load(file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb32a172-5a13-4cfc-b543-96f48fe9f368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
